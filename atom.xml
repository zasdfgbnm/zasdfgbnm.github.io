<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>zasdfgbnm</title>
  
  
  <link href="https://zasdfgbnm.github.io/atom.xml" rel="self"/>
  
  <link href="https://zasdfgbnm.github.io/"/>
  <updated>2021-04-14T02:38:48.164Z</updated>
  <id>https://zasdfgbnm.github.io/</id>
  
  <author>
    <name>zasdfgbnm</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Moderna, Pfizer, 以及强生三种疫苗信息总结</title>
    <link href="https://zasdfgbnm.github.io/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/"/>
    <id>https://zasdfgbnm.github.io/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/</id>
    <published>2021-04-04T15:14:21.000Z</published>
    <updated>2021-04-14T02:38:48.164Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p>在4.15日加州全面放开打疫苗前，花时间整理了一下各个疫苗的相关数据跟结论。虽然我没有任何医学或者生物学背景，但是我毕竟也有博士学位，一点基础的科研思维还是有的，看这些东西，对我本人是有益的，可以让我知道what to expect以及what not to expect。我把我自己读paper的笔记写成文章，除了自己日后查阅方便以外，一方面是希望省去有同样需求的人从头找文献的一丁点麻烦；另一方面则是如果有医学专业的人士看到我的笔记，可以帮我指出其中的不足或者疏忽，这样子也能加深我本人的理解。</p><p><em>本人并非医学专业，所以请带着批判性思维来阅读本文章。如发现错误或者遗漏，欢迎指正。</em></p><h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>（TLDR可以直接跳过文章看总结。）</p><p>本文主要总结的Moderna、辉瑞、强生三种疫苗的三期临床数据，以及一些跟副作用以及有效性相关的后续研究。这些研究里面，最常用的有两种研究手段：</p><p>一种是通过临床实验，得出统计规律。这种研究一般来讲，就是让大量的人注射疫苗。然后统计一下这些人里面，都有谁得了新冠。然后就可以记录下来，得了新冠的人里面，有多少是接种了疫苗的，多少是没有接种疫苗的，以及多少人会接种部位疼痛，多少人会发烧，等等数据。最后根据数据就能算出来比例。</p><p>另一种则是病毒中和实验。这种实验就有点类似中学化学里面学的滴定实验。这种实验的做法，是取接种者的血浆，然后拿着这些血浆来中和病毒。如果疫苗非常有效的话，血浆中会含有大量的抗体。这种情况下，血浆是可以直接中和掉所有的病毒的。这个时候，要定量研究血浆的有效性，就需要对血浆进行稀释，一直稀释到血浆只能中和一半病毒为止。这个时候稀释的倍数，就叫做滴度（titer）。显然，血浆中的抗体浓度越高/抗体越有效，需要稀释的倍数就更高，滴度就更大。对于变种病毒来讲，变种导致抗体的有效性降低了，对应到这个实验上，就是滴度降低了。</p><span id="more"></span><h1 id="术语"><a href="#术语" class="headerlink" title="术语"></a>术语</h1><p>本文中所有参考文献的引用都采用 “[Moderna.1]” 这种格式。</p><p><strong>疫苗：</strong></p><ul><li><strong>mRNA-1273:</strong> Moderna疫苗</li><li><strong>BNT162b1/BNT162b2:</strong> 这就是大家常说的辉瑞疫苗。但在本文我更倾向于称之为BioNTech-Pfizer疫苗，因为这疫苗其实是这两家公司合作研发的。疫苗研发早期，研究人员测试了BNT162b1跟BNT162b2两种，后来发现两者有效性差不多，但是b2副作用低一些，于是后来就采用b2了 [BioNTech-Pfizer.4]</li><li><strong>Ad26.COV2.S:</strong> 强生疫苗。这个疫苗是强生公司的子公司Janssen（杨森制药）制造的。</li></ul><p><strong>毒株：</strong></p><ul><li><strong>USA-WA1/2020:</strong> 这是从一位感染者身上收集的毒株，这位旅客2020年一月份一位从中国去了华盛顿州。这个毒株<a href="https://www.beiresources.org/Catalog/animalviruses/NR-52281.aspx">网上有卖的</a>。</li><li><strong>B.1.1.7:</strong> 英国变种</li><li><strong>B.1.351:</strong> 南非变种</li><li><strong>P.1:</strong> 巴西变种</li><li><strong>B.1.427/B.1.429:</strong> 加州变种</li></ul><p>除了上述的几个变种病毒以外，病毒的S蛋白还有可能发生其他的一些微小的突变。比如说，如果在614这个位置上，D氨基酸（天冬氨酸）变异成了G氨基酸（甘氨酸），则这个突变被称为<em>D614G</em>（备注：组成蛋白质的20种氨基酸里面，每个氨基酸都有自己的字母表示，这种表示方法在蛋白质研究中很常见，具体的对照表可以参阅<a href="https://zh.wikipedia.org/wiki/%E6%A8%99%E6%BA%96%E8%9B%8B%E7%99%BD%E8%83%BA%E5%9F%BA%E9%85%B8%E5%88%97%E8%A1%A8">维基百科</a>）。刚刚所说的D614G突变，非常有利于病毒传播，以至于从2020年6月份以后，就已经很难找到不存在D614G突变的病毒了[General.3]。再比如<em>B.1.1.7+E484K</em>，表示的是在英国变种的基础上484这个位置的E被替换为K。</p><h1 id="疫苗综述"><a href="#疫苗综述" class="headerlink" title="疫苗综述"></a>疫苗综述</h1><p>目前市场上的疫苗，都是针对新冠病毒的S蛋白的。S蛋白在新冠病上的作用可以参见几位中国研究者发在Nature上的文章 [General.5]。简而言之就是：S蛋白是冠状病毒表面的那些刺突（spike），这些刺突就跟开门的钥匙一样，他跟细胞上的门锁ACE2受体结合，细胞就会对病毒进行放行，让病毒进入细胞体内。病毒进入细胞体内以后，就会释放病毒的mRNA，用以指导合成新的病毒，达到增殖的目的。</p><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/41401_2020_485_Fig1_HTML.webp" class="" title="S蛋白扮演的角色"><p>另外值得指出的是，S蛋白并不稳定，所以这些疫苗都会对S蛋白进行魔改，让其稳定，这样才能很好地刺激人体的免疫系统。</p><p>美国市场上的疫苗有两种，一种是mRNA疫苗（Moderna跟BioNTech-Pfizer），另一种则是病毒载体疫苗（强生疫苗）。其中mRNA疫苗使用脂质（lipid）包裹mRNA（还记得中学生物课学过的，细胞膜的主要成分是磷脂双分子层吗？磷脂双分子层英文叫做lipid bilayer），又称作“<em>mRNA–LNP</em>”，其中LNP是lipid nanoparticles的缩写。LNP包裹着mRNA，把mRNA一路护送到细胞内部，然后细胞内部就会用这些mRNA来合成新冠病毒的S蛋白，这些蛋白通过高尔基体的呈递而诱发免疫反应。用LNP来包裹mRNA优点是：可以帮助保护mRNA，也可以target特定类型的细胞，并且脂质可以很方便地进行大规模生产 [General.6]。从[General.6]里面盗用两张图来说明mRNA–LNP的工作原理：</p><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/p1f3149rsi1s5jdfh16r68kj1aqj4_page_03.svg" class="" title="mRNA–LNP工作原理1"><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/p1f3149rsi1s5jdfh16r68kj1aqj4_page_05.svg" class="" title="mRNA–LNP工作原理2"><p>跟其他疫苗相比，mRNA疫苗的很大一个优势就是可以快速地研发，以及快速大量地生产。比如这次新冠疫情中，在新冠病毒序列公布后的五天之内，Moderna就开始了针对新冠病毒的疫苗生产，序列公布后66天就开始了一期临床 [Moderna.1]。</p><p>病毒载体疫苗（virally vectored vaccine），跟mRNA疫苗类似，同样是把S蛋白的基因送入人体细胞，让人体细胞合成S蛋白作为抗原来诱导免疫反应。只不过不同的是，病毒载体疫苗不是用脂质来把S蛋白的基因送入人体，而是直接用某种活的病毒来把S蛋白的基因送入人体 [General.7]：</p><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/w14465_f2_conv.jpeg" class="" title="病毒载体疫苗的工作原理"><p>病毒载体疫苗有一个弊端：病毒载体本身也是病毒，也会引起免疫系统的抵抗。如果你接种的时候已经有这个载体的抗体了，那么这个载体还没把S蛋白的基因送给细胞，自己就先被免疫系统干掉了，这样子效果就低了。另外，病毒载体疫苗生产起来比较复杂。[General.7]</p><h2 id="Moderna"><a href="#Moderna" class="headerlink" title="Moderna"></a>Moderna</h2><p>Moderna疫苗的成分是 [Moderna.1]：</p><blockquote><p><em>mRNA–LNP</em> encoding the <em>SARS-CoV-2 S(2P)</em> as a transmembrane-anchored protein with the native furin cleavage site (mRNA-1273)。</p></blockquote><p>“*SARS-CoV-2 S(2P)*”指的是新冠病毒的S蛋白的某个变体，参见 [Moderna.1] 原文：</p><blockquote><p>Subsequently, we identified 2 proline substitutions (2P) at the apex of the central helix and heptad repeat 1 that effectively stabilized MERS-CoV, SARS-CoV and human coronavirus HKU1S proteins in the prefusion conformation. Similar to other prefusion-stabilized fusion proteins, MERS-CoV S(2P) protein was more immunogenic at lower doses than wild-type S protein. The 2P mutation has similar effects on the stability of S proteins from other betacoronaviruses, suggesting a generalizable approach for designing stabilized-prefusion Betacoronavirus S protein antigens for vaccination.</p></blockquote><p>大意是S(2P)变体，比起普通的S蛋白，更稳定，低剂量下更有效。</p><p>“transmembrane-anchored protein”跟“native furin cleavage site”是啥意思我也不知道，不过似乎不知道也无所谓，所以就不深扒了。。。</p><h2 id="BioNTech-Pfizer疫苗"><a href="#BioNTech-Pfizer疫苗" class="headerlink" title="BioNTech-Pfizer疫苗"></a>BioNTech-Pfizer疫苗</h2><p>技术上跟Moderna一样，用的都是mRNA-LNP [BioNTech-Pfizer.3]。BioNTech-Pfizer疫苗其实有两种：BNT162b1以及BNT162b2。其中区别是：BNT162b1包含的是“a secreted trimerized SARS-CoV-2 receptor–binding domain”，而BNT162b2则包含“a membrane-anchored SARS-CoV-2 full-length spike, stabilized in the prefusion conformation” [BioNTech-Pfizer.4]。最早的一期跟二期临床都是用BNT162b1做的 [BioNTech-Pfizer.2,3]，BNT162b2则是后来又找了些人对比研究，发现他们俩效果差不多，但是BNT162b2副作用更低，于是最终就选择了BNT162b2 [BioNTech-Pfizer.4]。</p><h2 id="Janssen（强生）"><a href="#Janssen（强生）" class="headerlink" title="Janssen（强生）"></a>Janssen（强生）</h2><p>疫苗的设计参见 [Janssen.4]。这个疫苗是使用Ad26腺病毒作为载体的病毒载体疫苗。具体的成分是：</p><blockquote><p>Ad26 vector encoding for a membrane-bound stabilized S protein with a wild-type signal peptide elicited potent neutralizing humoral immunity and cellular immunity that was polarized towards Th1 IFN-γ.</p></blockquote><h1 id="有效性"><a href="#有效性" class="headerlink" title="有效性"></a>有效性</h1><p>分析有效性，需要关注的是：</p><ol><li>疫苗能防止接种者感染新冠吗？</li><li>疫苗能防止接种者重症吗？</li><li>疫苗能够阻断病毒传播吗？</li></ol><p>1对疫苗的要求是最高的。但是即使一个疫苗达不到1，如果能达到2，那也是很有用的。所以我这里的总结主要针对1跟2。至于3的研究，对全人类的流行病防治有重要意义，但是相关研究不多，我只发现了 [BioNTech-Pfizer.12]，感兴趣的读者可以自行阅读，我就不展开了。</p><h2 id="Moderna-1"><a href="#Moderna-1" class="headerlink" title="Moderna"></a>Moderna</h2><p>Moderna疫苗三期临床有效性如图所示 [Moderna.5]：</p><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/nejmoa2035389_f4.webp" class="" title="Moderna疫苗三期临床有效性"><p>Moderna三期临床总共有30例重症一例死亡，这些案例全都是在安慰剂组。疫苗组没有发现任何重症或者死亡案例。</p><p>Moderna对变种病毒有效性的研究发表在 [Moderna.6]。这里并不像三期临床那样子用实际的病例算出efficacy，而是在实验室环境下，用中和实验测量中和假病毒（recombinant vesicular stomatitis virus (rVSV)–based SARS-CoV-2 (a pseudovirus-based model)）需要的血清浓度。</p><p>这个实验表明，使用接种第二针之后7天的志愿者的血清，可以中和全部的变种病毒。Moderna测量了50%中和滴度（志愿者的血清，如果不进行稀释的话，是会中和全部病毒的。而这个滴度测量的就是，需要对这个血清稀释多少倍，才能让这个稀释后的溶液效果弱化到只能中和50%的病毒。需要的稀释倍数越高，说明血清的防护效果越好。），结果如图：</p><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/nejmc2102179_f1.jpeg" class="" title="Moderna疫苗变异病毒滴度"><p>从图中可以看出，跟欧美广泛流行的D614G相比，B.1.1.7对血浆的中和能力影响不大。P.1, B.1.427/B.1.429, B.1.1.7+E484K, B.1.351这些变种会导致血浆的中和滴度下降了2.3-6.4倍（也就是说，需要的抗体浓度更高了），其中下降最大的6.4倍出现在南非变种。值得注意的是，虽然中和能力有所下降，中和滴度的值依然很高。这就意味着，疫苗对变种病毒防御力依然很强。</p><p>Moderna还研究了疫苗的时效性 [Moderna.7,9]：</p><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/nejmc2103916_f1.webp" class="" title="Moderna疫苗时效性"><p>上图中，横轴指的是注射第一针之后的天数，纵轴是各种不同的滴度（越大越好）。大家有兴趣的话，可以根据上面那个图来猜猜有效性能够持续到多久。</p><h2 id="BioNTech-Pfizer疫苗-1"><a href="#BioNTech-Pfizer疫苗-1" class="headerlink" title="BioNTech-Pfizer疫苗"></a>BioNTech-Pfizer疫苗</h2><p>BioNTech-Pfizer疫苗三期临床有效性下表所示 [BioNTech-Pfizer.5]：</p><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/nejmoa2034577_t2.webp" class="" title="BioNTech-Pfizer疫苗三期临床有效性"><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/nejmoa2034577_t3.jpeg" class="" title="BioNTech-Pfizer疫苗三期临床有效性细节"><p>BioNTech-Pfizer疫苗三期临床在接种完第一针之后，总共有10例重症患者，其中9例是在安慰剂组，1例在疫苗组。疫苗组的这一例患者，是在接种完第二针之后超过7天之后发生的。</p><p>除了三期临床以外，以色列还对这个疫苗进行了国家级别的研究，参与者将近120万人，所以结果的数据在统计上更有说服力一点 [BioNTech-Pfizer.5]：</p><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/nejmoa2101765_t2.jpeg" class="" title="BioNTech-Pfizer疫苗以色列有效性"><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/nejmoa2101765_t3.jpeg" class="" title="BioNTech-Pfizer疫苗以色列有效性细节"><p>上述表格中的数据清楚地告诉了我们接种疫苗不同时间段、或者只接种一针疫苗的有效性。所以接种完第一针以后不要浪，你还远没受保护！</p><p>对变种病毒也有一些相关的研究，我感觉比较有代表性的是对各种变种的中和测试 [BioNTech-Pfizer.8]：</p><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/nejmc2102017_f1.webp" class="" title="BioNTech-Pfizer疫苗以色列有效性细节"><p>上图表明，B.1.1.7跟P.1对血清的中和能力影响不大，B.1.351会导致中和能力下降（具体下降多少请看图中的数值）。</p><h2 id="Janssen（强生）-1"><a href="#Janssen（强生）-1" class="headerlink" title="Janssen（强生）"></a>Janssen（强生）</h2><p>我并没有找到三期临床的paper啥的，所以此处的数据来源都是FDA的报告 [Janssen.7]。FDA报告中，我认为最值得关注的是这几个表格：</p><p>中等-重症：</p><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/VRBPAC-02.26.21-Meeting-Briefing-Document-FDA-25.svg" class="" title="强生局部副作用"><p>所有case：</p><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/VRBPAC-02.26.21-Meeting-Briefing-Document-FDA-31.svg" class="" title="强生局部副作用"><p>重症：</p><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/VRBPAC-02.26.21-Meeting-Briefing-Document-FDA-32.svg" class="" title="强生局部副作用"><p>除此之外，强生疫苗三期临床的一大亮点是，它包含了南非跟巴西变异的的数据：</p><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/VRBPAC-02.26.21-Meeting-Briefing-Document-FDA-37.svg" class="" title="强生局部副作用"><p>相比之下，Moderna跟BioNTech-Pfizer则只有中和滴定实验的数据，并没有临床的统计数据。</p><h1 id="副作用"><a href="#副作用" class="headerlink" title="副作用"></a>副作用</h1><h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="solicited-vs-unsolicited"><a href="#solicited-vs-unsolicited" class="headerlink" title="solicited vs unsolicited"></a>solicited vs unsolicited</h3><p>这里引用台湾CDE的文章中的内容 [General.4]：</p><blockquote><p>疫苗临床试验中不良事件（adverse event）的评估应包括设定记录不良事件（solicited adverse events）以及非设定记录不良事件（unsolicited adverse events）；设定记录的不良事件主要应分为局部性（例如，局部疼痛，局部红肿）与全身性（例如，发烧，呕吐，疲倦，头痛，过敏性反应），这些不良事件的定义，评估方式以及追踪的时间，应于临床试验计划书中预先定义，以确保能够记录到这些不良事件的信息。通常来说，临床试验执行中，应于注射疫苗后20到60分钟之间密切观察，以侦测立即发生的不良反应；由于大多数的设定记录不良事件，多发生在注射疫苗后数天内，因此，应在注射每一剂疫苗后，至少收集七天内的设定记录不良事件（solicited adverse events）。非设定记录不良事件，则应在整个临床试验期间记录。安全性试验追踪期，建议至少为施打最后一剂疫苗后的六个月内。</p></blockquote><p>我对上一段的理解是：在三期临床开始前，药厂要制定一个计划书，计划书中应该包含他们准备监测什么样子的副作用，以及如何监测这些副作用。计划书中的这些预先规定好的，就叫solicited。除此之外，如果接种者认为自己遇到了在计划书中的监测规定之外的副作用，也可以主动向药厂汇报，药厂需要记录这些副作用，而这些则叫做unsolicited。</p><p>另外值得说的是，solicited的副作用，往往比较模式化，一般都是些疼痛、发烧之类的常见副作用。由于是模式化的，所以可以很容易制作成图表来更好地展示，也可以更好地对比不同的疫苗。而unsolicited副作用则多种多样，比如面瘫。而且，unsolicited往往数据量低，很难确定这些副作用是否跟疫苗有关。</p><p>所以，我个人认为，要想了解都有啥unsolicited的副作用，其实除了看权威的报告以外，还可以看看那些媒体报道的，引发广泛恐慌的那种，可能危及生命的副作用，比如血栓以及血小板减少症。这些症状是否跟疫苗有关并无定论，但是知道一下发生相关情况的自救知识倒是很好的。</p><h3 id="严重程度的定义"><a href="#严重程度的定义" class="headerlink" title="严重程度的定义"></a>严重程度的定义</h3><p>FDA以及国家癌症研究所对副作用严重性程度的定义（具体每个症状的citation在表格内）:</p><table><thead><tr><th>局部副作用</th><th>温和(grade 1)</th><th>中等(grade 2)</th><th>严重(grade 3)</th><th>危及生命(grade 4)</th></tr></thead><tbody><tr><td>疼痛(Pain) [General.1]</td><td>不影响行动</td><td>需要重复使用24小时以上的非麻醉性止痛药，或者干扰正常活动</td><td>需要使用麻醉性止痛药，或者无法进行日常活动</td><td>需要访问急诊室或者住院</td></tr><tr><td>触痛(Tenderness) [General.1]</td><td>触摸会引起轻微不适</td><td>运动时会感到不适</td><td>静息时也能感到严重不适</td><td>需要访问急诊室或者住院</td></tr><tr><td>红斑(Erythema/Redness) [General.1]</td><td>2.5–5cm</td><td>5.1–10cm</td><td>&gt;10cm</td><td>坏死或剥脱性皮炎</td></tr><tr><td>肿胀(Induration/Swelling) [General.1]</td><td>2.5–5cm, 不影响行动</td><td>5.1–10cm，或者干扰正常活动</td><td>&gt;10cm，或者无法进行日常活动</td><td>坏死</td></tr><tr><td>淋巴结病(Lymphadenopathy) [General.2]</td><td>局部淋巴结变大</td><td>局部溃疡；全身淋巴结变大</td><td></td><td></td></tr></tbody></table><table><thead><tr><th>系统性副作用</th><th>温和(grade 1)</th><th>中等(grade 2)</th><th>严重(grade 3)</th><th>危及生命(grade 4)</th></tr></thead><tbody><tr><td>发烧(Fever) (°C) [General.1]</td><td>38.0–38.4</td><td>38.5–38.9</td><td>39.0–40</td><td>&gt;40</td></tr><tr><td>头疼(Headache) [General.1]</td><td>不影响行动</td><td>需要重复使用24小时以上的非麻醉性止痛药，或者干扰正常活动</td><td>严重; 需要使用麻醉性止痛药，或者无法进行日常活动</td><td>需要访问急诊室或者住院</td></tr><tr><td>疲劳(Fatigue) [General.1]</td><td>不影响行动</td><td>影响正常活动</td><td>严重; 或者无法进行日常活动</td><td>需要访问急诊室或者住院</td></tr><tr><td>肌痛(Myalgia) [General.1]</td><td>不影响行动</td><td>影响正常活动</td><td>严重; 或者无法进行日常活动</td><td>需要访问急诊室或者住院</td></tr><tr><td>关节痛(Arthralgia) [General.2]</td><td>轻微疼痛</td><td>中度疼痛; 限制工具性日常生活活动</td><td>严重的症状; 影响自我照顾的日常活动; 选择性手术干预</td><td>威胁生命的后果；需要紧急干预</td></tr><tr><td>恶心/呕吐(Nausea/vomiting) [General.1]</td><td>不影响行动 或者 每天1-2次</td><td>影响正常活动 或者 每天超过2次</td><td>无法进行日常活动 或者 需要门诊静脉补水</td><td>需要因为降压性休克访问急诊室或者住院</td></tr><tr><td>腹泻(Diarrhea) [General.1]</td><td>2-3次稀便 或 &lt;400gms/24小时</td><td>4-5次稀便 或 400-800gms/24小时</td><td>6次或更多次稀便 或 &gt;800gms/24小时 或 需要静脉补水</td><td>需要访问急诊室或者住院</td></tr><tr><td>寒冷(Chills) [General.2]</td><td>轻度的寒冷感; 发抖; 牙齿颤抖</td><td>全身中度震颤；麻痹</td><td>严重或长时间，对麻醉品没有反应</td><td></td></tr></tbody></table><p>除了上述等级之外，另外还有grade 5，grade 5一般指的是死亡 [General.2]。</p><h2 id="Moderna-2"><a href="#Moderna-2" class="headerlink" title="Moderna"></a>Moderna</h2><p>Moderna疫苗三期临床solicited副作用如图所示 [Moderna.5]：</p><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/nejmoa2035389_f2.webp" class="" title="Moderna疫苗三期临床副作用"><p>副作用平均持续时间，第一针为2.6天，第二针为3.2天。更详细的持续时间数据见表格：</p><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/nejmoa2035389_appendix_page_29.svg" class="" title="Moderna疫苗三期临床副作用持续时间"><p>年轻人比老年人副作用更普遍。有0.2%-0.4%的人在注射后8天以上才开始出现延后的副作用（红斑、肿胀、触痛），这些副作用一般在4-5天之后消失。</p><p>unsolicited副作用情况如图：</p><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/nejmoa2035389_appendix-34.svg" class="" title="Moderna疫苗三期临床unsolicited副作用1"><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/nejmoa2035389_appendix-35.svg" class="" title="Moderna疫苗三期临床unsolicited副作用2"><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/nejmoa2035389_appendix-36.svg" class="" title="Moderna疫苗三期临床unsolicited副作用3"><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/nejmoa2035389_appendix-37.svg" class="" title="Moderna疫苗三期临床unsolicited副作用4"><p>除此之外，[Moderna.8]给出了一些比较严重的延后副作用的额外的数据以及图片：</p><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/nejmc2102131_f1.jpeg" class="" title="Moderna疫苗延后的副作用"><h2 id="BioNTech-Pfizer疫苗-2"><a href="#BioNTech-Pfizer疫苗-2" class="headerlink" title="BioNTech-Pfizer疫苗"></a>BioNTech-Pfizer疫苗</h2><p>BioNTech-Pfizer疫苗三期临床副作用如图所示 [BioNTech-Pfizer.5]：</p><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/nejmoa2034577_f2.webp" class="" title="BioNTech-Pfizer疫苗副作用"><p>疫苗的局部副作用通常会在1-2天内消失。对于系统性的副作用，年轻人比老年人严重，第二针比第一针严重。</p><p>此外，BioNTech-Pfizer疫苗三期临床paper没讲unsolicited副作用，但是FDA报告[BioNTech-Pfizer.16]里面讲了：</p><blockquote><p><em>Serious Adverse Events</em><br>In Study 2, among participants 16 to 55 years of age who had received at least 1 dose of vaccine or placebo(Pfizer-BioNTech COVID-19 Vaccine = 10,841; placebo = 10,851), serious adverse events from Dose 1 through up to 30 days after Dose 2 in ongoing follow-up were reported by 0.4% of Pfizer-BioNTech COVID-19 Vaccine recipients and by 0.3% of placebo recipients. In a similar analysis, in participants 56 years of age and older (Pfizer-BioNTech COVID-19 Vaccine = 7960, placebo = 7934), serious adverse events were reported by 0.8% of Pfizer-BioNTech COVID-19 Vaccine recipients and by 0.6% of placebo recipients who received at least 1 dose of Pfizer-BioNTech COVID-19 Vaccine or placebo, respectively. In these analyses, 91.6% of study participants had at least 30 days of follow-up after Dose 2. Appendicitis was reported as a serious adverse event for 12 participants, and numerically higher in the vaccine group, 8 vaccine participants and 4 placebo participants. Currently available information is insufficient to determine a causal relationship with the vaccine. There were no other notable patterns or numerical imbalances between treatment groups for specific categories of serious adverse events (including neurologic, neuro-inflammatory, and thrombotic events) that would suggest a causal relationship to Pfizer-BioNTech COVID-19 Vaccine.</p><p><em>Non-Serious Adverse Events</em><br>Overall in Study 2 in which 10,841 participants 16 to 55 years of age received Pfizer-BioNTech COVID-19 Vaccine and 10,851 participants received placebo, non-serious adverse events from Dose 1 through up to 30 days after Dose 2 in ongoing follow-up were reported in 29.3% of participants who received Pfizer-BioNTech COVID-19 Vaccine and 13.2% of participants in the placebo group, for participants who received at least 1 dose. Overall in a similar analysis in which 7960 participants 56 years of age and older received Pfizer-BioNTech COVID-19 Vaccine, non-serious adverse events within 30 days were reported in 23.8% of participants who received Pfizer-BioNTech COVID-19 Vaccine and 11.7% of participants in the placebo group, for participants who received at least 1 dose. In these analyses, 91.6% of study participants had at least 30 days of follow-up after Dose 2. The higher frequency of reported unsolicited non-serious adverse events among Pfizer BioNTech COVID-19 Vaccine recipients compared to placebo recipients was primarily attributed to local and systemic adverse events reported during the first 7 days following vaccination that are consistent with adverse reactions solicited among participants in the reactogenicity subset and presented in Tables 3 and 4. From Dose 1 through 30 days after Dose 2, reports of lymphadenopathy were imbalanced with notably more cases in the Pfizer-BioNTech COVID-19 Vaccine group (64) vs. the placebo group (6), which is plausibly related to vaccination. Throughout the safety follow-up period to date, Bell’s palsy (facial paralysis) was reported by four participants in the Pfizer-BioNTech COVID-19 Vaccine group. Onset of facial paralysis was Day 37 after Dose 1 (participant did not receive Dose 2) and Days 3, 9, and 48 after Dose 2. No cases of Bell’s palsy were reported in the placebo group. Currently available information is insufficient to determine a causal relationship with the vaccine. There were no other notable patterns or numerical imbalances between treatment groups for specific categories of non-serious adverse events (including other neurologic or neuroinflammatory, and thrombotic events) that would suggest a causal relationship to Pfizer-BioNTech COVID-19 Vaccine.</p></blockquote><h2 id="Janssen（强生）-2"><a href="#Janssen（强生）-2" class="headerlink" title="Janssen（强生）"></a>Janssen（强生）</h2><p>由于我没找到三期临床的paper，所以数据都来自于FDA的报告 [Janssen.7]。</p><p>局部副作用的比例：</p><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/VRBPAC-02.26.21-Meeting-Briefing-Document-FDA-41.svg" class="" title="强生局部副作用"><p>局部副作用的持续时间：</p><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/VRBPAC-02.26.21-Meeting-Briefing-Document-FDA-42.svg" class="" title="强生局部副作用持续时间"><p>系统性副作用的比例：</p><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/VRBPAC-02.26.21-Meeting-Briefing-Document-FDA-43.svg" class="" title="强生系统性副作用"><p>系统性副作用的持续时间：</p><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/VRBPAC-02.26.21-Meeting-Briefing-Document-FDA-44.svg" class="" title="强生系统性副作用持续时间"><p>Unsolicited：</p><img src="/2021/04/04/Moderna-%E8%BE%89%E7%91%9E-%E4%BB%A5%E5%8F%8A%E5%BC%BA%E7%94%9F%E4%B8%89%E7%A7%8D%E7%96%AB%E8%8B%97%E4%BF%A1%E6%81%AF%E6%80%BB%E7%BB%93/VRBPAC-02.26.21-Meeting-Briefing-Document-FDA-45.svg" class="" title="强生系统性副作用持续时间"><p>此外，FDA报告里面还列举了一些比较有临床意义的unsolicited的副作用，比如血栓。太长了，我就不摘抄了，大家可以自己看[Janssen.7]的45页“Unsolicited Adverse Events of Clinical Interest”这一节。</p><h1 id="危及生命的副作用"><a href="#危及生命的副作用" class="headerlink" title="危及生命的副作用"></a>危及生命的副作用</h1><p>除了三期临床跟FDA报告里面汇报的副作用以外，各路媒体传播的沸沸扬扬的副作用还包括血栓跟血小板减少症。这些副作用跟疫苗是否有关联尚未被医学界确认，并且这些副作用非常罕见。由于新冠本身就有很大的几率导致血小板减少跟血栓，所以即使这些副作用跟疫苗有关，还是值得打疫苗的。但是由于这些副作用一旦发生就非常危险，所以我认为，虽然我们不应该因此就拒绝打疫苗，但是我们还是应该应该了解这些副作用，并且做好相应的准备，以防万一。</p><p>这一小节我并没有参照权威的论文或者教材，而是直接上网上找的资料。（太专业的医学材料我看不懂，所以看的科普向的）</p><h2 id="血小板减少"><a href="#血小板减少" class="headerlink" title="血小板减少"></a>血小板减少</h2><p>来源<a href="https://www.youtube.com/watch?v=CoRIUcZfaqU&ab_channel=%E5%8C%BB%E7%97%B4%E7%9A%84%E6%9C%A8%E5%A4%B4%E5%B1%8B">医痴的木头屋</a>，强烈建议读者自己看一遍这个视频。</p><p><strong>血小板减少症相关的英文是什么？</strong><br>血小板减少症：thrombocytopenia<br>血小板：platelet</p><p><strong>血小板减少症有什么症状？</strong><br>牙龈出血不止，身上不明淤青，鼻血不止，或者别的出血不止、或者嘴里有血泡</p><p><strong>如果我出现了血小板减少症该怎么办？</strong><br>找医生，并要求医生测量血小板。</p><p><strong>打了疫苗以后，有啥注意事项来避免血小板减少症？</strong><br>接种疫苗后，如果发烧的话，不要吃布洛芬，因为布洛芬会降低血小板。</p><h2 id="血栓"><a href="#血栓" class="headerlink" title="血栓"></a>血栓</h2><p>来源<a href="https://www.youtube.com/watch?v=z72f0llsmiU&ab_channel=%E5%8C%BB%E7%97%B4%E7%9A%84%E6%9C%A8%E5%A4%B4%E5%B1%8B">医痴的木头屋</a>，<a href="https://www.youtube.com/watch?v=T6I3QhGfLOo&ab_channel=%E7%86%8A%E7%8C%AB%E5%8C%BB%E8%B0%88">熊猫医谈</a>，强烈建议读者自己看一遍这两个视频。</p><p>疫苗引发的血栓跟普通血栓不一样，疫苗引发的血栓伴随着血小板减少。</p><p><strong>血栓的英文是什么？</strong><br>脑静脉窦血栓：CVST<br>血栓：blood clots</p><p><strong>血栓有什么症状？</strong><br>头疼超过四天，头疼的时候伴随其他症状（比如视觉模糊、重影），或者严重头疼、腹部疼痛、腿痛、呼吸困难。</p><p><strong>如果我出现了血栓该怎么办？</strong><br>找医生，要求做CT跟核磁共振。</p><p><strong>打了疫苗以后，有啥注意事项来避免血栓？</strong><br>接种疫苗以后，避免使用肝素（Heparin）治疗，因为肝素会导致类似情况。</p><h1 id="对比总结"><a href="#对比总结" class="headerlink" title="对比总结"></a>对比总结</h1><p><strong>有效性：</strong></p><table><thead><tr><th></th><th>Moderna三期临床</th><th>BioNTech-Pfizer以色列</th><th>强生三期临床</th></tr></thead><tbody><tr><td>感染</td><td>94%</td><td>94%</td><td>67%</td></tr><tr><td>重症</td><td>100%</td><td>92%</td><td>77%</td></tr></tbody></table><p>除了有效性之外，疫苗诱发的抗体浓度还是很值得关注的，根据<a href="https://www.youtube.com/watch?v=lp9HOHplb_w&t=420s&ab_channel=%E5%8C%BB%E7%97%B4%E7%9A%84%E6%9C%A8%E5%A4%B4%E5%B1%8B">医痴的木头屋</a>，Moderna疫苗产生的抗体是康复病人的4.1倍，BioNTech-Pfizer的则是1.8-3.8倍。（抗体浓度这种医学专业的东西paper我看的不是很明白，所以直接搬运别人的结果了）</p><p><strong>副作用：</strong></p><table><thead><tr><th></th><th>Moderna第一针</th><th>Moderna第二针</th><th>BioNTech-Pfizer第一针</th><th>BioNTech-Pfizer第二针</th><th>强生</th></tr></thead><tbody><tr><td><strong>局部副作用（年轻人）</strong></td><td><strong>N/A</strong></td><td><strong>N/A</strong></td><td><strong>N/A</strong></td><td><strong>N/A</strong></td><td><strong>N/A</strong></td></tr><tr><td>疼痛</td><td>86.9%</td><td>89.9%</td><td>83%</td><td>78%</td><td>58.6%</td></tr><tr><td>触痛</td><td>11.6%</td><td>16.2%</td><td>Unknown</td><td>Unknown</td><td>Unknown</td></tr><tr><td>红斑</td><td>3%</td><td>8.9%</td><td>5%</td><td>6%</td><td>9%</td></tr><tr><td>肿胀</td><td>6.7%</td><td>12.6%</td><td>6%</td><td>6%</td><td>7%</td></tr><tr><td><strong>局部副作用（老年人）</strong></td><td><strong>N/A</strong></td><td><strong>N/A</strong></td><td><strong>N/A</strong></td><td><strong>N/A</strong></td><td><strong>N/A</strong></td></tr><tr><td>疼痛</td><td>74%</td><td>83.2%</td><td>71%</td><td>66%</td><td>33.3%</td></tr><tr><td>触痛</td><td>6.1%</td><td>8.5%</td><td>Unknown</td><td>Unknown</td><td>Unknown</td></tr><tr><td>红斑</td><td>2.3%</td><td>7.5%</td><td>5%</td><td>7%</td><td>4.6%</td></tr><tr><td>肿胀</td><td>4.4%</td><td>10.8%</td><td>7%</td><td>7%</td><td>2.7%</td></tr><tr><td><strong>系统性副作用（年轻人）</strong></td><td><strong>N/A</strong></td><td><strong>N/A</strong></td><td><strong>N/A</strong></td><td><strong>N/A</strong></td><td><strong>N/A</strong></td></tr><tr><td>发烧</td><td>0.9%</td><td>17.4%</td><td>4%</td><td>16%</td><td>12.8%</td></tr><tr><td>头疼</td><td>35.3%</td><td>62.8%</td><td>42%</td><td>52%</td><td>44.4%</td></tr><tr><td>疲劳</td><td>38.4%</td><td>67.6%</td><td>47%</td><td>59%</td><td>43.8%</td></tr><tr><td>肌痛</td><td>23.7%</td><td>61%</td><td>21%</td><td>37%</td><td>39.1%</td></tr><tr><td>关节痛</td><td>16.6%</td><td>45.5%</td><td>11%</td><td>22%</td><td>Unknown</td></tr><tr><td>恶心/呕吐</td><td>9.4%</td><td>21.4%</td><td>1%</td><td>2%</td><td>15.5%</td></tr><tr><td>腹泻</td><td>Unknown</td><td>Unknown</td><td>11%</td><td>10%</td><td>Unknown</td></tr><tr><td>寒冷</td><td>9.2%</td><td>48.6%</td><td>14%</td><td>35%</td><td>Unknown</td></tr><tr><td>使用退烧药/止疼药</td><td>Unknown</td><td>Unknown</td><td>28%</td><td>45%</td><td>26.4%</td></tr><tr><td><strong>系统性副作用（老年人）</strong></td><td><strong>N/A</strong></td><td><strong>N/A</strong></td><td><strong>N/A</strong></td><td><strong>N/A</strong></td><td><strong>N/A</strong></td></tr><tr><td>发烧</td><td>0.3%</td><td>10%</td><td>1%</td><td>11%</td><td>3.1%</td></tr><tr><td>头疼</td><td>24.5%</td><td>46.2%</td><td>25%</td><td>39%</td><td>30.4%</td></tr><tr><td>疲劳</td><td>33.3%</td><td>58.3%</td><td>34%</td><td>51%</td><td>29.7%</td></tr><tr><td>肌痛</td><td>19.7%</td><td>47.1%</td><td>14%</td><td>29%</td><td>24%</td></tr><tr><td>关节痛</td><td>16.4%</td><td>35%</td><td>9%</td><td>19%</td><td>Unknown</td></tr><tr><td>恶心/呕吐</td><td>5.2%</td><td>11.8%</td><td>0%</td><td>1%</td><td>12.3%</td></tr><tr><td>腹泻</td><td>Unknown</td><td>Unknown</td><td>8%</td><td>8%</td><td>Unknown</td></tr><tr><td>寒冷</td><td>5.4%</td><td>30.9%</td><td>6%</td><td>23%</td><td>Unknown</td></tr><tr><td>使用退烧药/止疼药</td><td>Unknown</td><td>Unknown</td><td>20%</td><td>38%</td><td>9.8%</td></tr></tbody></table><p>从上面的数据来看，Moderna疫苗最有效，副作用也最大。BioNTech-Pfizer有效性稍逊Moderna，但是副作用低了不少。强生疫苗效果要弱很多，副作用也要弱一些。</p><p>我个人的选择是：打BioNTech-Pfizer或者Moderna，这两个不要挑，哪个能预约上就先打哪个。至于不选强生的原因，除了效果不好以外，还有很重要的两点：</p><ol><li>看新闻说这两种mRNA疫苗药厂已经在研发针对变种病毒的第三针了。这两种疫苗用到的mRNA-LNP技术，比起其他疫苗技术，非常适合快速研发以及快速大规模生产。快速研发意味着，我们可以期待第三针的临床实验会很快完成。快速大规模生产意味着，研发完成了以后，优先级比较低的人群也能早早排上。</li><li>强生疫苗的病毒载体Ad26本身也会引发免疫反应。如果将来因为变种病毒我们需要打第二针甚至第三针强生疫苗，到时候体内已经产生了Ad26的抗体，很有可能载体到达细胞之前就被消灭了，这样子效果会大打折扣。（观点来自 <a href="https://www.youtube.com/watch?v=crLws_yLQP0&ab_channel=%E7%86%8A%E7%8C%AB%E5%8C%BB%E8%B0%88">熊猫医谈</a>）</li></ol><p>需要注意的是，mRNA疫苗接种完第一针以后，有效性只有50%左右。即使接种完第二针，有效性也不是立马就能产生，而是需要一段时间。所以还是应该等接种完第二针14天之后再从事各种活动也不迟。</p><p>疫苗会有一些发烧疼痛之类的副作用，但都不致命，忍一忍就过去了，如果严重就去找医生。如果发烧的话，退烧药建议不要吃布洛芬，而是吃别的退烧药（我家里备的是泰诺），因为布洛芬会减少血小板。</p><p>疫苗接种过程中，有发现一些比较严重的可能致命的副作用。这些副作用跟疫苗是否有关尚不清楚，而且即使有关，考虑到这些副作用极其罕见，跟新冠的死亡率比，还是完全应该打疫苗的。只是我们应该做好最坏的打算，了解一下相关的知识也是应该的。</p><p>如果你接种疫苗以后，出现牙龈出血不止，身上不明淤青，鼻血不止，嘴里有血泡，或者别的出血不止等症状，这有可能是血小板减少症，请看医生，并要求医生测量你的血小板。这两个单词的英文是：血小板减少症：thrombocytopenia，血小板：platelet。</p><p>另外，如果你接种疫苗以后头疼超过四天，或者头疼的同时伴有其他症状（比如视觉模糊、重影），或者严重头疼、腹部疼痛、腿痛、呼吸困难，那么有可能是血栓，请找医生，要求做CT跟核磁共振。相关的英文为：脑静脉窦血栓：CVST，血栓：blood clots。</p><h1 id="致谢"><a href="#致谢" class="headerlink" title="致谢"></a>致谢</h1><p>我之前一直关注一个YouTube频道叫做“医痴的木头屋”，作者是加州的注册药剂师江博士。江博士一直在YouTube上对新冠进行科普。我对新冠以及新冠疫苗的大部分信息，都是来自江博士的科普。正是看了这些科普，我才会对新冠以及新冠疫苗有很好的宏观认识，这样才能在自己阅读paper的时候，知道该看哪些paper，该关注哪些点。医学的专业paper，对于我一个物理本科+理论化学PhD+现在从事计算机的人来讲，阅读起来门槛还是很高的，如果不是看过这么多科普的视频，我觉得我是没办法自己完全从头扒这一堆paper来获取自己想要的信息的。频道地址：<br><a href="https://www.youtube.com/channel/UCR2f5HSx_E06HK6LzSzQQ5g">https://www.youtube.com/channel/UCR2f5HSx_E06HK6LzSzQQ5g</a></p><p>另外，还有一个叫做熊猫医谈的频道也很不错：<br><a href="https://www.youtube.com/channel/UC2eAakZz8c8zBWJAw6_Mo9A/videos">https://www.youtube.com/channel/UC2eAakZz8c8zBWJAw6_Mo9A/videos</a><br>我在本文中也引用了一些这上面的分析。</p><h1 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h1><h2 id="General"><a href="#General" class="headerlink" title="General"></a>General</h2><ol><li>Guidance for Industry: Toxicity Grading Scale for Healthy Adult and Adolescent Volunteers Enrolled in Preventive Vaccine Clinical Trials <a href="https://www.fda.gov/media/73679/download">https://www.fda.gov/media/73679/download</a></li><li>National Cancer Institute Common Toxicity Criteria, April 30, 1999.  <a href="https://ctep.cancer.gov/protocoldevelopment/electronic_applications/ctc.htm">https://ctep.cancer.gov/protocoldevelopment/electronic_applications/ctc.htm</a></li><li>The coronavirus is mutating — does it matter? <a href="https://www.nature.com/articles/d41586-020-02544-6">https://www.nature.com/articles/d41586-020-02544-6</a></li><li>疫苗研發的臨床參考要點 - 財團法人醫藥品查驗中心 <a href="https://www.cde.org.tw/Content/Files/Knowledge/64cb33f4-1e55-4d38-b527-f3fbb236e39b.pdf">https://www.cde.org.tw/Content/Files/Knowledge/64cb33f4-1e55-4d38-b527-f3fbb236e39b.pdf</a></li><li>Huang, Yuan, et al. “Structural and functional properties of SARS-CoV-2 spike protein: potential antivirus drug development for COVID-19.” Acta Pharmacologica Sinica 41.9 (2020): 1141-1149. <a href="https://www.nature.com/articles/s41401-020-0485-4">https://www.nature.com/articles/s41401-020-0485-4</a></li><li>Reichmuth, Andreas M., et al. “mRNA vaccine delivery using lipid nanoparticles.” Therapeutic delivery 7.5 (2016): 319-334. <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5439223/">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5439223/</a></li><li>Pinschewer, Daniel D. “Virally vectored vaccine delivery: medical needs, mechanisms, advantages and challenges.” Swiss medical weekly 147.3132 (2017). <a href="https://smw.ch/article/doi/smw.2017.14465">https://smw.ch/article/doi/smw.2017.14465</a></li></ol><h2 id="Moderna-3"><a href="#Moderna-3" class="headerlink" title="Moderna"></a>Moderna</h2><p>官方列表：</p><ul><li><a href="https://www.modernatx.com/covid-19-resources/publications-and-external-resources">https://www.modernatx.com/covid-19-resources/publications-and-external-resources</a></li></ul><p>官方列表不全，只有临床前研究跟一期临床实验？Moderna这坑货，不更新主页的吗？太懒了吧。。。动物实验我就不看了，一期临床试验倒是可以看一看。。。</p><p>文献：</p><ol><li>设计：Corbett, Kizzmekia S., et al. “SARS-CoV-2 mRNA vaccine design enabled by prototype pathogen preparedness.” Nature 586.7830 (2020): 567-571.  <a href="https://www.nature.com/articles/s41586-020-2622-0">https://www.nature.com/articles/s41586-020-2622-0</a></li><li>一期临床年轻人：Jackson, Lisa A., et al. “An mRNA vaccine against SARS-CoV-2—preliminary report.” New England Journal of Medicine (2020). <a href="https://www.nejm.org/doi/full/10.1056/NEJMoa2022483">https://www.nejm.org/doi/full/10.1056/NEJMoa2022483</a></li><li>一期临床老人：Anderson, Evan J., et al. “Safety and immunogenicity of SARS-CoV-2 mRNA-1273 vaccine in older adults.” New England Journal of Medicine 383.25 (2020): 2427-2438.  <a href="https://www.nejm.org/doi/full/10.1056/NEJMoa2028436">https://www.nejm.org/doi/full/10.1056/NEJMoa2028436</a></li><li>二期临床：Chu, Laurence, et al. “A preliminary report of a randomized controlled phase 2 trial of the safety and immunogenicity of mRNA-1273 SARS-CoV-2 vaccine.” Vaccine (2021). <a href="https://www.sciencedirect.com/science/article/pii/S0264410X21001535#">https://www.sciencedirect.com/science/article/pii/S0264410X21001535#</a>!</li><li>三期临床：Baden, Lindsey R., et al. “Efficacy and safety of the mRNA-1273 SARS-CoV-2 vaccine.” New England Journal of Medicine 384.5 (2021): 403-416.  <a href="https://www.nejm.org/doi/full/10.1056/nejmoa2035389">https://www.nejm.org/doi/full/10.1056/nejmoa2035389</a></li><li>变种病毒的研究：Wu, Kai, et al. “Serum Neutralizing Activity Elicited by mRNA-1273 Vaccine.” New England Journal of Medicine (2021).  <a href="https://www.nejm.org/doi/full/10.1056/NEJMc2102179">https://www.nejm.org/doi/full/10.1056/NEJMc2102179</a></li><li>疫苗时效性：Widge, Alicia T., et al. “Durability of responses after SARS-CoV-2 mRNA-1273 vaccination.” New England Journal of Medicine 384.1 (2021): 80-82.  <a href="https://www.nejm.org/doi/full/10.1056/NEJMc2032195">https://www.nejm.org/doi/full/10.1056/NEJMc2032195</a></li><li>副作用：Blumenthal, Kimberly G., et al. “Delayed Large Local Reactions to mRNA-1273 Vaccine against SARS-CoV-2.” New England Journal of Medicine (2021).  <a href="https://www.nejm.org/doi/full/10.1056/NEJMc2102131">https://www.nejm.org/doi/full/10.1056/NEJMc2102131</a></li><li>疫苗时效性：Doria-Rose, Nicole, et al. “Antibody Persistence through 6 Months after the Second Dose of mRNA-1273 Vaccine for Covid-19.” New England Journal of Medicine (2021).</li></ol><p>疑问：Moderna的二期临床为啥这么没有存在感？没有发表在顶刊上，也没怎么被引用。三期临床的paper [Moderna.4] 在引用前期结果的时候，只引用了 [Moderna.2, Moderna.3]。看Moderna官方的新闻稿，似乎确实是一期临床做完了就直接三期了：<a href="https://investors.modernatx.com/news-releases/news-release-details/moderna-announces-expansion-barda-agreement-support-larger-phase">https://investors.modernatx.com/news-releases/news-release-details/moderna-announces-expansion-barda-agreement-support-larger-phase</a></p><h2 id="BioNTech-Pfizer"><a href="#BioNTech-Pfizer" class="headerlink" title="BioNTech-Pfizer"></a>BioNTech-Pfizer</h2><p>官方列表:</p><ul><li><a href="https://biontech.de/science/publications">https://biontech.de/science/publications</a></li><li><a href="https://www.pfizer.com/science/coronavirus">https://www.pfizer.com/science/coronavirus</a></li></ul><p>文献：</p><p>动物实验就不看了。。。另外，英国政府又在作妖了，说是第二针延后打。然后就有一些相关的研究。。。我一向看不惯英国政府搞出来的政策，先是群体免疫，后来又是延迟接种。相关的研究我也不看了，反正在美国都是正常打的。</p><ol><li>动物实验：Vogel, Annette B., et al. “BNT162b vaccines protect rhesus macaques from SARS-CoV-2.” Nature (2021): 1-7.  <a href="https://www.nature.com/articles/s41586-021-03275-y">https://www.nature.com/articles/s41586-021-03275-y</a></li><li>一/二期临床：Mulligan, Mark J., et al. “Phase I/II study of COVID-19 RNA vaccine BNT162b1 in adults.” Nature 586.7830 (2020): 589-593.  <a href="https://www.nature.com/articles/s41586-020-2639-4">https://www.nature.com/articles/s41586-020-2639-4</a></li><li>一/二期临床抗体：Sahin, Ugur, et al. “COVID-19 vaccine BNT162b1 elicits human antibody and TH1 T cell responses.” Nature 586.7830 (2020): 594-599.  <a href="https://www.nature.com/articles/s41586-020-2814-7">https://www.nature.com/articles/s41586-020-2814-7</a></li><li>疫苗选择：Walsh, Edward E., et al. “Safety and immunogenicity of two RNA-based Covid-19 vaccine candidates.” New England Journal of Medicine 383.25 (2020): 2439-2450.  <a href="https://www.nejm.org/doi/full/10.1056/NEJMoa2027906">https://www.nejm.org/doi/full/10.1056/NEJMoa2027906</a></li><li>三期临床：Polack, Fernando P., et al. “Safety and efficacy of the BNT162b2 mRNA Covid-19 vaccine.” New England Journal of Medicine 383.27 (2020): 2603-2615.  <a href="https://www.nejm.org/doi/full/10.1056/NEJMoa2034577">https://www.nejm.org/doi/full/10.1056/NEJMoa2034577</a></li><li>以色列数据：Dagan, Noa, et al. “BNT162b2 mRNA Covid-19 vaccine in a nationwide mass vaccination setting.” New England Journal of Medicine (2021).  <a href="https://www.nejm.org/doi/10.1056/NEJMoa2101765">https://www.nejm.org/doi/10.1056/NEJMoa2101765</a></li><li>变种病毒：Xie, Xuping, et al. “Neutralization of SARS-CoV-2 spike 69/70 deletion, E484K and N501Y variants by BNT162b2 vaccine-elicited sera.” Nature Medicine (2021): 1-2.  <a href="https://www.nature.com/articles/s41591-021-01270-4">https://www.nature.com/articles/s41591-021-01270-4</a></li><li>变种病毒：Liu, Yang, et al. “Neutralizing activity of BNT162b2-elicited serum.” New England Journal of Medicine (2021).  <a href="https://www.nejm.org/doi/full/10.1056/NEJMc2102017">https://www.nejm.org/doi/full/10.1056/NEJMc2102017</a></li><li>变种病毒：Muik, Alexander, et al. “Neutralization of SARS-CoV-2 lineage B.1.1.7 pseudovirus by BNT162b2 vaccine–elicited human sera.” Science 371.6534 (2021): 1152-1153.  <a href="https://science.sciencemag.org/content/371/6534/1152.abstract">https://science.sciencemag.org/content/371/6534/1152.abstract</a></li><li>变种病毒：Zou, Jing, et al. “The effect of SARS-CoV-2 D614G mutation on BNT162b2 vaccine-elicited neutralization.” npj Vaccines 6.1 (2021): 1-4.  <a href="https://www.nature.com/articles/s41541-021-00313-8">https://www.nature.com/articles/s41541-021-00313-8</a></li><li>医护人员数据：Benenson, Shmuel, et al. “BNT162b2 mRNA Covid-19 Vaccine Effectiveness among Health Care Workers.” New England Journal of Medicine (2021).  <a href="https://www.nejm.org/doi/full/10.1056/NEJMc2101951">https://www.nejm.org/doi/full/10.1056/NEJMc2101951</a></li><li>病毒传播：Levine-Tiefenbrun, Matan, et al. “Initial report of decreased SARS-CoV-2 viral load after inoculation with the BNT162b2 vaccine.” Nature Medicine (2021): 1-3.  <a href="https://www.nature.com/articles/s41591-021-01316-7">https://www.nature.com/articles/s41591-021-01316-7</a></li><li>第二针啥时候打：Prendecki, Maria, et al. “Effect of previous SARS-CoV-2 infection on humoral and T-cell responses to single-dose BNT162b2 vaccine.” The Lancet 397.10280 (2021): 1178-1181.  <a href="https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(21)00502-X/fulltext">https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(21)00502-X/fulltext</a></li><li>第二针啥时候打：Robertson, John FR, Herb F. Sewell, and Marcia Stewart. “Delayed second dose of the BNT162b2 vaccine: innovation or misguided conjecture?.” The Lancet 397.10277 (2021): 879-880.  <a href="https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(21)00455-4/fulltext">https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(21)00455-4/fulltext</a></li><li>第二针啥时候打：Manisty, Charlotte, et al. “Antibody response to first BNT162b2 dose in previously SARS-CoV-2-infected individuals.” The Lancet 397.10279 (2021): 1057-1058.  <a href="https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(21)00501-8/fulltext">https://www.thelancet.com/journals/lancet/article/PIIS0140-6736(21)00501-8/fulltext</a></li><li>FDA报告：EMERGENCY USE AUTHORIZATION (EUA) OF THE PFIZER-BIONTECH COVID-19 VACCINE TO PREVENT CORONAVIRUS DISEASE 2019 (COVID-19) <a href="https://www.fda.gov/media/144413/download">https://www.fda.gov/media/144413/download</a></li></ol><h2 id="Janssen（强生）-3"><a href="#Janssen（强生）-3" class="headerlink" title="Janssen（强生）"></a>Janssen（强生）</h2><p>我去Google Scholar里面搜索Ad26.COV2.S，感觉找到的结果好少，在Janssen公司的官网也没发现啥publication的list。所以是因为强生公司没有发paper的习惯？还是因为我漏掉了？我甚至连三期临床的paper都没找到，只是找到了fda的报告。将就着也能看吧。</p><ol><li>动物实验：Mercado, Noe B., et al. “Single-shot Ad26 vaccine protects against SARS-CoV-2 in rhesus macaques.” Nature 586.7830 (2020): 583-588. <a href="https://www.nature.com/articles/s41586-020-2607-z?elqTrackId=4a779cff52a6429c991dcd18014ea740">https://www.nature.com/articles/s41586-020-2607-z?elqTrackId=4a779cff52a6429c991dcd18014ea740</a></li><li>动物实验：van der Lubbe, Joan EM, et al. “Ad26. COV2. S protects Syrian hamsters against G614 spike variant SARS-CoV-2 and does not enhance respiratory disease.” npj Vaccines 6.1 (2021): 1-12. <a href="https://www.nature.com/articles/s41541-021-00301-y">https://www.nature.com/articles/s41541-021-00301-y</a></li><li>动物实验：Tostanoski, Lisa H., et al. “Ad26 vaccine protects against SARS-CoV-2 severe clinical disease in hamsters.” Nature medicine 26.11 (2020): 1694-1700. <a href="https://www.nature.com/articles/s41591-020-1070-6">https://www.nature.com/articles/s41591-020-1070-6</a></li><li>设计：Bos, Rinke, et al. “Ad26 vector-based COVID-19 vaccine encoding a prefusion-stabilized SARS-CoV-2 Spike immunogen induces potent humoral and cellular immune responses.” npj Vaccines 5.1 (2020): 1-11. <a href="https://www.nature.com/articles/s41541-020-00243-x">https://www.nature.com/articles/s41541-020-00243-x</a></li><li>一期临床：Stephenson, Kathryn E., et al. “Immunogenicity of the Ad26. COV2. S Vaccine for COVID-19.” JAMA (2021). <a href="https://jamanetwork.com/journals/jama/article-abstract/2777598">https://jamanetwork.com/journals/jama/article-abstract/2777598</a></li><li>1–2a期临床：Sadoff, Jerald, et al. “Interim Results of a Phase 1–2a Trial of Ad26. COV2. S Covid-19 Vaccine.” New England Journal of Medicine (2021). <a href="https://www.nejm.org/doi/full/10.1056/NEJMoa2034201">https://www.nejm.org/doi/full/10.1056/NEJMoa2034201</a></li><li>FDA报告：Vaccines and Related Biological Products Advisory Committee Meeting： <a href="https://www.fda.gov/media/146217/download">https://www.fda.gov/media/146217/download</a></li></ol>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;前言&quot;&gt;&lt;a href=&quot;#前言&quot; class=&quot;headerlink&quot; title=&quot;前言&quot;&gt;&lt;/a&gt;前言&lt;/h1&gt;&lt;p&gt;在4.15日加州全面放开打疫苗前，花时间整理了一下各个疫苗的相关数据跟结论。虽然我没有任何医学或者生物学背景，但是我毕竟也有博士学位，一点基础的科研思维还是有的，看这些东西，对我本人是有益的，可以让我知道what to expect以及what not to expect。我把我自己读paper的笔记写成文章，除了自己日后查阅方便以外，一方面是希望省去有同样需求的人从头找文献的一丁点麻烦；另一方面则是如果有医学专业的人士看到我的笔记，可以帮我指出其中的不足或者疏忽，这样子也能加深我本人的理解。&lt;/p&gt;
&lt;p&gt;&lt;em&gt;本人并非医学专业，所以请带着批判性思维来阅读本文章。如发现错误或者遗漏，欢迎指正。&lt;/em&gt;&lt;/p&gt;
&lt;h1 id=&quot;简介&quot;&gt;&lt;a href=&quot;#简介&quot; class=&quot;headerlink&quot; title=&quot;简介&quot;&gt;&lt;/a&gt;简介&lt;/h1&gt;&lt;p&gt;（TLDR可以直接跳过文章看总结。）&lt;/p&gt;
&lt;p&gt;本文主要总结的Moderna、辉瑞、强生三种疫苗的三期临床数据，以及一些跟副作用以及有效性相关的后续研究。这些研究里面，最常用的有两种研究手段：&lt;/p&gt;
&lt;p&gt;一种是通过临床实验，得出统计规律。这种研究一般来讲，就是让大量的人注射疫苗。然后统计一下这些人里面，都有谁得了新冠。然后就可以记录下来，得了新冠的人里面，有多少是接种了疫苗的，多少是没有接种疫苗的，以及多少人会接种部位疼痛，多少人会发烧，等等数据。最后根据数据就能算出来比例。&lt;/p&gt;
&lt;p&gt;另一种则是病毒中和实验。这种实验就有点类似中学化学里面学的滴定实验。这种实验的做法，是取接种者的血浆，然后拿着这些血浆来中和病毒。如果疫苗非常有效的话，血浆中会含有大量的抗体。这种情况下，血浆是可以直接中和掉所有的病毒的。这个时候，要定量研究血浆的有效性，就需要对血浆进行稀释，一直稀释到血浆只能中和一半病毒为止。这个时候稀释的倍数，就叫做滴度（titer）。显然，血浆中的抗体浓度越高/抗体越有效，需要稀释的倍数就更高，滴度就更大。对于变种病毒来讲，变种导致抗体的有效性降低了，对应到这个实验上，就是滴度降低了。&lt;/p&gt;</summary>
    
    
    
    <category term="新冠" scheme="https://zasdfgbnm.github.io/categories/%E6%96%B0%E5%86%A0/"/>
    
    
    <category term="疫苗" scheme="https://zasdfgbnm.github.io/tags/%E7%96%AB%E8%8B%97/"/>
    
    <category term="新冠" scheme="https://zasdfgbnm.github.io/tags/%E6%96%B0%E5%86%A0/"/>
    
    <category term="Moderna" scheme="https://zasdfgbnm.github.io/tags/Moderna/"/>
    
    <category term="辉瑞" scheme="https://zasdfgbnm.github.io/tags/%E8%BE%89%E7%91%9E/"/>
    
    <category term="Pfizer" scheme="https://zasdfgbnm.github.io/tags/Pfizer/"/>
    
    <category term="BioNTech" scheme="https://zasdfgbnm.github.io/tags/BioNTech/"/>
    
    <category term="mRNA" scheme="https://zasdfgbnm.github.io/tags/mRNA/"/>
    
    <category term="强生" scheme="https://zasdfgbnm.github.io/tags/%E5%BC%BA%E7%94%9F/"/>
    
    <category term="副作用" scheme="https://zasdfgbnm.github.io/tags/%E5%89%AF%E4%BD%9C%E7%94%A8/"/>
    
    <category term="有效性" scheme="https://zasdfgbnm.github.io/tags/%E6%9C%89%E6%95%88%E6%80%A7/"/>
    
    <category term="Janssen" scheme="https://zasdfgbnm.github.io/tags/Janssen/"/>
    
    <category term="COVID-19" scheme="https://zasdfgbnm.github.io/tags/COVID-19/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch JIT Source Code Read Note (Updated at Feb 2020)</title>
    <link href="https://zasdfgbnm.github.io/2020/02/07/PyTorch-JIT-Source-Code-Read-Note-Updated-202002/"/>
    <id>https://zasdfgbnm.github.io/2020/02/07/PyTorch-JIT-Source-Code-Read-Note-Updated-202002/</id>
    <published>2020-02-07T19:00:00.000Z</published>
    <updated>2021-04-04T05:17:59.764Z</updated>
    
    <content type="html"><![CDATA[<p>This is my note for reading PyTorch’s JIT source. We begin by looking at <code>torch.jit.script</code> to find the frontend that compiles the Python code into PyTorch’s tree views, and the backend that compiles tree views to graph. We also read the structure of the internal representation of PyTorch’s graph. Finally we go to graph executor to look at how the computation graph is further compiled into instructions and how the action of these instructions are defined and executed.</p><span id="more"></span><p>PyTorch is under very active development. So the PyTorch’s source code at the time the reader reading this article won’t be the same as when I wrote this article. To get the same source code as in this article, the readers could run the following command:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout c6fa6d82aebc1dcd7561ea29ec5d41c5a211bae1</span><br></pre></td></tr></table></figure><h1 id="Starting-point-torch-jit-script"><a href="#Starting-point-torch-jit-script" class="headerlink" title="Starting point: torch.jit.script"></a>Starting point: torch.jit.script</h1><p>In PyTorch, a Python function can be just-in-time compiled by doing something like:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@torch.jit.script</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x + x</span><br></pre></td></tr></table></figure><p>the <code>torch.jit.script</code> is a decorator of your function <code>f</code>. If you are unfamiliar with Python’s decorator, please refer to <a href="https://realpython.com/primer-on-python-decorators/">this article</a>.</p><p>We will start by looking at <code>torch.jit.script</code>. To read <code>torch.jit.script</code>, we begin by looking at <code>torch/jit/__init__.py</code>. To quickly locate <code>script</code>, search <code>def script</code> in your editor, and you will immediately find it:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">script</span>(<span class="params">obj, optimize=<span class="literal">True</span>, _frames_up=<span class="number">0</span></span>):</span></span><br><span class="line">    ....</span><br><span class="line">    <span class="keyword">if</span> inspect.isclass(obj):</span><br><span class="line">      ...</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">      _check_directly_compile_overloaded(obj)</span><br><span class="line">      maybe_already_compiled_fn = _try_get_jit_cached_function(obj)</span><br><span class="line">      <span class="keyword">if</span> maybe_already_compiled_fn:</span><br><span class="line">          <span class="keyword">return</span> maybe_already_compiled_fn</span><br><span class="line">      ast = get_jit_def(obj)</span><br><span class="line">      <span class="keyword">if</span> _rcb <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">          _rcb = _jit_internal.createResolutionCallbackFromClosure(obj)</span><br><span class="line">      fn = torch._C._jit_script_compile(qualified_name, ast, _rcb, get_default_args(obj))</span><br><span class="line">      <span class="comment"># Forward docstrings</span></span><br><span class="line">      fn.__doc__ = obj.__doc__</span><br><span class="line">      _set_jit_function_cache(obj, fn)</span><br><span class="line">      <span class="keyword">return</span> fn</span><br></pre></td></tr></table></figure><p>Here we want to quickly get a big picture of <code>torch.jit</code>, so we will only look at how a function is compiled. We will ignore the compilation of a module or class, etc.</p><p>The core of the above code is this four lines</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ast = get_jit_def(obj)</span><br><span class="line"><span class="keyword">if</span> _rcb <span class="keyword">is</span> <span class="literal">None</span>:</span><br><span class="line">    _rcb = _jit_internal.createResolutionCallbackFromClosure(obj)</span><br><span class="line">fn = torch._C._jit_script_compile(qualified_name, ast, _rcb, get_default_args(obj))</span><br></pre></td></tr></table></figure><p>Just by reading the English, we can tell that what it does is roughly get the abstract syntax tree(AST) and then call <code>torch._C._jit_script_compile</code> to compile it to PyTorch’s internal representation.</p><p>From the beginning of <code>__init__.py</code>, we know that <code>get_jit_def</code> is imported from <code>torch.jit.frontend</code>. From the name of this function and its owning module, we can tell that this is the frontend of PyTorch’s JIT compiler that compiles the source code of the scripted function into AST.</p><p>Then <code>createResolutionCallbackFromClosure</code> is called. This function is from <code>_jit_internal.py</code>, by looking at its definition and the codes around, we can tell that it roughly gets the symbols available to the function so that they could be accessed through C++ when executing the graph. We will not go into details about how this works.</p><p>The next line uses <code>torch._C._jit_script_compile</code> to compiles the AST obtained in the previous step into computation graph. The <code>torch._C</code> tells us that <code>_jit_script_compile</code> is implemented in C++.</p><h1 id="The-Python-frontend"><a href="#The-Python-frontend" class="headerlink" title="The Python frontend"></a>The Python frontend</h1><p>A good starting point of the frontend is the <code>get_jit_def</code> we just saw. This function is defined at <code>torch/jit/frontend.py</code>. The code is:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_jit_def</span>(<span class="params">fn, self_name=<span class="literal">None</span></span>):</span></span><br><span class="line">    sourcelines, file_lineno, filename = get_source_lines_and_file(fn)</span><br><span class="line">    source = <span class="string">&#x27;&#x27;</span>.join(sourcelines)</span><br><span class="line">    dedent_src = dedent(source)</span><br><span class="line">    py_ast = ast.parse(dedent_src)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(py_ast.body) != <span class="number">1</span> <span class="keyword">or</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(py_ast.body[<span class="number">0</span>], ast.FunctionDef):</span><br><span class="line">        <span class="keyword">raise</span> RuntimeError(<span class="string">&quot;Expected a single top-level function&quot;</span>)</span><br><span class="line">    leading_whitespace_len = <span class="built_in">len</span>(source.split(<span class="string">&#x27;\n&#x27;</span>, <span class="number">1</span>)[<span class="number">0</span>]) - <span class="built_in">len</span>(dedent_src.split(<span class="string">&#x27;\n&#x27;</span>, <span class="number">1</span>)[<span class="number">0</span>])</span><br><span class="line">    type_line = torch.jit.annotations.get_type_line(source)</span><br><span class="line">    ctx = SourceContext(source, filename, file_lineno, leading_whitespace_len, _uses_true_division(fn))</span><br><span class="line">    <span class="keyword">return</span> build_def(ctx, py_ast.body[<span class="number">0</span>], type_line, self_name)</span><br></pre></td></tr></table></figure><p>The first 7 lines of function body just use the standard tools provided by Python, <code>dedent</code>, <code>inspect</code>, and <code>ast</code>, to construct the Python AST, do some check to make sure the thing being compiled is “a single top-level function”, as well as getting the position, line numbers, etc. so that useful information could be printted to the user for debugging when there is an error.</p><p>The following line <code>type_line = torch.jit.annotations.get_type_line(source)</code> is interesting. After looking at <code>torch/jit/annotations.py</code>, we can see that PyTorch’s JIT allows the user to specify the type of arguments and return value by writing something like <code># type: (Tensor, torch.Tensor) -&gt; Tuple[Tensor, Tensor]</code>.</p><p>In the next line <code>ctx = SourceContext(.....)</code>, the <code>_uses_true_division</code> is defined in the same file to handle the different behavior of <code>/</code> in Python2 with or without <code>from __future__ import division</code> (see <a href="https://www.python.org/dev/peps/pep-0238/">PEP 238</a> for the difference). The <code>SourceContext</code> is also defined in the same file. It is a subclass of <code>SourceRangeFactory</code> with additional field to store if the division is true division. The <code>SourceRangeFactory</code> is imported by <code>from torch._C._jit_tree_views import *</code>. After reading its definition at <code>torch/csrc/jit/script/python_tree_views.cpp</code>, we can see that this is basically a class designed to store the range of source code, e.g. where in the source code a token is located.</p><p>The core is the <code>build_def</code> in the last line, so we move on:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_def</span>(<span class="params">ctx, py_def, type_line, self_name=<span class="literal">None</span></span>):</span></span><br><span class="line">    body = py_def.body</span><br><span class="line">    r = ctx.make_range(py_def.lineno + <span class="built_in">len</span>(py_def.decorator_list),</span><br><span class="line">                       py_def.col_offset,</span><br><span class="line">                       py_def.col_offset + <span class="built_in">len</span>(<span class="string">&quot;def&quot;</span>))</span><br><span class="line">    param_list = build_param_list(ctx, py_def.args, self_name)</span><br><span class="line">    return_type = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">getattr</span>(py_def, <span class="string">&#x27;returns&#x27;</span>, <span class="literal">None</span>) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        return_type = build_expr(ctx, py_def.returns)</span><br><span class="line">    decl = Decl(r, param_list, return_type)</span><br><span class="line">    is_method = self_name <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> type_line <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        type_comment_decl = torch._C.parse_type_comment(type_line)</span><br><span class="line">        decl = torch._C.merge_type_from_type_comment(decl, type_comment_decl, is_method)</span><br><span class="line">    <span class="keyword">return</span> Def(Ident(r, py_def.name),</span><br><span class="line">               decl,</span><br><span class="line">               build_stmts(ctx, body))</span><br></pre></td></tr></table></figure><p>Reading through this, we can see that what basically this does is to convert the Python’s AST into the internal representation. Names like <code>Decl</code>, <code>Def</code>, <code>Ident</code> are all imported by <code>from torch._C._jit_tree_views import *</code>. In the last line, we can see that the function body is constructed by <code>build_stmts</code>, so let’s go further to read <code>build_stmts</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_stmts</span>(<span class="params">ctx, stmts</span>):</span></span><br><span class="line">    stmts = [build_stmt(ctx, s) <span class="keyword">for</span> s <span class="keyword">in</span> stmts]</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">filter</span>(<span class="literal">None</span>, stmts))</span><br></pre></td></tr></table></figure><p>This is a very simple function: call <code>build_stmt</code> for each item and filter out those not needed. But what is <code>build_stmt</code>? It is defined as: <code>build_stmt = StmtBuilder()</code>. The definition of <code>StmtBuilder</code> looks like:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StmtBuilder</span>(<span class="params">Builder</span>):</span></span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_Expr</span>(<span class="params">ctx, stmt</span>):</span></span><br><span class="line">        value = stmt.value</span><br><span class="line">        <span class="keyword">if</span> value.__class__.__name__ == <span class="string">&#x27;Str&#x27;</span>:</span><br><span class="line">            <span class="comment"># If a statement is a string literal expression,</span></span><br><span class="line">            <span class="comment"># then it is a docstring. Just ignore it.</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> ExprStmt(build_expr(ctx, value))</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_Assign</span>(<span class="params">ctx, expr</span>):</span></span><br><span class="line">        <span class="comment"># ...</span></span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_AnnAssign</span>(<span class="params">ctx, stmt</span>):</span></span><br><span class="line">        <span class="comment">#...</span></span><br><span class="line">    <span class="comment"># ......</span></span><br></pre></td></tr></table></figure><p>We can see that, this is a class with many static methods that define what to do for different types of Python AST. I will not go deep into how each type is handled. Since at this point, the readers should be able to catch all the details on how each type of nodes in Python AST are dealt with by themselves. So We will stop our frontend reading right here.</p><h1 id="From-Python-AST-to-PyTorch-IR-part-1"><a href="#From-Python-AST-to-PyTorch-IR-part-1" class="headerlink" title="From Python AST to PyTorch IR: part 1"></a><a name="ast2ir"></a>From Python AST to PyTorch IR: part 1</h1><p>Now let’s move on to read <code>_jit_script_compile</code>. To find where it is located, simply run the command <code>grep _jit_script_compile -r .</code>. We will find something like:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./torch/csrc/jit/script/init.cpp:      <span class="string">&quot;_jit_script_compile&quot;</span>,</span><br></pre></td></tr></table></figure><p>So, <code>torch/csrc/jit/script/init.cpp</code> would be a good start point. The complete definition of <code>_jit_script_compile</code> is:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">m.<span class="built_in">def</span>(</span><br><span class="line">    <span class="string">&quot;_jit_script_compile&quot;</span>,</span><br><span class="line">    [](<span class="keyword">const</span> std::string&amp; qualname,</span><br><span class="line">       <span class="keyword">const</span> Def&amp; def,</span><br><span class="line">       ResolutionCallback rcb,</span><br><span class="line">       <span class="keyword">const</span> FunctionDefaults&amp; defaults) &#123;</span><br><span class="line">      <span class="built_in">C10_LOG_API_USAGE_ONCE</span>(<span class="string">&quot;torch.script.compile&quot;</span>);</span><br><span class="line">      <span class="keyword">const</span> <span class="keyword">auto</span> name = c10::<span class="built_in">QualifiedName</span>(qualname);</span><br><span class="line">      <span class="built_in">TORCH_INTERNAL_ASSERT</span>(name.<span class="built_in">name</span>() == def.<span class="built_in">name</span>().<span class="built_in">name</span>());</span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">script_compile_function</span>(name, def, defaults, std::<span class="built_in">move</span>(rcb));</span><br><span class="line">    &#125;);</span><br></pre></td></tr></table></figure><p>So, let’s move on to <code>script_compile_function</code>. This is a function defined in the same file</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> StrongFunctionPtr <span class="title">script_compile_function</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> c10::QualifiedName&amp; name,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> Def&amp; def,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> FunctionDefaults&amp; defaults,</span></span></span><br><span class="line"><span class="function"><span class="params">    ResolutionCallback rcb)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> cu = <span class="built_in">get_python_cu</span>();</span><br><span class="line">  <span class="keyword">auto</span> defined_functions = cu-&gt;<span class="built_in">define</span>(</span><br><span class="line">      <span class="built_in">QualifiedName</span>(name.<span class="built_in">prefix</span>()),</span><br><span class="line">      &#123;def&#125;,</span><br><span class="line">      &#123;<span class="built_in">pythonResolver</span>(std::<span class="built_in">move</span>(rcb))&#125;,</span><br><span class="line">      <span class="literal">nullptr</span>,</span><br><span class="line">      <span class="literal">true</span>);</span><br><span class="line">  <span class="built_in">TORCH_INTERNAL_ASSERT</span>(defined_functions.<span class="built_in">size</span>() == <span class="number">1</span>);</span><br><span class="line">  <span class="keyword">auto</span>&amp; defined = defined_functions[<span class="number">0</span>];</span><br><span class="line">  defined-&gt;<span class="built_in">setSchema</span>(<span class="built_in">getSchemaWithNameAndDefaults</span>(</span><br><span class="line">      def.<span class="built_in">range</span>(), defined-&gt;<span class="built_in">getSchema</span>(), def.<span class="built_in">name</span>().<span class="built_in">name</span>(), defaults));</span><br><span class="line">  <span class="function">StrongFunctionPtr <span class="title">ret</span><span class="params">(std::move(cu), defined)</span></span>;</span><br><span class="line">  <span class="built_in">didFinishEmitFunction</span>(ret);</span><br><span class="line">  <span class="keyword">return</span> ret;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Which part of this function does the acutal job of compiling tree views to PyTorch IR? It could be <code>cu-&gt;define</code>, or constructor of <code>StrongFunctionPtr</code><br>or <code>didFinishEmitFunction</code>. It is not clear right now, but seems mostly likely to be in <code>cu-&gt;define</code>, but let’s skim through these functions:</p><p>By greping <code>get_python_cu</code>, we can find this line</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">inline std::shared_ptr&lt;script::CompilationUnit&gt; get_python_cu() &#123;</span><br></pre></td></tr></table></figure><p>which tells us that the <code>cu</code> in the code is a <code>CompilationUnit</code>. By greping <code>CompilationUnit::define</code>, we find its definition in <code>torch/csrc/jit/script/compiler.cpp</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::unique_ptr&lt;Function&gt; <span class="title">CompilationUnit::define</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> c10::optional&lt;QualifiedName&gt;&amp; prefix,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> Def&amp; def,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> ResolverPtr&amp; resolver,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> Self* self,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> std::unordered_map&lt;std::string, Function*&gt;&amp; function_table,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">bool</span> shouldMangle)</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">  <span class="comment">// .......</span></span><br><span class="line">  <span class="keyword">auto</span> creator = [def, _resolver, self](Function&amp; method) &#123;</span><br><span class="line">    <span class="comment">// .......</span></span><br><span class="line">    <span class="built_in">to_ir</span>(def, _resolver, self, method);</span><br><span class="line">  &#125;;</span><br><span class="line">  <span class="comment">// .......</span></span><br><span class="line">  <span class="keyword">auto</span> fn = torch::make_unique&lt;Function&gt;(</span><br><span class="line">      std::<span class="built_in">move</span>(name), std::make_shared&lt;Graph&gt;(), creator);</span><br><span class="line">  <span class="keyword">if</span> (self) &#123;</span><br><span class="line">    <span class="comment">// Register this as a method on `self`&#x27;s type</span></span><br><span class="line">    self-&gt;<span class="built_in">getClassType</span>()-&gt;<span class="built_in">addMethod</span>(fn.<span class="built_in">get</span>());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> fn;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Less important parts of the code is omitted. From above, we can find that the core of compiling an AST into a compute graph is done at <code>to_ir</code>. It is defined in the same file. Skimming through <code>to_ir</code> we find that it is a struct of ~3000 lines of code, with member functions that handles different cases of Python AST. Without knowing PyTorch’s IR, it’s not easy to understand what <code>to_ir</code> does. So let’s pause a little bit to take a look at PyTorch IR and come back later.</p><h1 id="The-PyTorch-IR"><a href="#The-PyTorch-IR" class="headerlink" title="The PyTorch IR"></a>The PyTorch IR</h1><p>PyTorch now has a very detailed design doc at <a href="https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/docs/OVERVIEW.md"><code>torch/csrc/jit/docs/OVERVIEW.md</code></a>. We should read through this document before coming back.</p><h1 id="From-Python-AST-to-PyTorch-IR-part-2"><a href="#From-Python-AST-to-PyTorch-IR-part-2" class="headerlink" title="From Python AST to PyTorch IR: part 2"></a>From Python AST to PyTorch IR: part 2</h1><p>Let’s continue the reading by looking at the definition of <code>to_ir</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">to_ir</span>(</span><br><span class="line">    <span class="keyword">const</span> Def&amp; def,</span><br><span class="line">    ResolverPtr resolver_,</span><br><span class="line">    <span class="keyword">const</span> Self* self,</span><br><span class="line">    Function&amp; method) <span class="comment">// method being constructed</span></span><br><span class="line">    : <span class="built_in">method</span>(method),</span><br><span class="line">      <span class="built_in">graph</span>(method.<span class="built_in">graph</span>()),</span><br><span class="line">      <span class="built_in">resolver</span>(std::<span class="built_in">move</span>(resolver_)),</span><br><span class="line">      <span class="built_in">typeParser_</span>(resolver),</span><br><span class="line">      <span class="built_in">environment_stack</span>(<span class="literal">nullptr</span>) &#123;</span><br><span class="line">  <span class="built_in">AT_ASSERT</span>(resolver);</span><br><span class="line">  <span class="built_in">pushFrame</span>(graph-&gt;<span class="built_in">block</span>(), <span class="comment">/*starts_def=*/</span><span class="literal">true</span>);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Type annotations exclude explicitly typing the &quot;self&quot; parameter, so in</span></span><br><span class="line">  <span class="comment">// the case that this is a method with self we expect one fewer parameter</span></span><br><span class="line">  <span class="comment">// annotation than the number of parameters this Def takes.</span></span><br><span class="line">  <span class="keyword">if</span> (self &amp;&amp; def.<span class="built_in">decl</span>().<span class="built_in">params</span>().<span class="built_in">size</span>() == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">throw</span> <span class="built_in">ErrorReport</span>(def.<span class="built_in">decl</span>().<span class="built_in">params</span>().<span class="built_in">range</span>())</span><br><span class="line">        &lt;&lt; <span class="string">&quot;methods must have a self argument&quot;</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  method.<span class="built_in">setSchema</span>(<span class="built_in">emitDef</span>(def, self, graph-&gt;<span class="built_in">block</span>()));</span><br><span class="line"></span><br><span class="line">  <span class="comment">// NB ORDERING: SSA conversion has to occur before</span></span><br><span class="line">  <span class="comment">// lifting of closures and forks, this way closures are converted</span></span><br><span class="line">  <span class="comment">// to SSA while part of their original graph, and closures are ready to</span></span><br><span class="line">  <span class="comment">// be inlined into forked closures</span></span><br><span class="line">  <span class="built_in">ConvertToSSA</span>(graph);</span><br><span class="line">  <span class="comment">// convert loops with an iter and body condition specified to</span></span><br><span class="line">  <span class="comment">// python-recognize while loops. we do this so they can be exported,</span></span><br><span class="line">  <span class="comment">// and run the pass early to avoid jitter. Like conversion to SSA,</span></span><br><span class="line">  <span class="comment">// it only needs to run once.</span></span><br><span class="line">  <span class="built_in">CanonicalizeModifiedLoops</span>(graph);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">runCleanupPasses</span>(graph);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>we can clearly see that we first convert from tree view to PyTorch IR in <code>emitDef</code>, the convert the PyTorch IR to SSA in <code>ConvertToSSA</code>, and then do some special handling of loops and then cleanup. Looking around, it is also not hard to find that <code>ConvertToSSA</code> is defined in <code>torch/csrc/jit/script/convert_to_ssa.cpp</code>. Roughly the flow chart is:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Python AST --[torch.jit.frontend]--&gt; Tree View --[compiler.cpp]--&gt; PyTorch IR --[convert_to_ssa.cpp]--&gt; SSA ----&gt; canonicalized and cleanuped SSA</span><br></pre></td></tr></table></figure><p>Now let’s continue looking at <code>emitDef</code> for the <code>Tree View --&gt; PyTorch IR</code> conversion:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">FunctionSchema <span class="title">emitDef</span><span class="params">(<span class="keyword">const</span> Def&amp; def, <span class="keyword">const</span> Self* self, Block* block)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> schema = typeParser_.<span class="built_in">parseSchemaFromDef</span>(def, <span class="built_in"><span class="keyword">bool</span></span>(self));</span><br><span class="line">  <span class="comment">// TODO need guards on init returning none</span></span><br><span class="line">  <span class="keyword">if</span> (schema.<span class="built_in">returns</span>().<span class="built_in">size</span>() == <span class="number">1</span>) &#123;</span><br><span class="line">    def_stack_.<span class="built_in">back</span>().declared_return_type_ = schema.<span class="built_in">returns</span>().<span class="built_in">at</span>(<span class="number">0</span>).<span class="built_in">type</span>();</span><br><span class="line">  &#125;</span><br><span class="line">  std::vector&lt;Argument&gt; arguments =</span><br><span class="line">      <span class="built_in">emitFormalArguments</span>(def, self, schema, block);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// body</span></span><br><span class="line">  <span class="keyword">auto</span> stmts_list = def.<span class="built_in">statements</span>();</span><br><span class="line">  <span class="built_in">emitStatements</span>(stmts_list.<span class="built_in">begin</span>(), stmts_list.<span class="built_in">end</span>());</span><br><span class="line">  <span class="built_in">handleMaybeNoReturn</span>(def, block);</span><br><span class="line">  std::vector&lt;Argument&gt; returns = &#123;<span class="built_in">emitOutput</span>(def.<span class="built_in">range</span>(), schema, block)&#125;;</span><br><span class="line">  <span class="keyword">return</span> &#123;def.<span class="built_in">name</span>().<span class="built_in">name</span>(), <span class="string">&quot;&quot;</span>, std::<span class="built_in">move</span>(arguments), std::<span class="built_in">move</span>(returns)&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Basically what it does is:</p><ol><li>parse schema and arguments</li><li>compile function body by <code>emitStatements</code></li><li>handle return</li></ol><p>We will not go into the details about schema and how the return is handled. We only continue looking at <code>emitStatements</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">emitStatements</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    List&lt;Stmt&gt;::const_iterator begin,</span></span></span><br><span class="line"><span class="function"><span class="params">    List&lt;Stmt&gt;::const_iterator end)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (; begin != end; ++begin) &#123;</span><br><span class="line">    <span class="keyword">auto</span> stmt = *begin;</span><br><span class="line">    ErrorReport::CallStack::<span class="built_in">update_pending_range</span>(stmt.<span class="built_in">range</span>());</span><br><span class="line">    <span class="built_in"><span class="keyword">switch</span></span> (stmt.<span class="built_in">kind</span>()) &#123;</span><br><span class="line">      <span class="keyword">case</span> TK_IF:</span><br><span class="line">        <span class="built_in">emitIf</span>(<span class="built_in">If</span>(stmt));</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> TK_WHILE:</span><br><span class="line">        <span class="built_in">emitWhile</span>(<span class="built_in">While</span>(stmt));</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> TK_FOR:</span><br><span class="line">        <span class="built_in">emitFor</span>(<span class="built_in">For</span>(stmt));</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> TK_ASSIGN:</span><br><span class="line">        <span class="built_in">emitAssignment</span>(<span class="built_in">Assign</span>(stmt));</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> TK_AUG_ASSIGN:</span><br><span class="line">        <span class="built_in">emitAugAssignment</span>(<span class="built_in">AugAssign</span>(stmt));</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> TK_EXPR_STMT: &#123;</span><br><span class="line">        <span class="keyword">auto</span> expr = <span class="built_in">ExprStmt</span>(stmt).<span class="built_in">expr</span>();</span><br><span class="line">        <span class="built_in">emitSugaredExpr</span>(expr, <span class="number">0</span>);</span><br><span class="line">      &#125; <span class="keyword">break</span>;</span><br><span class="line">      <span class="comment">// .......</span></span><br><span class="line">      <span class="keyword">default</span>:</span><br><span class="line">        <span class="keyword">throw</span> <span class="built_in">ErrorReport</span>(stmt)</span><br><span class="line">            &lt;&lt; <span class="string">&quot;Unrecognized statement kind &quot;</span> &lt;&lt; <span class="built_in">kindToString</span>(stmt.<span class="built_in">kind</span>());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>we can see that the handle of each kind of statement is dispatched by <code>stmt.kind()</code>. For each specialized emit, we would expect it take the tree view as input, recursively traverse the tree view to emit the code. Let’s first take a look at a simple specialization of this kind of emit:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Currently we do not support assigning exceptions to variables,</span></span><br><span class="line"><span class="comment">// a = Exception(&quot;hi&quot;)</span></span><br><span class="line"><span class="comment">// raise a</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// We ignore the expression following raise</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">emitRaise</span><span class="params">(<span class="keyword">const</span> SourceRange&amp; loc)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> std::string exception = <span class="string">&quot;Exception&quot;</span>;</span><br><span class="line">  <span class="keyword">auto</span> string_input = <span class="built_in">insertConstant</span>(*graph, exception, loc);</span><br><span class="line">  graph-&gt;<span class="built_in">insert</span>(prim::RaiseException, &#123;string_input&#125;, &#123;&#125;, loc);</span><br><span class="line">  exit_blocks.<span class="built_in">insert</span>(environment_stack-&gt;<span class="built_in">block</span>());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>we see that it just insert a <code>prim::RaiseException</code> into the graph.</p><p>When designing a compiler, expression is always an important sublanguage to pay attention to. Let’s take a look at how PyTorch JIT handles expression here. The place to look at is <code>emitSugaredExpr</code>. Before we start, it worth mentioning that, Python is a dynamically typed language, while PyTorch IR is statically typed. So we would expect <code>emitSugaredExpr</code> to have a type system to infer types. The <code>emitSugaredExpr</code> is:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// any expression that can produce a SugaredValue is handled here</span></span><br><span class="line"><span class="comment">// expressions that only return a single Value* are handled in emitSimpleExpr</span></span><br><span class="line"><span class="comment">// type_hint is set if there is a type that this value is expected to be</span></span><br><span class="line"><span class="comment">// e.g. a : List[int] = []</span></span><br><span class="line"><span class="comment">// or a = torch.jit.annotate(List[int], [])</span></span><br><span class="line"><span class="comment">// the caller is responsible for checking that the result matches type_hint</span></span><br><span class="line"><span class="comment">// emitSugaredExpr is free to ignore it.</span></span><br><span class="line"><span class="function">std::shared_ptr&lt;SugaredValue&gt; <span class="title">emitSugaredExpr</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> Expr&amp; tree,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">size_t</span> n_binders,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> TypePtr&amp; type_hint = <span class="literal">nullptr</span>)</span> </span>&#123;</span><br><span class="line">  <span class="built_in"><span class="keyword">switch</span></span> (tree.<span class="built_in">kind</span>()) &#123;</span><br><span class="line">    <span class="keyword">case</span> TK_VAR:</span><br><span class="line">      <span class="keyword">return</span> environment_stack-&gt;<span class="built_in">getSugaredVar</span>(<span class="built_in">Var</span>(tree).<span class="built_in">name</span>());</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;.&#x27;</span>: &#123;</span><br><span class="line">      <span class="keyword">auto</span> select = <span class="built_in">Select</span>(tree);</span><br><span class="line">      <span class="keyword">auto</span> sv = <span class="built_in">emitSugaredExpr</span>(select.<span class="built_in">value</span>(), <span class="number">1</span>);</span><br><span class="line">      <span class="keyword">return</span> sv-&gt;<span class="built_in">attr</span>(select.<span class="built_in">range</span>(), method, select.<span class="built_in">selector</span>().<span class="built_in">name</span>());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">case</span> TK_APPLY: &#123;</span><br><span class="line">      <span class="keyword">auto</span> apply = <span class="built_in">Apply</span>(tree);</span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">emitApplyExpr</span>(apply, n_binders);</span><br><span class="line">    &#125; <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">      <span class="keyword">return</span> std::make_shared&lt;SimpleValue&gt;(<span class="built_in">emitSimpleExpr</span>(tree, type_hint));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Here we will only go deep into simple expressions. An example of simple expression is <code>a + b</code>, and we will look at how this specific example is handled. Now let’s look at <code>emitSimpleExpr</code>, it is:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Value* <span class="title">emitSimpleExpr</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> TreeRef&amp; tree,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> TypePtr&amp; type_hint = <span class="literal">nullptr</span>)</span> </span>&#123;</span><br><span class="line">  <span class="built_in"><span class="keyword">switch</span></span> (tree-&gt;<span class="built_in">kind</span>()) &#123;</span><br><span class="line">    <span class="comment">// .....</span></span><br><span class="line">    <span class="keyword">case</span> TK_IN:</span><br><span class="line">    <span class="keyword">case</span> TK_POW:</span><br><span class="line">    <span class="keyword">case</span> TK_NE:</span><br><span class="line">    <span class="keyword">case</span> TK_EQ:</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;&lt;&#x27;</span>:</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;&gt;&#x27;</span>:</span><br><span class="line">    <span class="keyword">case</span> TK_LE:</span><br><span class="line">    <span class="keyword">case</span> TK_GE:</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;*&#x27;</span>:</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;/&#x27;</span>:</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;+&#x27;</span>:</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;-&#x27;</span>:</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;%&#x27;</span>:</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;&amp;&#x27;</span>:</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;|&#x27;</span>:</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;^&#x27;</span>: &#123;</span><br><span class="line">      <span class="keyword">const</span> <span class="keyword">auto</span>&amp; inputs = tree-&gt;<span class="built_in">trees</span>();</span><br><span class="line">      <span class="keyword">auto</span> kind = <span class="built_in">getNodeKind</span>(tree-&gt;<span class="built_in">kind</span>(), inputs.<span class="built_in">size</span>());</span><br><span class="line">      <span class="keyword">auto</span> overload = <span class="built_in">getOperatorOverload</span>(tree-&gt;<span class="built_in">kind</span>(), inputs.<span class="built_in">size</span>());</span><br><span class="line">      <span class="keyword">auto</span> named_values = <span class="built_in">getNamedValues</span>(inputs, <span class="comment">/*maybe_unpack=*/</span><span class="literal">false</span>);</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (tree-&gt;<span class="built_in">kind</span>() == TK_IN) &#123;</span><br><span class="line">        <span class="comment">// For `in` the arguments are in reverse order (the object being</span></span><br><span class="line">        <span class="comment">// checked is second)</span></span><br><span class="line">        std::<span class="built_in">iter_swap</span>(named_values.<span class="built_in">begin</span>() + <span class="number">0</span>, named_values.<span class="built_in">begin</span>() + <span class="number">1</span>);</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">asSimple</span>(</span><br><span class="line">          <span class="built_in">makeMagic</span>(</span><br><span class="line">              overload, std::make_shared&lt;BuiltinFunction&gt;(kind, at::nullopt))</span><br><span class="line">              -&gt;<span class="built_in">call</span>(tree-&gt;<span class="built_in">range</span>(), method, named_values, &#123;&#125;, <span class="number">0</span>));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// ....</span></span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">      <span class="keyword">throw</span> <span class="built_in">ErrorReport</span>(tree) &lt;&lt; <span class="string">&quot;Cannot emit expr for: &quot;</span> &lt;&lt; tree;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>We can see that, the actual work is done inside <code>BuiltinFunction::call</code>. This function is defined in <code>sugared_value.cpp</code> as:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::shared_ptr&lt;SugaredValue&gt; <span class="title">BuiltinFunction::call</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> SourceRange&amp; loc,</span></span></span><br><span class="line"><span class="function"><span class="params">    Function&amp; m,</span></span></span><br><span class="line"><span class="function"><span class="params">    at::ArrayRef&lt;NamedValue&gt; inputs,</span></span></span><br><span class="line"><span class="function"><span class="params">    at::ArrayRef&lt;NamedValue&gt; attributes,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">size_t</span> n_binders)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> std::make_shared&lt;SimpleValue&gt;(</span><br><span class="line">      <span class="built_in">emitBuiltinCall</span>(loc, *m.<span class="built_in">graph</span>(), symbol, inputs, attributes, self));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>where <code>emitBuiltinCall</code> is defined in <code>schema_matching.cpp</code> as:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Search for operators matching the provided symbol name and input types.</span></span><br><span class="line"><span class="comment">// If one is found, emit a node to the graph for that operator.</span></span><br><span class="line"><span class="function">Value* <span class="title">emitBuiltinCall</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> SourceRange&amp; loc,</span></span></span><br><span class="line"><span class="function"><span class="params">    Graph&amp; graph,</span></span></span><br><span class="line"><span class="function"><span class="params">    Symbol name,</span></span></span><br><span class="line"><span class="function"><span class="params">    at::ArrayRef&lt;NamedValue&gt; inputs,</span></span></span><br><span class="line"><span class="function"><span class="params">    at::ArrayRef&lt;NamedValue&gt; attributes,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> c10::optional&lt;NamedValue&gt;&amp; self)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">auto</span>&amp; variants = <span class="built_in">getAllOperatorsFor</span>(name);</span><br><span class="line">  <span class="keyword">const</span> <span class="keyword">auto</span>&amp; builtin_functions = <span class="built_in">getAllBuiltinFunctionsFor</span>(name);</span><br><span class="line"></span><br><span class="line">  std::stringstream failure_messages;</span><br><span class="line">  std::vector&lt;<span class="keyword">const</span> FunctionSchema*&gt; schemas;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">const</span> std::shared_ptr&lt;Operator&gt;&amp; op : variants) &#123;</span><br><span class="line">    schemas.<span class="built_in">push_back</span>(&amp;op-&gt;<span class="built_in">schema</span>());</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span> method : builtin_functions) &#123;</span><br><span class="line">    method-&gt;<span class="built_in">ensure_defined</span>();</span><br><span class="line">    schemas.<span class="built_in">push_back</span>(&amp;method-&gt;<span class="built_in">getSchema</span>());</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// no operators found with the same name, print out similarly named operators</span></span><br><span class="line">  <span class="keyword">if</span> (schemas.<span class="built_in">size</span>() == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">auto</span> close_symbols = <span class="built_in">findSimilarOperators</span>(name);</span><br><span class="line">    <span class="keyword">auto</span> error = <span class="built_in">ErrorReport</span>(loc);</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">auto</span>&amp; user_function_name = name.<span class="built_in">toQualString</span>();</span><br><span class="line">    error &lt;&lt; <span class="string">&quot;Unknown builtin op: &quot;</span> &lt;&lt; user_function_name &lt;&lt; <span class="string">&quot;.\n&quot;</span>;</span><br><span class="line">    <span class="keyword">if</span> (close_symbols.<span class="built_in">size</span>() == <span class="number">0</span>) &#123;</span><br><span class="line">      error</span><br><span class="line">          &lt;&lt; <span class="string">&quot;Could not find any similar ops to &quot;</span> &lt;&lt; user_function_name</span><br><span class="line">          &lt;&lt; <span class="string">&quot;. This op may not exist or may not be currently supported in TorchScript.\n&quot;</span>;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      error &lt;&lt; <span class="string">&quot;Here are some suggestions: \n&quot;</span>;</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>&amp; sym : close_symbols) &#123;</span><br><span class="line">        error &lt;&lt; <span class="string">&quot;\t&quot;</span> &lt;&lt; sym.<span class="built_in">toQualString</span>() &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">      &#125;</span><br><span class="line">      error &lt;&lt; <span class="string">&quot;\nThe original call is&quot;</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">throw</span> error;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> matched = <span class="built_in">matchSchemas</span>(schemas, loc, graph, inputs, attributes, self);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (matched.first &lt; variants.<span class="built_in">size</span>()) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">emitBuiltinNode</span>(matched.second, loc, graph, name);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    Function* fn = builtin_functions[matched.first - variants.<span class="built_in">size</span>()];</span><br><span class="line">    <span class="comment">// we inline builtin calls because they are normally very small</span></span><br><span class="line">    <span class="comment">// wrappers and are not useful for keeping around to debug</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">insertGraph</span>(graph, *fn-&gt;<span class="built_in">graph</span>(), matched.second.inputs).<span class="built_in">at</span>(<span class="number">0</span>);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>we can see that it look up the database of schemas and find the matching one, then use <code>emitBuiltinNode</code> to emit PyTorch IR. <code>emitBuiltinNode</code> is implemented as:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Given a successful match between operator schema and symbol, emit a node</span></span><br><span class="line"><span class="comment">// with the appropriate inputs and outputs.</span></span><br><span class="line"><span class="function"><span class="keyword">static</span> Value* <span class="title">emitBuiltinNode</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> MatchedSchema&amp; matched_schema,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> SourceRange&amp; loc,</span></span></span><br><span class="line"><span class="function"><span class="params">    Graph&amp; graph,</span></span></span><br><span class="line"><span class="function"><span class="params">    Symbol name)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> n = graph.<span class="built_in">insertNode</span>(graph.<span class="built_in">create</span>(name, matched_schema.inputs, <span class="number">0</span>))</span><br><span class="line">               -&gt;<span class="built_in">setSourceRange</span>(loc);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span>&amp; ret : matched_schema.return_types) &#123;</span><br><span class="line">    n-&gt;<span class="built_in">addOutput</span>()-&gt;<span class="built_in">setType</span>(ret);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// assert that we did indeed create an op that has implementation</span></span><br><span class="line">  <span class="comment">// otherwise schema and dispatch are not in sync</span></span><br><span class="line">  <span class="built_in">getOperation</span>(n);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">packOutputs</span>(graph, n-&gt;<span class="built_in">outputs</span>(), matched_schema.return_field_names);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>we can see that the type is infered by the schema in the following line</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (<span class="keyword">auto</span>&amp; ret : matched_schema.return_types) &#123;</span><br><span class="line">  n-&gt;<span class="built_in">addOutput</span>()-&gt;<span class="built_in">setType</span>(ret);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Reaching this point, we have already get the big picture of the <code>Tree View --&gt; PyTorch IR</code>: dispatch by node kind of tree view, and use schemas to do type inference.</p><p>After <code>to_ir</code> called, we should have a graph of PyTorch IR which is staticly typed. As described before, this graph will be converted to SSA and loops will be canonicalized. The conversion to SSA is a pretty standard task of compilers in general. Readers could refer to <a href="https://en.wikipedia.org/wiki/Static_single_assignment_form#Converting_to_SSA">Wikipedia</a> for how this could be done and read <code>convert_to_ssa.cpp</code> in PyTorch for detail. We will not go into details about loop canonicalization either.</p><h1 id="The-Graph-Executor"><a href="#The-Graph-Executor" class="headerlink" title="The Graph Executor"></a>The Graph Executor</h1><p>Now we have seen how the compilation is done and what does PyTorch JIT’s IR looks like, the thing left is how the IR are executed. As we have already seen in <a href="#ast2ir">From Python AST to PyTorch IR: part 1</a>, <code>script_compile_function</code> returns a pointer to a class <code>Function</code>. By looking at the implementation of <code>Function</code> at <code>torch/csrc/jit/function.&#123;h, cpp&#125;</code> we can easily see how a graph is executed:</p><p>In <code>functions.h</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> once</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;torch/csrc/jit/graph_executor.h&gt;</span></span></span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::shared_ptr&lt;Graph&gt; <span class="title">optimized_graph</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">  <span class="function">std::lock_guard&lt;std::recursive_mutex&gt; <span class="title">lock</span><span class="params">(compile_mutex)</span></span>;</span><br><span class="line">  <span class="keyword">if</span> (optimized_graph_) &#123;</span><br><span class="line">    <span class="keyword">return</span> *optimized_graph_;</span><br><span class="line">  &#125;</span><br><span class="line">  optimized_graph_ = graph_-&gt;<span class="built_in">copy</span>();</span><br><span class="line">  <span class="built_in">preoptimizeGraph</span>(*optimized_graph_);</span><br><span class="line">  <span class="keyword">return</span> *optimized_graph_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">GraphExecutor&amp; <span class="title">get_executor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="built_in">ensure_defined</span>();</span><br><span class="line">  <span class="function">std::lock_guard&lt;std::recursive_mutex&gt; <span class="title">lock</span><span class="params">(compile_mutex)</span></span>;</span><br><span class="line">  <span class="keyword">if</span> (executor_) &#123;</span><br><span class="line">    <span class="keyword">return</span> executor_;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">check_single_output</span>();</span><br><span class="line">  executor_ = <span class="built_in">GraphExecutor</span>(<span class="built_in">optimized_graph</span>());</span><br><span class="line">  <span class="keyword">return</span> executor_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>and in <code>functions.cpp</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// functions.cpp</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;torch/csrc/jit/passes/inliner.h&gt;</span></span></span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Function::run</span><span class="params">(Stack&amp; stack)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">get_executor</span>().<span class="built_in">run</span>(stack);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">Function::run</span><span class="params">(Stack&amp;&amp; stack)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">run</span>(stack);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">IValue <span class="title">Function::operator</span><span class="params">()</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    std::vector&lt;IValue&gt; stack,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> Kwargs&amp; kwargs)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">getSchema</span>().<span class="built_in">checkAndNormalizeInputs</span>(stack, kwargs);</span><br><span class="line">  <span class="built_in">run</span>(stack);</span><br><span class="line">  <span class="keyword">return</span> stack.<span class="built_in">front</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">preoptimizeGraph</span><span class="params">(std::shared_ptr&lt;Graph&gt;&amp; graph)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// <span class="doctag">TODO:</span> Invoke cleanup passes before and after inlining to reduce amount of</span></span><br><span class="line">  <span class="comment">// code we&#x27;re copying.</span></span><br><span class="line">  <span class="built_in">Inline</span>(*graph);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>We can see that, when we want to execute a graph, PyTorch first inline the graph using the inliner defined in <code>torch/csrc/jit/passes/inliner.h</code>, then create a <code>GraphExecutor</code> for the inlined graph. We will not go into details on how the graph is inlined. We will move to <code>GraphExecutor</code> instead.</p><p>The <code>GraphExecutor</code> is defined in <code>torch/csrc/jit/graph_executor.&#123;h, cpp&#125;</code>.</p><p>The constructor and <code>run</code> tells us that <code>GraphExecutor</code> is just a wrapper of <code>GraphExecutorImplBase</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">GraphExecutor::<span class="built_in">GraphExecutor</span>(std::shared_ptr&lt;Graph&gt; graph)</span><br><span class="line">    : <span class="built_in">pImpl</span>(</span><br><span class="line">          <span class="built_in">getExecutorMode</span>() ? <span class="keyword">dynamic_cast</span>&lt;GraphExecutorImplBase*&gt;(</span><br><span class="line">                                  <span class="keyword">new</span> <span class="built_in">ProfilingGraphExecutorImpl</span>(graph))</span><br><span class="line">                            : <span class="keyword">dynamic_cast</span>&lt;GraphExecutorImplBase*&gt;(</span><br><span class="line">                                  <span class="keyword">new</span> <span class="built_in">GraphExecutorImpl</span>(graph))) &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">GraphExecutor::run</span><span class="params">(Stack&amp; inputs)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> pImpl-&gt;<span class="built_in">run</span>(inputs);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>We can also tell that there are actually two implementations of graph executor: <code>GraphExecutorImpl</code> and <code>ProfilingGraphExecutorImpl</code>. Both are subclasses of <code>GraphExecutorImplBase</code>. <code>GraphExecutorImpl</code> is implemented in <code>graph_executor.cpp</code>, while <code>ProfilingGraphExecutorImpl</code> is implemented in <code>profiling_graph_executor_impl.cpp</code>. We will look at both implementations.</p><p>Before looking at any implementation, let’s first look at the base class, which is also implemented in <code>graph_executor.cpp</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">GraphExecutorImplBase::run</span><span class="params">(Stack&amp; stack)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">TORCH_CHECK</span>(</span><br><span class="line">      stack.<span class="built_in">size</span>() &gt;= num_inputs,</span><br><span class="line">      <span class="string">&quot;expected &quot;</span>,</span><br><span class="line">      num_inputs,</span><br><span class="line">      <span class="string">&quot; inputs, but got only &quot;</span>,</span><br><span class="line">      stack.<span class="built_in">size</span>());</span><br><span class="line"></span><br><span class="line">  <span class="built_in">C10_LOG_API_USAGE_ONCE</span>(<span class="string">&quot;torch.graph_executor.run&quot;</span>);</span><br><span class="line">  logging::<span class="built_in">getLogger</span>()-&gt;<span class="built_in">addStatValue</span>(</span><br><span class="line">      logging::runtime_counters::GRAPH_EXECUTOR_INVOCATIONS, <span class="number">1.0</span>);</span><br><span class="line"></span><br><span class="line">  ExecutionPlan plan =</span><br><span class="line">      <span class="built_in">getPlanFor</span>(stack, GraphExecutor::<span class="built_in">getDefaultNumBailOuts</span>());</span><br><span class="line">  <span class="built_in">InterpreterState</span>(plan.code).<span class="built_in">run</span>(stack);</span><br><span class="line">  last_executed_optimized_graph = plan.graph;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>we can see that it first get an <code>ExecutionPlan</code>, create a state machine <code>InterpreterState</code>, and run the state machine on the stack.</p><h2 id="GraphExecutorImpl"><a href="#GraphExecutorImpl" class="headerlink" title="GraphExecutorImpl"></a>GraphExecutorImpl</h2><p>Now let’s move on to <code>GraphExecutorImpl</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">ExecutionPlan <span class="title">getPlanFor</span><span class="params">(Stack&amp; stack, <span class="keyword">size_t</span> remaining_bailout_depth)</span></span></span><br><span class="line"><span class="function">    <span class="keyword">override</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">getGraphExecutorOptimize</span>() ? <span class="built_in">getOrCompile</span>(stack)</span><br><span class="line">                                    : <span class="built_in">getOrCompileFallback</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>We can see that the second argument <code>remaining_bailout_depth</code> is completely ignored, which indicate that <code>GraphExecutorImpl</code> does not have a bailout mechanism.</p><p>We also see that the graph is compiled at the first time it runs to get an execution plan. Compilation of graph to execution plan is done by <code>getOrCompile</code> or <code>getOrCompileFallback</code> depending on if optimization is enabled. These two methods are copied below:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">const</span> ExecutionPlan&amp; <span class="title">getOrCompileFallback</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(compile_mutex)</span></span>;</span><br><span class="line">  <span class="keyword">if</span> (!fallback) &#123;</span><br><span class="line">    <span class="keyword">auto</span> graph_ = graph-&gt;<span class="built_in">copy</span>();</span><br><span class="line">    <span class="built_in">runRequiredPasses</span>(graph_);</span><br><span class="line">    fallback = <span class="built_in">ExecutionPlan</span>(graph_);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> fallback;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">const</span> ExecutionPlan&amp; <span class="title">getOrCompile</span><span class="params">(<span class="keyword">const</span> Stack&amp; stack)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// outside lock guard, to minimize the time holding the lock on the fast</span></span><br><span class="line">  <span class="comment">// path ArgumentSpec even computes its hashCode here.</span></span><br><span class="line">  ArgumentSpec spec =</span><br><span class="line">      arg_spec_creator_.<span class="built_in">create</span>(autograd::GradMode::<span class="built_in">is_enabled</span>(), stack);</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(compile_mutex)</span></span>;</span><br><span class="line">    <span class="keyword">auto</span> it = plan_cache.<span class="built_in">find</span>(spec);</span><br><span class="line">    <span class="keyword">if</span> (it != plan_cache.<span class="built_in">end</span>()) &#123;</span><br><span class="line">      logging::<span class="built_in">getLogger</span>()-&gt;<span class="built_in">addStatValue</span>(</span><br><span class="line">          logging::runtime_counters::EXECUTION_PLAN_CACHE_HIT, <span class="number">1.0</span>);</span><br><span class="line">      <span class="keyword">return</span> it-&gt;second;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">auto</span> plan = <span class="built_in">compileSpec</span>(spec);</span><br><span class="line">    <span class="keyword">auto</span> r = plan_cache.<span class="built_in">emplace</span>(std::<span class="built_in">move</span>(spec), std::<span class="built_in">move</span>(plan));</span><br><span class="line">    logging::<span class="built_in">getLogger</span>()-&gt;<span class="built_in">addStatValue</span>(</span><br><span class="line">        logging::runtime_counters::EXECUTION_PLAN_CACHE_MISS, <span class="number">1.0</span>);</span><br><span class="line">    <span class="keyword">return</span> r.first-&gt;second;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>These code explain itself well: if optimization is turned off, then we only run required passes and cache the result. Otherwise, depending on the characteristic of inputs (<code>ArgumentSpec</code>), we run full optimization and cache the generated plan for each different <code>ArgumentSpec</code>. The plan is created by the constructor of <code>ExecutionPlan</code>.</p><p>It worth a look at what passes are called:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">ExecutionPlan <span class="title">compileSpec</span><span class="params">(<span class="keyword">const</span> ArgumentSpec&amp; spec)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> opt_graph = graph-&gt;<span class="built_in">copy</span>();</span><br><span class="line">  <span class="built_in">SOURCE_DUMP</span>(<span class="string">&quot;Optimizing the following function:&quot;</span>, opt_graph);</span><br><span class="line">  arg_spec_creator_.<span class="built_in">specializeTypes</span>(*opt_graph, spec);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Phase 0. Inline functions, then clean up any artifacts that the inliner</span></span><br><span class="line">  <span class="comment">//          left in that may inhibit optimization</span></span><br><span class="line">  <span class="built_in">Inline</span>(*opt_graph);</span><br><span class="line">  <span class="built_in">LowerGradOf</span>(*opt_graph);</span><br><span class="line">  <span class="built_in">specializeAutogradZero</span>(*opt_graph);</span><br><span class="line">  <span class="built_in">LowerSimpleTuples</span>(opt_graph);</span><br><span class="line">  <span class="built_in">ConstantPooling</span>(opt_graph);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Phase 1. Specialize to input definedness (this is very important for</span></span><br><span class="line">  <span class="comment">//          gradient graphs), and run required passes to bring the graph</span></span><br><span class="line">  <span class="comment">//          to an executable form.</span></span><br><span class="line">  <span class="built_in">runRequiredPasses</span>(opt_graph);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Phase 2. Propagate detailed information about the spec through the</span></span><br><span class="line">  <span class="comment">//          graph (enabled more specializations in later passes).</span></span><br><span class="line">  <span class="comment">//          Shape propagation sometimes depends on certain arguments being</span></span><br><span class="line">  <span class="comment">//          constants, and constant propagation doesn&#x27;t need shape</span></span><br><span class="line">  <span class="comment">//          information anyway, so it&#x27;s better to run it first.</span></span><br><span class="line">  <span class="built_in">ConstantPropagation</span>(opt_graph);</span><br><span class="line">  <span class="built_in">PropagateInputShapes</span>(opt_graph);</span><br><span class="line">  <span class="built_in">PropagateRequiresGrad</span>(opt_graph);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Phase 3. Run differentiable optimizations (i.e. simple graph rewrites</span></span><br><span class="line">  <span class="comment">//          that we can still execute using autograd).</span></span><br><span class="line">  <span class="built_in">runOptimization</span>(opt_graph);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Phase 4. If this graph will be differentiated, we need to slice out the</span></span><br><span class="line">  <span class="comment">//          symbolically differentiable subgraphs for further optimizations.</span></span><br><span class="line">  <span class="comment">// Phase 5. Apply non-differentiable optimizations to the graphs we&#x27;ve found</span></span><br><span class="line">  <span class="comment">//          (or the whole graph if we know we won&#x27;t need its derivative).</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">needsGradient</span>(opt_graph)) &#123;</span><br><span class="line">    <span class="keyword">auto</span> diff_nodes = <span class="built_in">CreateAutodiffSubgraphs</span>(</span><br><span class="line">        opt_graph,</span><br><span class="line">        autodiff_subgraph_inlining ? autodiffSubgraphNodeThreshold : <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">for</span> (Node* dnode : diff_nodes) &#123;</span><br><span class="line">      <span class="keyword">auto</span> diff_graph = std::<span class="built_in">move</span>(dnode-&gt;<span class="built_in">g</span>(attr::Subgraph));</span><br><span class="line">      Gradient gradient = <span class="built_in">differentiate</span>(diff_graph);</span><br><span class="line">      <span class="comment">// Run post differentiation optimizations, Autodiff will replace some</span></span><br><span class="line">      <span class="comment">// parts of graph with new graph, these new graphs usually consists of</span></span><br><span class="line">      <span class="comment">// control flows and miss shape information on nodes, so we run shape</span></span><br><span class="line">      <span class="comment">// prop and differentiable optimizations to ensure the graph is</span></span><br><span class="line">      <span class="comment">// optimized</span></span><br><span class="line">      <span class="built_in">PropagateInputShapes</span>(gradient.f);</span><br><span class="line">      <span class="built_in">runOptimization</span>(gradient.f);</span><br><span class="line">      <span class="comment">// run non diff optimization on the forward graph</span></span><br><span class="line">      <span class="built_in">runNondiffOptimization</span>(gradient.f);</span><br><span class="line">      <span class="built_in">packGradient</span>(gradient, dnode);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">InlineAutodiffSubgraphs</span>(</span><br><span class="line">        opt_graph,</span><br><span class="line">        autodiff_subgraph_inlining ? autodiffSubgraphInlineThreshold : <span class="number">1</span>);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">runNondiffOptimization</span>(opt_graph);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Make sure there are no leftovers from any passes.</span></span><br><span class="line">  <span class="built_in">EliminateDeadCode</span>(opt_graph);</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">ExecutionPlan</span>(opt_graph);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">runNondiffOptimization</span><span class="params">(std::shared_ptr&lt;Graph&gt;&amp; graph)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// decomposition pass, decompose certain ops that will be used in the</span></span><br><span class="line">  <span class="comment">// following passes (like batchmm and jit fusion)</span></span><br><span class="line">  <span class="keyword">if</span> (!<span class="built_in">getProfilingMode</span>()) &#123;</span><br><span class="line">    <span class="built_in">DecomposeOps</span>(graph);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// TupleConstruct / TupleUnpack pairs can still be present at this point</span></span><br><span class="line">  <span class="comment">// and must be removed for fusion.</span></span><br><span class="line">  <span class="built_in">LowerSimpleTuples</span>(graph);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Rewrite subgraphs with many MMs into expressions that batch them.</span></span><br><span class="line">  <span class="built_in">BatchMM</span>(graph);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Fuse the dequant - op - quant patterns into quantized ops</span></span><br><span class="line">  <span class="built_in">QuantFusion</span>(graph);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">FuseGraph</span>(graph);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Run custom passes that different backends can register.</span></span><br><span class="line">  <span class="comment">// This is done last to give internal optimization passes priority.</span></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>&amp; pass : <span class="built_in">getCustomPasses</span>()) &#123;</span><br><span class="line">    <span class="built_in">pass</span>(graph);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">runOptimization</span><span class="params">(std::shared_ptr&lt;Graph&gt;&amp; graph)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// Basic graph preprocessing to eliminate noise.</span></span><br><span class="line">  <span class="built_in">EliminateDeadCode</span>(graph);</span><br><span class="line">  <span class="built_in">EliminateCommonSubexpression</span>(graph);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">PeepholeOptimize</span>(graph);</span><br><span class="line">  <span class="built_in">ConstantPropagation</span>(graph);</span><br><span class="line">  <span class="built_in">ConstantPooling</span>(graph);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Unroll small loops, and eliminate expressions that are the same at every</span></span><br><span class="line">  <span class="comment">// iteration.</span></span><br><span class="line">  <span class="built_in">UnrollLoops</span>(graph);</span><br><span class="line">  <span class="built_in">EliminateCommonSubexpression</span>(graph);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">CheckInplace</span>(graph);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>I will not go deep into most of these passes in this note, interested readers can read them at <code>torch/csrc/jit/passes/</code>.</p><h2 id="ProfilingGraphExecutorImpl"><a href="#ProfilingGraphExecutorImpl" class="headerlink" title="ProfilingGraphExecutorImpl"></a>ProfilingGraphExecutorImpl</h2><p>Now let’s take a look at the profiling graph executor. We also start from <code>getPlanFor</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">ExecutionPlan <span class="title">ProfilingGraphExecutorImpl::getPlanFor</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    Stack&amp; stack,</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">size_t</span> remaining_bailout_depth)</span> </span>&#123;</span><br><span class="line">  <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(compile_mutex)</span></span>;</span><br><span class="line">  <span class="built_in">GRAPH_DEBUG</span>(<span class="string">&quot;Running ProfilingGraphExecutorImpl &quot;</span>, <span class="keyword">this</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (optimized_plan_) &#123;</span><br><span class="line">    <span class="keyword">return</span> *optimized_plan_;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// simple executor</span></span><br><span class="line">  <span class="keyword">if</span> (remaining_bailout_depth == <span class="number">0</span>) &#123;</span><br><span class="line">    <span class="keyword">auto</span> copy = graph-&gt;<span class="built_in">copy</span>();</span><br><span class="line">    <span class="built_in">runProfilingInsensitiveOptimizations</span>(copy);</span><br><span class="line">    <span class="built_in">GRAPH_DUMP</span>(<span class="string">&quot;Optimized SimpleExecutor Graph : &quot;</span>, copy);</span><br><span class="line">    optimized_plan_ = <span class="built_in">ExecutionPlan</span>(copy);</span><br><span class="line">    <span class="keyword">return</span> *optimized_plan_;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// if a profiling graph hasn&#x27;t been created yet</span></span><br><span class="line">  <span class="keyword">if</span> (!pr_) &#123;</span><br><span class="line">    <span class="keyword">auto</span> copy = graph-&gt;<span class="built_in">copy</span>();</span><br><span class="line">    <span class="built_in">runProfilingInsensitiveOptimizations</span>(copy);</span><br><span class="line">    pr_ = ProfilingRecord::<span class="built_in">instrumentGraph</span>(copy);</span><br><span class="line">    <span class="keyword">auto</span> pr_copy = pr_-&gt;<span class="built_in">graph</span>()-&gt;<span class="built_in">copy</span>();</span><br><span class="line">    <span class="built_in">GRAPH_DUMP</span>(<span class="string">&quot;Profiled Graph: &quot;</span>, pr_copy);</span><br><span class="line">    profiling_plan_ = <span class="built_in">ExecutionPlan</span>(pr_copy);</span><br><span class="line">    <span class="comment">// fall-through</span></span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">// profile until a graph is ready</span></span><br><span class="line">  <span class="keyword">if</span> (!pr_-&gt;<span class="built_in">ready</span>()) &#123;</span><br><span class="line">    <span class="keyword">return</span> *profiling_plan_;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> copy = pr_-&gt;<span class="built_in">graph</span>()-&gt;<span class="built_in">copy</span>();</span><br><span class="line">  <span class="built_in">runProfilingOptimizations</span>(copy);</span><br><span class="line">  <span class="comment">// cache</span></span><br><span class="line">  optimized_plan_ = <span class="built_in">ExecutionPlan</span>(copy, remaining_bailout_depth);</span><br><span class="line">  <span class="keyword">return</span> *optimized_plan_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>We can see that there is a “bailout” mechanism with limited depth, if the depth is reached, then the executor just do “profiling insentive optimizations”. But what is “bailout”, what is “profiling”, and what is “profiling insentive optimizations”? It is still not clear at this point. We can also see that <code>remaining_bailout_depth</code> is passed to the constructor of <code>ExecutionPlan</code>, so the bailout mechanism must be a collaboration of interpreter and graph executor. The optimizations are:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">ProfilingGraphExecutorImpl::runProfilingOptimizations</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    std::shared_ptr&lt;Graph&gt;&amp; copy)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (!<span class="built_in">getGraphExecutorOptimize</span>()) &#123;</span><br><span class="line">    <span class="built_in">LowerGradOf</span>(*copy);</span><br><span class="line">    <span class="built_in">runRequiredPasses</span>(copy);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">InsertGuards</span>(copy);</span><br><span class="line">  <span class="built_in">LowerGradOf</span>(*copy);</span><br><span class="line">  <span class="built_in">EliminateRedundantGuards</span>(copy);</span><br><span class="line">  <span class="built_in">InsertBailOuts</span>(copy);</span><br><span class="line">  <span class="built_in">GRAPH_DUMP</span>(<span class="string">&quot;After InsertBailOuts: &quot;</span>, copy);</span><br><span class="line">  <span class="built_in">specializeAutogradZero</span>(*copy);</span><br><span class="line"></span><br><span class="line">  <span class="built_in">runRequiredPasses</span>(copy);</span><br><span class="line">  <span class="built_in">ConstantPropagation</span>(copy);</span><br><span class="line">  <span class="built_in">runOptimization</span>(copy);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">needsGradientInProfilingMode</span>(copy-&gt;<span class="built_in">block</span>())) &#123;</span><br><span class="line">    <span class="keyword">auto</span> diff_nodes = <span class="built_in">CreateAutodiffSubgraphs</span>(</span><br><span class="line">        copy,</span><br><span class="line">        <span class="built_in">getAutodiffSubgraphInlining</span>() ? autodiffSubgraphNodeThreshold : <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">for</span> (Node* dnode : diff_nodes) &#123;</span><br><span class="line">      <span class="keyword">auto</span> diff_graph = std::<span class="built_in">move</span>(dnode-&gt;<span class="built_in">g</span>(attr::Subgraph));</span><br><span class="line">      Gradient gradient = <span class="built_in">differentiate</span>(diff_graph);</span><br><span class="line">      <span class="built_in">runOptimization</span>(gradient.f);</span><br><span class="line">      <span class="comment">// run non diff optimization on the forward graph</span></span><br><span class="line">      <span class="built_in">runNondiffOptimization</span>(gradient.f);</span><br><span class="line">      <span class="built_in">packGradient</span>(gradient, dnode);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">InlineAutodiffSubgraphs</span>(</span><br><span class="line">        copy,</span><br><span class="line">        <span class="built_in">getAutodiffSubgraphInlining</span>() ? autodiffSubgraphInlineThreshold : <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">runNondiffOptimization</span>(copy);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">EliminateDeadCode</span>(copy);</span><br><span class="line">  <span class="built_in">GRAPH_DUMP</span>(<span class="string">&quot;Optimized Graph : &quot;</span>, copy);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">ProfilingGraphExecutorImpl::runProfilingInsensitiveOptimizations</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    std::shared_ptr&lt;Graph&gt;&amp; copy)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">LowerGradOf</span>(*copy);</span><br><span class="line">  <span class="built_in">GRAPH_DUMP</span>(<span class="string">&quot;runProfilingInsensitiveOptimizations&quot;</span>, copy);</span><br><span class="line">  <span class="comment">// clear any residual undefinedness</span></span><br><span class="line">  <span class="comment">// as double backward graph inputs&#x27;</span></span><br><span class="line">  <span class="comment">// may carry over undefinedness</span></span><br><span class="line">  <span class="comment">// from profiled backward graphs</span></span><br><span class="line">  <span class="built_in">ClearUndefinedness</span>(copy);</span><br><span class="line">  <span class="built_in">runRequiredPasses</span>(copy);</span><br><span class="line">  <span class="keyword">if</span> (!<span class="built_in">getGraphExecutorOptimize</span>()) &#123;</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="built_in">DecomposeOps</span>(copy);</span><br><span class="line">  <span class="built_in">ConstantPropagation</span>(copy);</span><br><span class="line">  <span class="built_in">EliminateDeadCode</span>(copy);</span><br><span class="line">  <span class="built_in">EliminateCommonSubexpression</span>(copy);</span><br><span class="line">  <span class="built_in">ConstantPooling</span>(copy);</span><br><span class="line">  <span class="built_in">PeepholeOptimize</span>(copy);</span><br><span class="line">  <span class="built_in">EliminateDeadCode</span>(copy);</span><br><span class="line">  <span class="built_in">CheckInplace</span>(copy);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>We will postpone the reading of profiling and bailout after we have read how the interpreter works.</p><h1 id="PyTorch-IR-–-gt-Interpreter-Instructions"><a href="#PyTorch-IR-–-gt-Interpreter-Instructions" class="headerlink" title="PyTorch IR –&gt; Interpreter Instructions"></a>PyTorch IR –&gt; Interpreter Instructions</h1><p>Now it’s time to look at <code>ExecutionPlan</code> defined at <code>graph_executor.h</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ExecutionPlan</span> &#123;</span></span><br><span class="line">  <span class="built_in">ExecutionPlan</span>() = <span class="keyword">default</span>;</span><br><span class="line">  <span class="built_in">ExecutionPlan</span>(</span><br><span class="line">      std::shared_ptr&lt;Graph&gt; graph,</span><br><span class="line">      <span class="keyword">size_t</span> remaining_bailout_depth = <span class="number">0</span>)</span><br><span class="line">      : <span class="built_in">code</span>(graph, remaining_bailout_depth), <span class="built_in">graph</span>(std::<span class="built_in">move</span>(graph)) &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">operator</span> <span class="title">bool</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">static_cast</span>&lt;<span class="keyword">bool</span>&gt;(graph);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  Code code;</span><br><span class="line">  std::shared_ptr&lt;Graph&gt; graph;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>It just convert the graph into an object of <code>Code</code>, and the running is done by <code>InterpreterState</code>.</p><p><code>Code</code> and <code>InterpreterState</code> are defined in <code>torch/csrc/jit/interpreter.&#123;h,cpp&#125;</code>. These two classes are just a wrapper of its implementations:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">Code::<span class="built_in">Code</span>(<span class="keyword">const</span> std::shared_ptr&lt;Graph&gt;&amp; graph, <span class="keyword">size_t</span> remaining_bailout_depth)</span><br><span class="line">    : <span class="built_in">pImpl</span>(<span class="keyword">new</span> <span class="built_in">CodeImpl</span>(graph, remaining_bailout_depth)) &#123;&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">InterpreterState::<span class="built_in">InterpreterState</span>(<span class="keyword">const</span> Code&amp; code)</span><br><span class="line">    : <span class="built_in">pImpl</span>(c10::make_intrusive&lt;InterpreterStateImpl&gt;(code)) &#123;&#125;</span><br></pre></td></tr></table></figure><p><code>CodeImpl</code> is a long struct, but quite logical. A selected list of fields it has is listed below:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PreprocessGraph preprocess;</span><br><span class="line">std::vector&lt;Instruction&gt; instructions;</span><br></pre></td></tr></table></figure><p>Its constructor is:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">CodeImpl</span>(<span class="keyword">const</span> std::shared_ptr&lt;Graph&gt;&amp; graph, <span class="keyword">size_t</span> remaining_bailout_depth)</span><br><span class="line">    : <span class="built_in">preprocess_</span>(*graph),</span><br><span class="line">      <span class="built_in">current_node_</span>(preprocess_.graph-&gt;<span class="built_in">return_node</span>()),</span><br><span class="line">      <span class="built_in">remaining_bailout_depth_</span>(remaining_bailout_depth) &#123;</span><br><span class="line">  graph_ = preprocess_.graph;</span><br><span class="line">  n_outputs = graph_-&gt;<span class="built_in">outputs</span>().<span class="built_in">size</span>();</span><br><span class="line">  <span class="keyword">if</span> (n_outputs == <span class="number">1</span>) &#123;</span><br><span class="line">    return_type_ = graph-&gt;<span class="built_in">outputs</span>().<span class="built_in">at</span>(<span class="number">0</span>)-&gt;<span class="built_in">type</span>();</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    return_type_ = TupleType::<span class="built_in">create</span>(</span><br><span class="line">        <span class="built_in">fmap</span>(graph-&gt;<span class="built_in">outputs</span>(), [](<span class="keyword">const</span> Value* v) &#123; <span class="keyword">return</span> v-&gt;<span class="built_in">type</span>(); &#125;));</span><br><span class="line">  &#125;</span><br><span class="line">  n_inputs = graph_-&gt;<span class="built_in">inputs</span>().<span class="built_in">size</span>();</span><br><span class="line">  <span class="comment">// std::cout &lt;&lt; *graph_ &lt;&lt; &quot;\n&quot;;</span></span><br><span class="line">  <span class="built_in">emitCodeForBlock</span>(graph_-&gt;<span class="built_in">block</span>());</span><br><span class="line">  <span class="built_in">insertInstruction</span>(RET);</span><br><span class="line">  <span class="comment">// we deferred the emission of bailout blocks so they appear at the end</span></span><br><span class="line">  <span class="comment">// emit them now and patch up the jumps</span></span><br><span class="line">  <span class="built_in">insertBailoutBlocks</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Clearly we can see what it does is:</p><ol><li>preprocess the graph, and then</li><li>emit instructions for interpreter.</li><li>insert bailout blocks</li></ol><p>The preprocessing of graph is very well explained in the beginning of file:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Before we translate to intepreter instructions, we do</span></span><br><span class="line"><span class="comment">// some preprocessing of the graph to turn it into a form that is closer</span></span><br><span class="line"><span class="comment">// to what the instructions will look like.</span></span><br><span class="line"><span class="comment">// In particular we:</span></span><br><span class="line"><span class="comment">// *  Computes whether a input to a node is the last use, so we can issue MOVE</span></span><br><span class="line"><span class="comment">//    rather than LOAD instructions.</span></span><br><span class="line"><span class="comment">// *  Drop nodes are inserted for any node that is unused to create a dummy use</span></span><br><span class="line"><span class="comment">//    that will cause the interpreter to free the node.</span></span><br><span class="line"><span class="comment">//    A drop node just pops its input off the stack to  ensure the interpreter</span></span><br><span class="line"><span class="comment">//    releases references to nodes that are never used. Drop nodes are also</span></span><br><span class="line"><span class="comment">//    inserted when the last use of a node is in some conditionally run control</span></span><br><span class="line"><span class="comment">//    flow (e.g. one side of an If) and the interpreter must free the node only</span></span><br><span class="line"><span class="comment">//    after the control flow has reconverged</span></span><br><span class="line"><span class="comment">// Outputs are:</span></span><br><span class="line"><span class="comment">// * graph - the post processed copy of g</span></span><br><span class="line"><span class="comment">// * move_flags[n] - a list of booleans, one for each input,</span></span><br><span class="line"><span class="comment">//   indicating whether this is the last use of the value. The interpreter</span></span><br><span class="line"><span class="comment">//   should generate a move rather than a copy in this case.</span></span><br></pre></td></tr></table></figure><p>The <code>emitCodeForBlock</code> emits instructions:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">emitCodeForBlock</span><span class="params">(Block* block)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">emitNodeAtBlockLevel</span>(block-&gt;<span class="built_in">param_node</span>());</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> node : block-&gt;<span class="built_in">nodes</span>()) &#123;</span><br><span class="line">    <span class="built_in">emitNodeAtBlockLevel</span>(node);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">emitNodeAtBlockLevel</span>(block-&gt;<span class="built_in">return_node</span>());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Since the nodes are topologically sorted, we just need to iterate the linked list and generate code for each node.</p><p>The <code>emitNodeAtBlockLevel</code> is:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">emitNodeAtBlockLevel</span><span class="params">(Node* node)</span> </span>&#123;</span><br><span class="line">  <span class="function">WithCurrentNode <span class="title">guard</span><span class="params">(&amp;current_node_, node)</span></span>;</span><br><span class="line">  <span class="built_in"><span class="keyword">switch</span></span> (node-&gt;<span class="built_in">kind</span>()) &#123;</span><br><span class="line">    <span class="keyword">case</span> prim::Constant:</span><br><span class="line">      <span class="built_in">emitConstant</span>(node);</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> prim::Return:</span><br><span class="line">      <span class="built_in">emitLoadInputs</span>(node-&gt;<span class="built_in">inputs</span>());</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">      <span class="keyword">if</span> (!preprocess_.can_emit_inline[node]) &#123;</span><br><span class="line">        <span class="built_in">emitNode</span>(node);</span><br><span class="line">        <span class="built_in">emitStoreOutputs</span>(node);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>where <code>emitNode</code> dispatches according to node kind:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">emitNode</span><span class="params">(Node* node)</span> </span>&#123;</span><br><span class="line">  <span class="function">WithCurrentNode <span class="title">guard</span><span class="params">(&amp;current_node_, node)</span></span>;</span><br><span class="line">  <span class="built_in"><span class="keyword">switch</span></span> (node-&gt;<span class="built_in">kind</span>()) &#123;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">      <span class="built_in">emitOperator</span>(node);</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> prim::Drop:</span><br><span class="line">      <span class="built_in">emitDrop</span>(node-&gt;<span class="built_in">inputs</span>());</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> prim::Constant:</span><br><span class="line">      <span class="built_in">emitConstant</span>(node);</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> prim::If:</span><br><span class="line">      <span class="built_in">emitIf</span>(node);</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> prim::Loop:</span><br><span class="line">      <span class="built_in">emitLoop</span>(node);</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> aten::wait:</span><br><span class="line">      <span class="built_in">emitWait</span>(node);</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> prim::Param:</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> prim::CallFunction:</span><br><span class="line">      <span class="built_in">emitCall</span>(</span><br><span class="line">          node-&gt;<span class="built_in">inputs</span>().<span class="built_in">at</span>(<span class="number">0</span>)-&gt;<span class="built_in">type</span>()-&gt;expect&lt;FunctionType&gt;()-&gt;<span class="built_in">function</span>(),</span><br><span class="line">          node-&gt;<span class="built_in">inputs</span>().<span class="built_in">slice</span>(<span class="number">1</span>));</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> prim::CallMethod:</span><br><span class="line">      <span class="keyword">if</span> (<span class="keyword">auto</span> class_type = node-&gt;<span class="built_in">inputs</span>().<span class="built_in">at</span>(<span class="number">0</span>)-&gt;<span class="built_in">type</span>()-&gt;cast&lt;ClassType&gt;()) &#123;</span><br><span class="line">        <span class="built_in">emitCall</span>(class_type-&gt;<span class="built_in">getMethod</span>(node-&gt;<span class="built_in">s</span>(attr::name)), node-&gt;<span class="built_in">inputs</span>());</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="built_in">emitInterfaceCall</span>(node-&gt;<span class="built_in">s</span>(attr::name), node-&gt;<span class="built_in">inputs</span>());</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> prim::BailOut:</span><br><span class="line">      <span class="built_in">emitBailOut</span>(node);</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> prim::GetAttr:</span><br><span class="line">      <span class="built_in">emitGetAttr</span>(node);</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">case</span> prim::SetAttr:</span><br><span class="line">      <span class="built_in">emitSetAttr</span>(node);</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Let’s further take a look at <code>emitOperator</code>, <code>emitIf</code> and <code>emitBailOut</code> as example.</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">emitOperator</span><span class="params">(Node* node)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">emitLoadInputs</span>(node-&gt;<span class="built_in">inputs</span>());</span><br><span class="line">  <span class="built_in">insertInstruction</span>(OP, operator_table_.<span class="built_in">size</span>());</span><br><span class="line">  operator_table_.<span class="built_in">emplace_back</span>(<span class="built_in">getOperation</span>(node));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">emitIf</span><span class="params">(Node* node)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">emitLoadInputs</span>(node-&gt;<span class="built_in">inputs</span>());</span><br><span class="line">  <span class="keyword">size_t</span> start_if = instructions_.<span class="built_in">size</span>();</span><br><span class="line">  <span class="built_in">insertInstruction</span>(JF, <span class="number">0</span>); <span class="comment">// dummy offset to be filled in</span></span><br><span class="line">  <span class="built_in">emitCodeForBlock</span>(node-&gt;<span class="built_in">blocks</span>().<span class="built_in">at</span>(<span class="number">0</span>));</span><br><span class="line">  <span class="built_in">insertInstruction</span>(JMP, <span class="number">0</span>); <span class="comment">// dummy offset</span></span><br><span class="line">  <span class="keyword">size_t</span> start_else = instructions_.<span class="built_in">size</span>();</span><br><span class="line">  instructions_[start_if].X = start_else - start_if;</span><br><span class="line">  <span class="built_in">emitCodeForBlock</span>(node-&gt;<span class="built_in">blocks</span>().<span class="built_in">at</span>(<span class="number">1</span>));</span><br><span class="line">  instructions_[start_else - <span class="number">1</span>].X = instructions_.<span class="built_in">size</span>() - (start_else - <span class="number">1</span>);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>these two are pretty standard compiler implementations.</p><p>Now let’s take a look at how bailout works:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">emitBailOut</span><span class="params">(Node* node)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> jf_index = <span class="built_in">emitGuard</span>(node);</span><br><span class="line">  <span class="keyword">auto</span> unoptimized_graph = node-&gt;<span class="built_in">inputs</span>().<span class="built_in">at</span>(<span class="number">0</span>)-&gt;<span class="built_in">node</span>()-&gt;<span class="built_in">g</span>(attr::Subgraph);</span><br><span class="line">  <span class="comment">// note, guaded input is already loaded onto the stack</span></span><br><span class="line">  <span class="comment">// for GUARD instruction</span></span><br><span class="line">  <span class="built_in">emitLoadInputs</span>(node-&gt;<span class="built_in">inputs</span>().<span class="built_in">slice</span>(<span class="number">2</span>));</span><br><span class="line">  <span class="built_in">insertInstruction</span>(TAIL_CALL, function_table_.<span class="built_in">size</span>());</span><br><span class="line">  <span class="built_in">TORCH_INTERNAL_ASSERT</span>(node-&gt;<span class="built_in">kind</span>() == prim::BailOut);</span><br><span class="line">  <span class="keyword">auto</span> bailout_index = node-&gt;<span class="built_in">i</span>(attr::index);</span><br><span class="line">  <span class="built_in">TORCH_INTERNAL_ASSERT</span>(bailout_index &gt;= <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> build_bailout_graph = [bailout_index,</span><br><span class="line">                              unoptimized_graph](Function &amp;func) &#123;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">BuildBailOutGraphFrom</span>(bailout_index, unoptimized_graph, func.<span class="built_in">graph</span>());</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> empty_graph = std::make_shared&lt;Graph&gt;();</span><br><span class="line">  <span class="keyword">auto</span> func = torch::make_unique&lt;Function&gt;(</span><br><span class="line">      <span class="string">&quot;bailout&quot;</span>, empty_graph, build_bailout_graph);</span><br><span class="line">  function_table_.<span class="built_in">emplace_back</span>(func.<span class="built_in">get</span>());</span><br><span class="line">  bailout_functions_.<span class="built_in">emplace_back</span>(std::<span class="built_in">move</span>(func));</span><br><span class="line">  <span class="built_in">createBailoutBlock</span>(jf_index);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>The <code>emitBailOut</code> seems to save an unoptimized graph and make a function out of it. We will not go into details about this right now, because this requires a big picture of how the profiling is done in the executor. For now we just want a brief organization of the code generally. But we will do a thorough read of this in <a href="#profiling">a separate section</a>. We will move to the virtual machine right now.</p><h1 id="The-Virtual-Machine"><a href="#The-Virtual-Machine" class="headerlink" title="The Virtual Machine"></a>The Virtual Machine</h1><p><code>InterpreterStateImpl</code> is the virtual machine that executes instructions. The related functions are located here:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">(Stack&amp; stack)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">runImpl</span>(stack)) &#123;</span><br><span class="line">    future_-&gt;<span class="built_in">wait</span>();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">auto</span> num_outputs = frames.<span class="built_in">front</span>().function-&gt;n_outputs;</span><br><span class="line">    <span class="keyword">if</span> (num_outputs == <span class="number">1</span>) &#123;</span><br><span class="line">      <span class="built_in">push</span>(stack, future_-&gt;<span class="built_in">value</span>());</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">auto</span> tuple = future_-&gt;<span class="built_in">value</span>().<span class="built_in">toTuple</span>();</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">const</span> IValue&amp; value : tuple-&gt;<span class="built_in">elements</span>()) &#123;</span><br><span class="line">        <span class="built_in">push</span>(stack, value);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>which invoke <code>runImpl</code> to run asynchronously and wait for the async run to finish(therefore sync in effect). The <code>runImpl</code> looks like:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">bool</span> <span class="title">runImpl</span><span class="params">(Stack&amp; stack)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// if we have never run before, then we might have to return the</span></span><br><span class="line">  <span class="comment">// stack when we suspend, record where it starts so we return the right</span></span><br><span class="line">  <span class="comment">// stack</span></span><br><span class="line">  <span class="keyword">if</span> (stack_start_ == <span class="number">-1</span>) &#123;</span><br><span class="line">    <span class="built_in">TORCH_INTERNAL_ASSERT</span>(stack.<span class="built_in">size</span>() &gt;= frames.<span class="built_in">back</span>().function-&gt;n_inputs);</span><br><span class="line">    stack_start_ = stack.<span class="built_in">size</span>() - frames.<span class="built_in">back</span>().function-&gt;n_inputs;</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="comment">// during restarts, all of the stack is always our own, so we leave</span></span><br><span class="line">    <span class="comment">// nothing</span></span><br><span class="line">    stack_start_ = <span class="number">0</span>;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">ActiveFrame <span class="title">af</span><span class="params">(frames.back())</span></span>;</span><br><span class="line">  <span class="keyword">try</span> &#123;</span><br><span class="line">    <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line"><span class="comment">//         std::cout &lt;&lt; &quot;RUNNING &quot;;</span></span><br><span class="line"><span class="comment">//         frames.back().function-&gt;dump(std::cout, af.pc);</span></span><br><span class="line">      Instruction inst = af.instructions[af.pc];</span><br><span class="line">      <span class="built_in"><span class="keyword">switch</span></span> (inst.op) &#123;</span><br><span class="line">        <span class="keyword">case</span> OP:</span><br><span class="line">          af.operators[inst.X](stack);</span><br><span class="line">          ++af.pc;</span><br><span class="line">          <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> OPN:</span><br><span class="line">          <span class="built_in">AT_ERROR</span>(<span class="string">&quot;OPN is currently supported in mobile mode only.&quot;</span>);</span><br><span class="line">          <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> LOAD:</span><br><span class="line">          stack.<span class="built_in">emplace_back</span>(<span class="built_in">reg</span>(inst.X));</span><br><span class="line">          ++af.pc;</span><br><span class="line">          <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> MOVE:</span><br><span class="line">          stack.<span class="built_in">emplace_back</span>(std::<span class="built_in">move</span>(<span class="built_in">reg</span>(inst.X)));</span><br><span class="line">          ++af.pc;</span><br><span class="line">          <span class="keyword">break</span>;</span><br><span class="line">        <span class="keyword">case</span> STORE: ...</span><br><span class="line">        <span class="keyword">case</span> STOREN: ...</span><br><span class="line">        <span class="keyword">case</span> DROP: ...</span><br><span class="line">        <span class="keyword">case</span> DROPR: ...</span><br><span class="line">        <span class="keyword">case</span> LOADC: ...</span><br><span class="line">        <span class="keyword">case</span> GET_ATTR: ...</span><br><span class="line">        <span class="keyword">case</span> SET_ATTR: ...</span><br><span class="line">        <span class="keyword">case</span> JF: ...</span><br><span class="line">        <span class="keyword">case</span> JMP: ...</span><br><span class="line">        <span class="keyword">case</span> LOOP: ...</span><br><span class="line">        <span class="keyword">case</span> CALL:</span><br><span class="line">        <span class="keyword">case</span> INTERFACE_CALL: ...</span><br><span class="line">        <span class="keyword">case</span> RET: ...</span><br><span class="line">        <span class="keyword">case</span> WAIT: ...</span><br><span class="line">        <span class="keyword">case</span> FAIL_GUARD: ...</span><br><span class="line">        <span class="keyword">case</span> GUARD: ...</span><br><span class="line">        <span class="keyword">case</span> TAIL_CALL: ...</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125; <span class="built_in"><span class="keyword">catch</span></span> (std::exception&amp; e) &#123;</span><br><span class="line">    frames.<span class="built_in">back</span>().pc = af.pc;</span><br><span class="line">    <span class="keyword">bool</span> is_jit_exception = <span class="keyword">dynamic_cast</span>&lt;JITException*&gt;(&amp;e);</span><br><span class="line">    <span class="built_in">handleError</span>(<span class="built_in">ExceptionMessage</span>(e), is_jit_exception);</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>There is nothing special, just mimicking the behavior of processors.</p><h1 id="Profiling-and-bailout"><a href="#Profiling-and-bailout" class="headerlink" title="Profiling and bailout"></a><a name="profiling"></a>Profiling and bailout</h1><p>A good starting point for profiling and bailout is the official design doc <a href="https://github.com/pytorch/pytorch/blob/master/torch/csrc/jit/docs/OVERVIEW.md"><code>torch/csrc/jit/docs/OVERVIEW.md</code></a>:</p><figure class="highlight markdown"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="section"># Profiling Programs</span></span><br><span class="line"></span><br><span class="line"><span class="code">`prim::profile`</span> nodes are inserted on every <span class="strong">**use**</span> of a value by <span class="code">`ProfilingRecord::instrumentBlock`</span>. Every <span class="code">`prim::profile`</span> node runs a lambda that uses a captured, initial type value and the type of an incoming tensor and merges the two into a refined <span class="code">`TensorType`</span></span><br><span class="line"></span><br><span class="line"><span class="code">`prim::profile`</span> nodes are replaced with <span class="code">`prim::Guard`</span> nodes by <span class="code">`InsertGuards`</span>. <span class="code">`prim::Guard`</span> nodes are inserted to guarantee that beyond the guard a guarded tensor will always be of the profiled shape. This guarantee will enable optimizations and codegens to generate more efficient code.</span><br><span class="line"></span><br><span class="line">JIT attempts to reduce the number of <span class="code">`prim::Guard`</span> nodes as these nodes may interefere with optimizations.</span><br><span class="line"><span class="bullet">*</span> First, <span class="code">`GuardElimination::moveGuardsToDefs`</span> tries to move <span class="code">`prim::Guards`</span> to their definitions, so the guards guarding the same tensor follow the definition directly or another guard on the same tensor. This step is done in</span><br><span class="line"><span class="bullet">*</span> This ordering allows us to <span class="strong">**coalesce**</span> (done in <span class="code">`GuardElimination::coalesceGuards`</span>) multiple guards into a single one.</span><br><span class="line"><span class="bullet">*</span> After guards are  <span class="strong">**coaslesced**</span> , <span class="code">`GuardElimination::eliminateGuards`</span> attempts to eliminate more guards as follows: it inspects each operation and its inputs. It checks if inputs to the operation are guarded and also if the operation produces the consistent shapes given the guarded inputs. For example, if two inputs to <span class="code">`add`</span> are guaranteed to be of shape <span class="code">`(2, 3) `</span>, the output shape will also always be <span class="code">`(2, 3)`</span> If this property holds, JIT is allowed to remove the guard guarding operation&#x27;s output.</span><br><span class="line"></span><br><span class="line">Lastly, JIT needs to be handle cases when the assumptions about tensor shapes fail at runtime. To handle guard failures, JIT needs to be able to run the original code i.e. the code  that doesn&#x27;t rely on assumptions about shapes. As guards can be inserted and moved (by Optimizer) at/to arbitrary points in a computional graph, JIT needs to be able to resume execution starting from those arbitrary points onward.</span><br><span class="line"></span><br><span class="line"><span class="code">`InsertBailoutNodes`</span> builds deoptimized versions of the original computational graph, that contain the rest of computations starting from their corresponding guard failure poins and, also, captures live values needed to execute those deoptimized graphs. In other words, the pass replaces <span class="code">`prim::Guard`</span> nodes with <span class="code">`prim::BailOut`</span> nodes which have the<span class="code">`attr::Subgraph`</span> attributes set to the deoptimized versions of the  remaining computations at their corresponding <span class="code">`prim::Guard`</span>s.</span><br></pre></td></tr></table></figure><p>After getting the rough idea, let’s look at the code. In <code>ProfilingGraphExecutorImpl::getPlanFor</code>, which runs everytime when we execute a graph, we have:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// if a profiling graph hasn&#x27;t been created yet</span></span><br><span class="line"><span class="keyword">if</span> (!pr_) &#123;</span><br><span class="line">  <span class="keyword">auto</span> copy = graph-&gt;<span class="built_in">copy</span>();</span><br><span class="line">  <span class="built_in">runProfilingInsensitiveOptimizations</span>(copy);</span><br><span class="line">  pr_ = ProfilingRecord::<span class="built_in">instrumentGraph</span>(copy);</span><br><span class="line">  <span class="keyword">auto</span> pr_copy = pr_-&gt;<span class="built_in">graph</span>()-&gt;<span class="built_in">copy</span>();</span><br><span class="line">  <span class="built_in">GRAPH_DUMP</span>(<span class="string">&quot;Profiled Graph: &quot;</span>, pr_copy);</span><br><span class="line">  profiling_plan_ = <span class="built_in">ExecutionPlan</span>(pr_copy);</span><br><span class="line">  <span class="comment">// fall-through</span></span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// profile until a graph is ready</span></span><br><span class="line"><span class="keyword">if</span> (!pr_-&gt;<span class="built_in">ready</span>()) &#123;</span><br><span class="line">  <span class="keyword">return</span> *profiling_plan_;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>From this, we can see that for the first few runs the graph executor instrument graph with profiling nodes and execute until no more profiling is needed.<br>Let go deep to see how the graph is instrumented. <code>ProfilingRecord::instrumentGraph</code> is defined in <code>torch/csrc/jit/profiling_record.cpp</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::unique_ptr&lt;ProfilingRecord&gt; <span class="title">ProfilingRecord::instrumentGraph</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    <span class="keyword">const</span> std::shared_ptr&lt;Graph&gt;&amp; graph)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> new_g = graph-&gt;<span class="built_in">copy</span>();</span><br><span class="line">  <span class="keyword">auto</span> pr = std::unique_ptr&lt;ProfilingRecord&gt;(<span class="keyword">new</span> <span class="built_in">ProfilingRecord</span>(new_g));</span><br><span class="line">  <span class="keyword">auto</span> raw_pr = pr.<span class="built_in">get</span>();</span><br><span class="line">  <span class="built_in">unprofileGraphInputs</span>(new_g);</span><br><span class="line">  <span class="built_in">unprofileBlock</span>(new_g-&gt;<span class="built_in">block</span>());</span><br><span class="line">  pr-&gt;<span class="built_in">instrumentBlock</span>(new_g-&gt;<span class="built_in">block</span>());</span><br><span class="line"></span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> i : new_g-&gt;<span class="built_in">return_node</span>()-&gt;<span class="built_in">inputs</span>()) &#123;</span><br><span class="line">    <span class="keyword">if</span> (i-&gt;<span class="built_in">type</span>()-&gt;<span class="built_in">isSubtypeOf</span>(TensorType::<span class="built_in">get</span>())) &#123;</span><br><span class="line">      pr-&gt;<span class="built_in">insertShapeProfile</span>(new_g-&gt;<span class="built_in">return_node</span>(), i);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  std::function&lt;<span class="built_in"><span class="keyword">void</span></span>(Stack&amp;)&gt; counter = [raw_pr](Stack&amp;) &#123;</span><br><span class="line">    std::lock_guard&lt;std::mutex&gt; <span class="built_in">lock</span>(raw_pr-&gt;mutex_);</span><br><span class="line">    <span class="keyword">if</span> (raw_pr-&gt;profiling_count_ &gt; <span class="number">0</span>)</span><br><span class="line">    &#123;</span><br><span class="line">        raw_pr-&gt;profiling_count_--;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> pop = pr-&gt;<span class="built_in">createProfileNode</span>(counter, &#123;&#125;);</span><br><span class="line">  new_g-&gt;<span class="built_in">appendNode</span>(pop);</span><br><span class="line">  <span class="keyword">return</span> pr;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Combining the knowledge from the docs, we can see that this function calls <code>instrumentBlock</code> to instruct the main block of the graph. Let’s now move on to <code>instrumentBlock</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">ProfilingRecord::instrumentBlock</span><span class="params">(Block *block)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> it = block-&gt;<span class="built_in">nodes</span>().<span class="built_in">begin</span>(); it != block-&gt;<span class="built_in">nodes</span>().<span class="built_in">end</span>(); ++it) &#123;</span><br><span class="line">    <span class="keyword">auto</span> n = *it;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> i : n-&gt;<span class="built_in">inputs</span>()) &#123;</span><br><span class="line">      <span class="keyword">if</span> (!i-&gt;<span class="built_in">type</span>()-&gt;<span class="built_in">isSubtypeOf</span>(TensorType::<span class="built_in">get</span>()) ||</span><br><span class="line">          i-&gt;<span class="built_in">node</span>()-&gt;<span class="built_in">kind</span>() == prim::profile) &#123;</span><br><span class="line">        <span class="keyword">continue</span>;</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      <span class="built_in">insertShapeProfile</span>(n, i);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> b : n-&gt;<span class="built_in">blocks</span>()) &#123;</span><br><span class="line">      <span class="built_in">instrumentBlock</span>(b);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>we can see that it iterate the whole graph, and for every node that has tensor input, we do <code>insertShapeProfile</code>. And we also recursively instrument blocks. The <code>ProfilingRecord</code> looks like:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">ProfilingRecord::insertShapeProfile</span><span class="params">(Node *n, Value *i)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> pn = <span class="built_in">createProfileNode</span>(<span class="literal">nullptr</span>, &#123;i&#125;);</span><br><span class="line">  <span class="keyword">auto</span> pno = pn-&gt;<span class="built_in">addOutput</span>();</span><br><span class="line">  <span class="keyword">bool</span> first = <span class="literal">true</span>;</span><br><span class="line">  pno-&gt;<span class="built_in">setType</span>(TensorType::<span class="built_in">get</span>());</span><br><span class="line">  std::function&lt;<span class="built_in"><span class="keyword">void</span></span>(Stack &amp;)&gt; shape_profiler = [<span class="keyword">this</span>, pno,</span><br><span class="line">                                                 first](Stack &amp;stack) <span class="keyword">mutable</span> &#123;</span><br><span class="line">    IValue t;</span><br><span class="line">    <span class="built_in">pop</span>(stack, t);</span><br><span class="line">    <span class="keyword">if</span> (t.<span class="built_in">isTensor</span>()) &#123;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">if</span> (t.<span class="built_in">toTensor</span>().<span class="built_in">defined</span>()) &#123;</span><br><span class="line">        <span class="keyword">auto</span> pttp = <span class="built_in">tensorTypeInCurrentExecutionContext</span>(t.<span class="built_in">toTensor</span>());</span><br><span class="line">        <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(<span class="keyword">this</span>-&gt;mutex_)</span></span>;</span><br><span class="line">        <span class="keyword">if</span> (<span class="keyword">auto</span> type = pno-&gt;<span class="built_in">type</span>()-&gt;cast&lt;TensorType&gt;()) &#123;</span><br><span class="line">          <span class="keyword">if</span> (!first) &#123;</span><br><span class="line">            pttp = pttp-&gt;<span class="built_in">merge</span>(type);</span><br><span class="line">          &#125;</span><br><span class="line">          pno-&gt;<span class="built_in">setType</span>(pttp);</span><br><span class="line">          first = <span class="literal">false</span>;</span><br><span class="line">        &#125;</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        pno-&gt;<span class="built_in">setType</span>(TensorType::<span class="built_in">get</span>()-&gt;<span class="built_in">withUndefined</span>());</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// passing t through</span></span><br><span class="line">    <span class="built_in">push</span>(stack, t);</span><br><span class="line"></span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  pn-&gt;<span class="built_in">setCallback</span>(shape_profiler);</span><br><span class="line">  pn-&gt;<span class="built_in">insertBefore</span>(n);</span><br><span class="line">  n-&gt;<span class="built_in">replaceInputWith</span>(i, pn-&gt;<span class="built_in">output</span>());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>We can see that it inserts a profile node before, and the call back of the proflie node set the the lambda <code>shape_profiler</code>. We will stop going deeper on <code>ProfilingRecord</code> at here since we already have a rough idea on what it does.</p><p>Now let’s move to <code>InsertGuards</code> which is called in <code>ProfilingGraphExecutorImpl::runProfilingOptimizations</code>, which is called in <code>ProfilingGraphExecutorImpl::getPlanFor</code>. The <code>InsertGuards</code> is defined at <code>torch/csrc/jit/passes/insert_guards.cpp</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">GuardInserter</span> &#123;</span></span><br><span class="line">  <span class="built_in">GuardInserter</span>(std::shared_ptr&lt;Graph&gt; graph) : <span class="built_in">graph_</span>(std::<span class="built_in">move</span>(graph)) &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="built_in">insertGuards</span>(graph_-&gt;<span class="built_in">block</span>());</span><br><span class="line">    <span class="built_in">removeProfilingNodes</span>(graph_-&gt;<span class="built_in">block</span>());</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line"> <span class="keyword">private</span>:</span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">removeProfilingNodes</span><span class="params">(Block* b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> it = b-&gt;<span class="built_in">nodes</span>().<span class="built_in">begin</span>(); it != b-&gt;<span class="built_in">nodes</span>().<span class="built_in">end</span>(); it++) &#123;</span><br><span class="line">      <span class="keyword">if</span> (it-&gt;<span class="built_in">kind</span>() == prim::profile) &#123;</span><br><span class="line">        it.<span class="built_in">destroyCurrent</span>();</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (Block* ib : it-&gt;<span class="built_in">blocks</span>()) &#123;</span><br><span class="line">          <span class="built_in">removeProfilingNodes</span>(ib);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">insertGuards</span><span class="params">(Block* b)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">auto</span> it = b-&gt;<span class="built_in">nodes</span>().<span class="built_in">begin</span>(); it != b-&gt;<span class="built_in">nodes</span>().<span class="built_in">end</span>(); it++) &#123;</span><br><span class="line">      <span class="keyword">auto</span> n = *it;</span><br><span class="line">      <span class="keyword">if</span> (n-&gt;<span class="built_in">kind</span>() == prim::profile &amp;&amp; n-&gt;<span class="built_in">outputs</span>().<span class="built_in">size</span>() == <span class="number">1</span>) &#123;</span><br><span class="line">        <span class="keyword">auto</span> pttp = n-&gt;<span class="built_in">output</span>()-&gt;<span class="built_in">type</span>()-&gt;cast&lt;TensorType&gt;();</span><br><span class="line">        <span class="keyword">if</span> (pttp) &#123;</span><br><span class="line">          <span class="keyword">auto</span> guard = graph_-&gt;<span class="built_in">create</span>(prim::Guard, &#123;n-&gt;<span class="built_in">input</span>()&#125;, <span class="number">1</span>);</span><br><span class="line">          <span class="keyword">auto</span> go = guard-&gt;<span class="built_in">output</span>();</span><br><span class="line">          go-&gt;<span class="built_in">setType</span>(pttp);</span><br><span class="line">          guard-&gt;<span class="built_in">insertBefore</span>(n);</span><br><span class="line">          n-&gt;<span class="built_in">output</span>()-&gt;<span class="built_in">replaceAllUsesWith</span>(go);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          <span class="comment">// we didn&#x27;t go down this path i.e</span></span><br><span class="line">          <span class="comment">// no profiling information is available</span></span><br><span class="line">          n-&gt;<span class="built_in">output</span>()-&gt;<span class="built_in">replaceAllUsesWith</span>(n-&gt;<span class="built_in">input</span>());</span><br><span class="line">        &#125;</span><br><span class="line">        it.<span class="built_in">destroyCurrent</span>();</span><br><span class="line">      &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">        <span class="keyword">for</span> (Block* ib : n-&gt;<span class="built_in">blocks</span>()) &#123;</span><br><span class="line">          <span class="built_in">insertGuards</span>(ib);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  std::shared_ptr&lt;Graph&gt; graph_;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">InsertGuards</span><span class="params">(std::shared_ptr&lt;Graph&gt; graph)</span> </span>&#123;</span><br><span class="line">  <span class="function">GuardInserter <span class="title">gi</span><span class="params">(std::move(graph))</span></span>;</span><br><span class="line">  gi.<span class="built_in">run</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>It is just a standard recursive graph traverse that replaces insert the guard before profiling node and then remove all profiling nodes.</p><p>We will skip the part on how the guard is moved for optimization. Let’s move on how the guard is converted to bailouts. From the document, we know that is is done at <code>InsertBailoutNodes</code>, but after some searching, we can not find <code>InsertBailoutNodes</code>. The docs must already been outdated. But after looking around, we see in <code>ProfilingGraphExecutorImpl::runProfilingOptimizations</code>, we have</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">InsertGuards</span>(copy);</span><br><span class="line"><span class="built_in">LowerGradOf</span>(*copy);</span><br><span class="line"><span class="built_in">EliminateRedundantGuards</span>(copy);</span><br><span class="line"><span class="built_in">InsertBailOuts</span>(copy);</span><br><span class="line"><span class="built_in">GRAPH_DUMP</span>(<span class="string">&quot;After InsertBailOuts: &quot;</span>, copy);</span><br></pre></td></tr></table></figure><p>So it must be <code>InsertBailOuts</code> actually doing the job. This function is defined at <code>torch/csrc/jit/passes/bailout_graph.cpp</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">InsertBailOuts</span><span class="params">(std::shared_ptr&lt;Graph&gt; graph)</span> </span>&#123;</span><br><span class="line">  <span class="function">BailOutInserter <span class="title">ibo</span><span class="params">(std::move(graph))</span></span>;</span><br><span class="line">  ibo.<span class="built_in">run</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// `BailOutInserter` replaces prim::Guard nodes with</span></span><br><span class="line"><span class="comment">// prim::BailOut nodes that allow interpreter to</span></span><br><span class="line"><span class="comment">// resume execution of the unoptimized(deoptimized)</span></span><br><span class="line"><span class="comment">// version of an original graph from a particular point</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">BailOutInserter</span> &#123;</span></span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">BailOutInserter</span><span class="params">(std::shared_ptr&lt;Graph&gt; graph)</span></span></span><br><span class="line"><span class="function">      : graph_(std::move(graph)), bailout_index_(<span class="number">0</span>) &#123;</span>&#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    liveness_sets_ = <span class="built_in">BuildLivenessSets</span>(graph_);</span><br><span class="line">    <span class="built_in">insertBailOuts</span>(graph_-&gt;<span class="built_in">block</span>());</span><br><span class="line">    <span class="built_in">replaceGuardsWithBailouts</span>();</span><br><span class="line">    <span class="comment">// embed a full original graph</span></span><br><span class="line">    <span class="built_in">addUnoptimizedFuncToBailouts</span>();</span><br><span class="line">  &#125;</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>We see a term <code>liveness</code>, this is an analysis in compilers, and it is explained in <a href="https://en.wikipedia.org/wiki/Live_variable_analysis">Wikipedia: Live variable analysis</a>. We won’t go deep into it, all we need to know is its definition:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">A variable is live at some point if it holds a value that may be needed in the future, or equivalently if its value may be read before the next time the variable is written to.</span><br></pre></td></tr></table></figure><p>Now, let’s look at <code>insertBailOuts</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Inserts prim::BailOut nodes for every prim::Guard</span></span><br><span class="line"><span class="comment">// Each BailOut point takes the set of inputs live</span></span><br><span class="line"><span class="comment">// at that particular execution point.</span></span><br><span class="line"><span class="comment">// An input is live if it&#x27;s used beyond the guard/BailOut</span></span><br><span class="line"><span class="comment">// point to compute graph&#x27;s outputs</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">insertBailOuts</span><span class="params">(Block* b)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> it = b-&gt;<span class="built_in">nodes</span>().<span class="built_in">begin</span>(); it != b-&gt;<span class="built_in">nodes</span>().<span class="built_in">end</span>(); ++it) &#123;</span><br><span class="line">    <span class="keyword">if</span> (it-&gt;<span class="built_in">kind</span>() == prim::Guard) &#123;</span><br><span class="line">      <span class="keyword">auto</span> bailout_node = b-&gt;<span class="built_in">owningGraph</span>()-&gt;<span class="built_in">create</span>(prim::BailOut);</span><br><span class="line">      bailouts_.<span class="built_in">push_back</span>(bailout_node);</span><br><span class="line"></span><br><span class="line">      <span class="keyword">const</span> <span class="keyword">auto</span>&amp; live_inputs = liveness_sets_[*it];</span><br><span class="line"></span><br><span class="line">      <span class="comment">// guarded inputs come first</span></span><br><span class="line">      <span class="comment">// currently, there&#x27;s always one guarded input</span></span><br><span class="line">      bailout_node-&gt;<span class="built_in">addInput</span>(it-&gt;<span class="built_in">input</span>());</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">auto</span> li : live_inputs) &#123;</span><br><span class="line">        <span class="comment">// Guarded inputs have already been added</span></span><br><span class="line">        <span class="comment">// Also, skip some inputs that BailOutGraphBuilder can</span></span><br><span class="line">        <span class="comment">// materialize into bailout graphs directly</span></span><br><span class="line">        <span class="keyword">if</span> (!<span class="built_in">shouldBeCapturedInByBailOut</span>(li-&gt;<span class="built_in">node</span>()) || li == it-&gt;<span class="built_in">input</span>()) &#123;</span><br><span class="line">          <span class="keyword">continue</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        bailout_node-&gt;<span class="built_in">addInput</span>(li);</span><br><span class="line">      &#125;</span><br><span class="line"></span><br><span class="line">      bailout_node-&gt;<span class="built_in">output</span>()-&gt;<span class="built_in">setType</span>(it-&gt;<span class="built_in">output</span>()-&gt;<span class="built_in">type</span>());</span><br><span class="line">      bailout_node-&gt;<span class="built_in">i_</span>(attr::index, bailout_index_++);</span><br><span class="line">      <span class="comment">// we can&#x27;t immediately replace nodes since this action will corrupt</span></span><br><span class="line">      <span class="comment">// the liveness sets of following BailOut nodes if any of their</span></span><br><span class="line">      <span class="comment">// arguments are BailOut nodes themselves</span></span><br><span class="line">      replacements_.<span class="built_in">insert</span>(&#123;it-&gt;<span class="built_in">output</span>(), bailout_node-&gt;<span class="built_in">output</span>()&#125;);</span><br><span class="line"></span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      <span class="keyword">for</span> (<span class="keyword">auto</span> ib : it-&gt;<span class="built_in">blocks</span>()) &#123;</span><br><span class="line">        <span class="built_in">insertBailOuts</span>(ib);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>We can see that it recursively traverse the graph, at each <code>prim::Guard</code> node, it creates a new node of kind <code>prim::BailOut</code> and set its input to live input at current point. The newly created node is not inserted into the graph, but stored at <code>replacements_</code> instead.</p><p>Then in <code>replaceGuardsWithBailouts</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// replace each prim::Guard</span></span><br><span class="line"><span class="comment">// with its corresponding prim::BailOut</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">replaceGuardsWithBailouts</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">auto</span> e : replacements_) &#123;</span><br><span class="line">    e.first-&gt;<span class="built_in">replaceAllUsesWith</span>(e.second);</span><br><span class="line">    e.second-&gt;<span class="built_in">node</span>()-&gt;<span class="built_in">insertAfter</span>(e.first-&gt;<span class="built_in">node</span>());</span><br><span class="line">    e.first-&gt;<span class="built_in">node</span>()-&gt;<span class="built_in">destroy</span>();</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Knowing that how the guards are converted to bailout nodes, the last step is to see how the bailout node is executed. From previous reading, we know that instructions for different kind of nodes are emitted in the constructor of <code>CodeImpl</code>, which calls <code>emitCodeForBlock</code>, which calls <code>emitNodeAtBlockLevel</code>, which calls <code>emitNode</code> which dispatch on node kind and calls <code>emitBailOut</code> for bailout nodes.</p><p>Now let’s go back to see <code>emitBailOut</code> again:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">emitBailOut</span><span class="params">(Node* node)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> jf_index = <span class="built_in">emitGuard</span>(node);</span><br><span class="line">  <span class="keyword">auto</span> unoptimized_graph = node-&gt;<span class="built_in">inputs</span>().<span class="built_in">at</span>(<span class="number">0</span>)-&gt;<span class="built_in">node</span>()-&gt;<span class="built_in">g</span>(attr::Subgraph);</span><br><span class="line">  <span class="comment">// note, guaded input is already loaded onto the stack</span></span><br><span class="line">  <span class="comment">// for GUARD instruction</span></span><br><span class="line">  <span class="built_in">emitLoadInputs</span>(node-&gt;<span class="built_in">inputs</span>().<span class="built_in">slice</span>(<span class="number">2</span>));</span><br><span class="line">  <span class="built_in">insertInstruction</span>(TAIL_CALL, function_table_.<span class="built_in">size</span>());</span><br><span class="line">  <span class="built_in">TORCH_INTERNAL_ASSERT</span>(node-&gt;<span class="built_in">kind</span>() == prim::BailOut);</span><br><span class="line">  <span class="keyword">auto</span> bailout_index = node-&gt;<span class="built_in">i</span>(attr::index);</span><br><span class="line">  <span class="built_in">TORCH_INTERNAL_ASSERT</span>(bailout_index &gt;= <span class="number">0</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> build_bailout_graph = [bailout_index,</span><br><span class="line">                              unoptimized_graph](Function &amp;func) &#123;</span><br><span class="line"></span><br><span class="line">    <span class="built_in">BuildBailOutGraphFrom</span>(bailout_index, unoptimized_graph, func.<span class="built_in">graph</span>());</span><br><span class="line">  &#125;;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> empty_graph = std::make_shared&lt;Graph&gt;();</span><br><span class="line">  <span class="keyword">auto</span> func = torch::make_unique&lt;Function&gt;(</span><br><span class="line">      <span class="string">&quot;bailout&quot;</span>, empty_graph, build_bailout_graph);</span><br><span class="line">  function_table_.<span class="built_in">emplace_back</span>(func.<span class="built_in">get</span>());</span><br><span class="line">  bailout_functions_.<span class="built_in">emplace_back</span>(std::<span class="built_in">move</span>(func));</span><br><span class="line">  <span class="built_in">createBailoutBlock</span>(jf_index);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>We can see that inside <code>emitBailOut</code>, it first <code>emitGuard</code> then emit a <code>TAIL_CALL</code> instruction. The <code>emitGuard</code> is:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">size_t</span> <span class="title">emitGuard</span><span class="params">(Node* node)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// unoptimized graph is at index 0</span></span><br><span class="line">  <span class="comment">// guarded input is at index 1</span></span><br><span class="line">  <span class="comment">// the rest of args follow</span></span><br><span class="line">  <span class="built_in">emitLoadInputs</span>(node-&gt;<span class="built_in">inputs</span>().<span class="built_in">slice</span>(<span class="number">1</span>, <span class="number">1</span>));</span><br><span class="line">  <span class="built_in">insertInstruction</span>(GUARD, type_table_.<span class="built_in">size</span>());</span><br><span class="line"></span><br><span class="line">  type_table_.<span class="built_in">emplace_back</span>(node-&gt;<span class="built_in">outputs</span>().<span class="built_in">at</span>(<span class="number">0</span>)-&gt;<span class="built_in">type</span>());</span><br><span class="line">  <span class="built_in">insertInstruction</span>(JF, <span class="number">0</span> <span class="comment">/* to be patched */</span>);</span><br><span class="line"></span><br><span class="line">  <span class="keyword">return</span> instructions_.<span class="built_in">size</span>() - <span class="number">1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>we can see that it emits a <code>GUARD</code> instruction and a <code>JF</code> instruction. The definition of how each instruction is executed is defined in <code>InterpreterStateImpl::runImpl</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="keyword">case</span> JF:</span><br><span class="line">  af.pc += (<span class="built_in">pop</span>(stack).<span class="built_in">toBool</span>()) ? <span class="number">1</span> : inst.X;</span><br><span class="line">  <span class="keyword">break</span>;</span><br><span class="line">.......</span><br><span class="line"><span class="keyword">case</span> GUARD: &#123;</span><br><span class="line">  <span class="keyword">auto</span> t = stack.<span class="built_in">back</span>().<span class="built_in">toTensor</span>();</span><br><span class="line">  <span class="keyword">const</span> TypePtr&amp; expected = af.types[inst.X];</span><br><span class="line">  <span class="keyword">bool</span> comp = expected-&gt;cast&lt;TensorType&gt;()</span><br><span class="line">                  -&gt;<span class="built_in">isCompatibleWithInCurrentExecutionContext</span>(t);</span><br><span class="line">  <span class="built_in">push</span>(stack, comp);</span><br><span class="line">  ++af.pc;</span><br><span class="line">&#125; <span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> TAIL_CALL: &#123;</span><br><span class="line">  <span class="built_in">GRAPH_DEBUG</span>(<span class="string">&quot;running TAIL_CALL for &quot;</span>, inst.X);</span><br><span class="line">  af.functions[inst.X]-&gt;<span class="built_in">ensure_defined</span>();</span><br><span class="line">  <span class="keyword">size_t</span> remaining_bailout_depth =</span><br><span class="line">      frames.<span class="built_in">back</span>().function-&gt;remaining_bailout_depth_ &gt; <span class="number">0</span></span><br><span class="line">      ? frames.<span class="built_in">back</span>().function-&gt;remaining_bailout_depth_ - <span class="number">1</span></span><br><span class="line">      : <span class="number">0</span>;</span><br><span class="line">  <span class="keyword">const</span> Code&amp; code = af.functions[inst.X]</span><br><span class="line">                          -&gt;<span class="built_in">get_executor</span>()</span><br><span class="line">                          .<span class="built_in">getPlanFor</span>(stack, remaining_bailout_depth)</span><br><span class="line">                          .code;</span><br><span class="line">  <span class="keyword">size_t</span> num_inputs = code.<span class="built_in">num_inputs</span>();</span><br><span class="line">  <span class="keyword">size_t</span> base_pointer = frames.<span class="built_in">back</span>().base_pointer;</span><br><span class="line">  <span class="built_in">TORCH_INTERNAL_ASSERT</span>(stack.<span class="built_in">size</span>() &gt;= num_inputs);</span><br><span class="line">  <span class="keyword">size_t</span> inputs_start = stack.<span class="built_in">size</span>() - num_inputs;</span><br><span class="line">  <span class="keyword">for</span> (<span class="keyword">size_t</span> i = <span class="number">0</span>; i &lt; num_inputs; ++i) &#123;</span><br><span class="line">    stack.<span class="built_in">at</span>(base_pointer + i) =</span><br><span class="line">        std::<span class="built_in">move</span>(stack.<span class="built_in">at</span>(inputs_start + i));</span><br><span class="line">  &#125;</span><br><span class="line">  stack.<span class="built_in">resize</span>(base_pointer + num_inputs);</span><br><span class="line">  <span class="built_in">leaveFrame</span>();</span><br><span class="line">  <span class="built_in">enterFrame</span>(code, base_pointer);</span><br><span class="line">  af = <span class="built_in">ActiveFrame</span>(frames.<span class="built_in">back</span>());</span><br><span class="line">&#125; <span class="keyword">break</span>;</span><br></pre></td></tr></table></figure><p>We will not worry about how the jump address is computed, but we can see that the big picture is: check if the tensor on the stack is compatible, if not, then call the backup unoptimized graph.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;This is my note for reading PyTorch’s JIT source. We begin by looking at &lt;code&gt;torch.jit.script&lt;/code&gt; to find the frontend that compiles the Python code into PyTorch’s tree views, and the backend that compiles tree views to graph. We also read the structure of the internal representation of PyTorch’s graph. Finally we go to graph executor to look at how the computation graph is further compiled into instructions and how the action of these instructions are defined and executed.&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="https://zasdfgbnm.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习" scheme="https://zasdfgbnm.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="PyTorch" scheme="https://zasdfgbnm.github.io/tags/PyTorch/"/>
    
    <category term="深度学习" scheme="https://zasdfgbnm.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>GRE、Wireguard、网桥与IPv6</title>
    <link href="https://zasdfgbnm.github.io/2018/11/09/GRE%E3%80%81Wireguard%E3%80%81%E7%BD%91%E6%A1%A5%E4%B8%8EIPv6/"/>
    <id>https://zasdfgbnm.github.io/2018/11/09/GRE%E3%80%81Wireguard%E3%80%81%E7%BD%91%E6%A1%A5%E4%B8%8EIPv6/</id>
    <published>2018-11-09T13:13:39.000Z</published>
    <updated>2021-04-04T05:17:59.763Z</updated>
    
    <content type="html"><![CDATA[<p>讲一下我自己给自己搭建的网络环境吧，好友很久之前就劝我写了，但那时候工作生活乐趣无穷，没心思写博客，反倒最近烦心事多了，想找点东西换换脑子转移注意力，就跑来写博客了。其实我最早开始玩网络，是因为被学校无端指责我用P2P软件，我去跟他们理论无果，他们拒绝向我提供任何的报告，而我也拒绝向他们认错，于是他们把我家里网“封锁”了，而我在寻求一种穿透他们的方法。经过不断的尝试与探索，我自己的网络结构也演化了好几代，反倒变得比被学校断网之前方便了好多，也引入了IPv6的支持，这样我就可以随时用手机访问自己家里任何设备的任何端口了。</p><p>我之所以搭建自己的网络环境，主要是为了提供如下的功能：</p><ul><li>把我在世界各地的局域网连接到一起去，让他们互相之间能够访问到，并且为这些网络提供可路由的公网IPv6地址。</li><li>突破一些封锁，比如学校的DHNet给我的断网，以及天朝的GFW。</li><li>在外面的便携设备，可以随时连接进来，获得可路由的公网IPv6地址。</li></ul><span id="more"></span><h1 id="网络结构的设计"><a href="#网络结构的设计" class="headerlink" title="网络结构的设计"></a>网络结构的设计</h1><p>网络采用中心化了的设计，示意图见下面。 一台位于Linode的主机充当了核心的管理节点。这个核心节点维护一个网桥，所有的子网或者设备想要加入，都是通过GRETAP桥接进这个网桥来实现的。如果是单个设备接入的话，那么这台设备直接通过GRETAP接入就好。如果是一个子网想要接入的话，除了建立GRETAP以外，还需要将其跟子网桥接起来。</p><img src="/2018/11/09/GRE%E3%80%81Wireguard%E3%80%81%E7%BD%91%E6%A1%A5%E4%B8%8EIPv6/design.svg" class="" title="网络的结构"><p>GRE协议本身无法穿透NAT，而不幸的是，由于IPv4地址的枯竭，现在的运营商很少会给你公网的IPv4地址了。PPTP改版过的GRE协议，是可以透过NAT的，然而笔者费尽周折，都没找到如何在Linux上抛开PPTP单用其GRE。为了解决NAT的问题，有两种解决方案，一种是通过<a href="https://datatracker.ietf.org/meeting/91/materials/slides-91-nvo3-1">Generic UDP Encapsulation(GUE)</a>来封装GRE包，另一种则是新建一个VPN链接，然后让GRE包直接通过VPN链接跟核心节点相连。</p><p>对于新建VPN连接的方案，笔者强烈推荐<a href="https://www.wireguard.com/">Wireguard</a>。之所以推荐Wireguard，首先是因为它配置相当简单，而且工具链符合Unix哲学：传统的VPN软件，在连接上VPN的时候，会自动改你的路由表、DNS设置等等，让你的一切连接都走VPN；而对于那些移动设备（办公室的电脑、随身携带的笔记本），我新建VPN只是希望能够提供一个虚拟通道，实现到核心节点的免NAT访问而已，我并不需要修改IPv4流量原来的走向。而且，Wireguard对移动设备非常友好，自带漫游功能，笔记本在一个地方连上Wireguard，然后带走去别的地方，连接上不同的网络，Wireguard也不会中断，而是自动漫游过去。</p><p>GRETAP跟网桥都设置好了以后，所有的设备之间就可以在layer2互相访问了，真正要使用的话，再处理好IP地址就好。IPv4的地址跟IPv6的地址的处理方式非常不一样。IPv6的设置异常简单，由于地址空间充足，我直接跟Linode要了个<code>/64</code>的网段，这个网段是我可以自己随意使用的，发往这个前缀下的任何IP地址的包，Linode都会帮我路由到我的那个核心节点去，这样我的核心节点只需要帮忙转发即可。由于layer2已经能互相访问了，我只需要在核心节点设置好<a href="https://en.wikipedia.org/wiki/Radvd">radvd</a>向网桥发送Router Advertisement来广播自己的前缀就好，设备收听到了Router Advertisement，就会自动设置好自己的IPv6地址跟路由信息。</p><p>IPv4的地址的配置则要复杂很多，由于IPv4地址空间太少，到处都是负责分配私有地址的DHCP服务器，数据包想要去Internet，也得NAT了才能上路。我这里采用半手动的管理的策略，我选择了<code>192.168.x.y</code>这个网段作为整个大网络的网段，对这个网段再进一步划分，想要连接进来的不同的子网，被人为设置了不同的<code>x</code>值，这些子网的路由器的DHCP服务器被设置了<code>/24</code>的前缀长度，也就是路由器只会分配不同的<code>y</code>值。核心节点我就给了它一个<code>192.168.0.1</code>这个地址，而各个子网，都人为选取不同的非零的<code>x</code>值。在每个子网的路由器上，把子网的大小设置为<code>/16</code>，但是DHCP服务器的前缀长度仍然保持<code>/24</code>，这样，子网内的设备想要访问其他子网的时候，包先会被路由到路由器中，然后路由器通过ARP映射表找到相应目标的Mac地址，然后通过layer2直接把包送到目标。如果想要翻墙，可以额外添加针对GeoIP的路由。如果想要整个子网都用核心节点当出口，那么只需要在路由器的路由表中，把核心节点的公网IP的路由人为标记为从WAN的interface出，然后把网关设置为<code>192.168.0.1</code>即可。</p><h1 id="核心节点的配置"><a href="#核心节点的配置" class="headerlink" title="核心节点的配置"></a>核心节点的配置</h1><p>按照我们设计的网络结构，核心的配置主要需要做这样一些事情：</p><ul><li>给一些想要通过Wireguard连接进来的主机建立Wireguard连接</li><li>给所有连接进来的设备或者子网设置GRETAP</li><li>设置一个网桥，把所有这一大堆GRETAP给桥接到一起</li></ul><p>Talk is cheap，我们直接来看code。笔者的所有操作系统都是Archlinux。公网的出口是<code>eth0</code>。</p><p>先来设置好变量：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">SERVER_IP=1.2.3.4  <span class="comment"># 保护隐私，此处隐去真实地址</span></span><br><span class="line">SERVER_IP6=2001:db8::1  <span class="comment"># 保护隐私，此处隐去真实地址</span></span><br><span class="line">SERVER_LOCAL_IP=192.168.0.1</span><br><span class="line">INTERFACE=eth0</span><br></pre></td></tr></table></figure><h2 id="网络基础设置的配置"><a href="#网络基础设置的配置" class="headerlink" title="网络基础设置的配置"></a>网络基础设置的配置</h2><p>然后就是启用IP Forward、Masquerade以及跟TCPMSS了，这些都是玩隧道跟软路由的常识了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">sysctl -w net.ipv4.conf.all.forwarding=1</span><br><span class="line">sysctl -w net.ipv6.conf.all.forwarding=1</span><br><span class="line">iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADE</span><br><span class="line">iptables -t mangle -A POSTROUTING -p tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu</span><br><span class="line">ip6tables -t mangle -A POSTROUTING -p tcp --tcp-flags SYN,RST SYN -j TCPMSS --clamp-mss-to-pmtu</span><br></pre></td></tr></table></figure><p>然后就是设置好bridge：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ip link add taps_bridge <span class="built_in">type</span> bridge</span><br><span class="line">ip link <span class="built_in">set</span> taps_bridge up</span><br><span class="line">ip address add <span class="variable">$SERVER_IP6</span>/64 dev taps_bridge</span><br><span class="line">ip address add <span class="variable">$SERVER_LOCAL_IP</span>/16 dev taps_bridge</span><br></pre></td></tr></table></figure><p>接下来就是配置radvd，先来看配置文件<code>/etc/radvd.conf</code>：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">interface taps_bridge</span><br><span class="line">&#123;</span><br><span class="line">AdvSendAdvert on;</span><br><span class="line"></span><br><span class="line">prefix 2001:db8::&#x2F;64</span><br><span class="line">&#123;</span><br><span class="line">AdvOnLink on;</span><br><span class="line">AdvAutonomous on;</span><br><span class="line">AdvRouterAddr on;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line">RDNSS 2001:4860:4860:0:0:0:0:8888</span><br><span class="line">&#123;</span><br><span class="line">&#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>上面的DNS服务器用的是<a href="https://developers.google.com/speed/public-dns/docs/using">Google Public DNS</a>。写好配置文件以后，就可以开启radvd了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemctl start radvd.service</span><br></pre></td></tr></table></figure><h2 id="GRE-over-GUE的配置"><a href="#GRE-over-GUE的配置" class="headerlink" title="GRE over GUE的配置"></a>GRE over GUE的配置</h2><p>接下来设置GUE封装的GRE的连接，每个连接都要来上这么一段：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">FOU_PORT=5555</span><br><span class="line">REMOTE_PUBLIC_IP=2.3.4.5  <span class="comment"># 保护隐私，此处隐去真实地址</span></span><br><span class="line">REMOTE_PUBLIC_PORT=5555</span><br><span class="line"></span><br><span class="line">modprobe fou</span><br><span class="line">ip fou add port <span class="variable">$FOU_PORT</span> gue</span><br><span class="line"></span><br><span class="line">ip link add name gretap_over_gue <span class="built_in">type</span> gretap \</span><br><span class="line">    remote <span class="variable">$REMOTE_PUBLIC_IP</span> <span class="built_in">local</span> <span class="variable">$SERVER_IP</span> \</span><br><span class="line">    ttl 225 encap gue encap-sport <span class="variable">$FOU_PORT</span> encap-dport <span class="variable">$REMOTE_PUBLIC_PORT</span></span><br><span class="line">ip link <span class="built_in">set</span> gretap_over_gue up</span><br><span class="line">ip link <span class="built_in">set</span> gretap_over_gue master taps_bridge</span><br></pre></td></tr></table></figure><p>上面的<code>FOU_PORT</code>是GUE接收端用的UDP端口号，关于这方面的更好的介绍，可以参见<a href="https://lwn.net/Articles/614348/">lwn.net对Foo over UDP的介绍</a>。<code>REMOTE_PUBLIC_IP</code>跟<code>REMOTE_PUBLIC_PORT</code>分别是要连接到核心节点的客户端的公网IP跟NAT转换后的端口。</p><h2 id="Wireguard的配置"><a href="#Wireguard的配置" class="headerlink" title="Wireguard的配置"></a>Wireguard的配置</h2><p>这里我们使用Wireguard作为我们的VPN解决方案。这里Wireguard的作用，仅仅是给GRETAP提供一个能够穿透NAT的皮而已，所有的上层流量都是封装进GRETAP里面去的，不直接走Wireguard。所以Wireguard的配置上，只需要设置好IP地址就好，不需要复杂的路由表设置。在Wireguard的interface的配置上，我们把核心节点设置成<code>172.16.0.1</code>，其他的设备分别赋予<code>172.16.0.2</code>、<code>172.16.0.3</code>、……。</p><p>Wireguard的配置教程参见<a href="https://www.wireguard.com/quickstart/">官网</a>. 这里我们的wireguard.conf文件如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">[Interface]</span><br><span class="line">PrivateKey &#x3D; aAaAaAaAaAaAaAaAaAaAaAaAaAaAaAaAaAaAaAaAaAa&#x3D;  # 此处为了隐私略去真实私钥</span><br><span class="line">#PublicKey &#x3D; JFcFDUEB0ZUVhUhfYPNT8Ma9FoeMVf2x03CYFyE5jTg&#x3D;</span><br><span class="line">ListenPort &#x3D; 23450</span><br><span class="line"></span><br><span class="line"># 每个要连接进来的节点都要有一个[Peer]条目</span><br><span class="line"></span><br><span class="line">[Peer]</span><br><span class="line"># office desktop</span><br><span class="line">PublicKey &#x3D; 8TYMD&#x2F;dmDLgbAp1VSvhemGEe6e8Yr&#x2F;7GGjRCAce6ZGA&#x3D;</span><br><span class="line">AllowedIPs &#x3D; 172.16.0.2&#x2F;32</span><br><span class="line"></span><br><span class="line">[Peer]</span><br><span class="line"># Macbook Pro</span><br><span class="line">PublicKey &#x3D; fgZdAIh6&#x2F;KIzpTYZtjtirOKPAujfmCqumPb+F7XGzmM&#x3D;</span><br><span class="line">AllowedIPs &#x3D; 172.16.0.3&#x2F;32</span><br><span class="line"></span><br><span class="line">[Peer]</span><br><span class="line"># Yichen</span><br><span class="line">PublicKey &#x3D; uYQJAsHtvClr2gnnUdMRZyzhTv6N9lY5L9ASZLW+AQM&#x3D;</span><br><span class="line">AllowedIPs &#x3D; 172.16.0.4&#x2F;32</span><br></pre></td></tr></table></figure><p>有了配置文件，接下来就是配置Wireguard的interface了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ip link add dev wg_vpns <span class="built_in">type</span> wireguard</span><br><span class="line">wg setconf wg_vpns wireguard.conf</span><br><span class="line">ip link <span class="built_in">set</span> up dev wg_vpns</span><br><span class="line">ip addr add 172.16.0.1/24 dev wg_vpns</span><br></pre></td></tr></table></figure><h2 id="GRE-in-Wireguard的配置"><a href="#GRE-in-Wireguard的配置" class="headerlink" title="GRE in Wireguard的配置"></a>GRE in Wireguard的配置</h2><p>Wireguard已经实现了一个新的子网，直接利用新的子网内的IP地址，建立GRE就行：</p><p>下面几行命令，需要在核心节点上执行多次，每次分别设置不同的主机。每台Wireguard连接进来的主机都需要在核心节点上按照下面的方法设置。下面仅以我的办公室的电脑为例：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># gretap for office desktop</span></span><br><span class="line">ip link add name gretap_office <span class="built_in">type</span> gretap \</span><br><span class="line">    remote 172.16.0.2 <span class="built_in">local</span> 172.16.0.1 ttl 225</span><br><span class="line">ip link <span class="built_in">set</span> gretap_office up</span><br><span class="line">ip link <span class="built_in">set</span> gretap_office master taps_bridge</span><br></pre></td></tr></table></figure><p>至此，核心节点的配置就已经结束了。</p><h1 id="客户节点的配置"><a href="#客户节点的配置" class="headerlink" title="客户节点的配置"></a>客户节点的配置</h1><p>客户节点的配置要比核心节点简单很多，只需要建立GRETAP即可。取决于不同的情况，可能还需要建立网桥跟Wireguard。</p><h2 id="GRE-over-GUE客户节点的配置"><a href="#GRE-over-GUE客户节点的配置" class="headerlink" title="GRE over GUE客户节点的配置"></a>GRE over GUE客户节点的配置</h2><p>笔者的GRE over GUE主要用在家里，用于把家里的子网跟核心节点桥接起来。笔者用来做这件事情的设备，是一台位于子网中的刷了openwrt的家用路由器。这台路由器关闭了DHCP服务器、Masquerade等家用路由器中标准的功能，IP地址固定在<code>192.168.88.6</code>，然后运行了一个名叫<code>br-lan</code>的网桥，把所有的有线跟无线网桥接起来（家用无线路由器默认都是会有网桥的，不需要人为启用啥）。</p><p>首先需要做的是建立GRE：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">SERVER_IP=1.2.3.4  <span class="comment"># 保护隐私，此处隐去真实地址</span></span><br><span class="line">LOCAL_IP=192.168.88.6</span><br><span class="line">FOU_PORT=5555</span><br><span class="line"></span><br><span class="line">modprobe fou</span><br><span class="line">ip fou add port <span class="variable">$FOU_PORT</span> gue</span><br><span class="line">ip link add name gretap_over_gue <span class="built_in">type</span> gretap \</span><br><span class="line">    remote <span class="variable">$SERVER_IP</span> <span class="built_in">local</span> <span class="variable">$LOCAL_IP</span> \</span><br><span class="line">    ttl 225 encap gue encap-sport <span class="variable">$FOU_PORT</span> encap-dport <span class="variable">$FOU_PORT</span></span><br><span class="line">ip link <span class="built_in">set</span> gretap_over_gue up</span><br></pre></td></tr></table></figure><p>然后把GRE添加到已有的网桥中即可：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ip link <span class="built_in">set</span> gretap_over_gue master br-lan</span><br></pre></td></tr></table></figure><h2 id="GRE-in-Wireguard客户节点的配置"><a href="#GRE-in-Wireguard客户节点的配置" class="headerlink" title="GRE in Wireguard客户节点的配置"></a>GRE in Wireguard客户节点的配置</h2><p>首先是配置文件wireguard.conf：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[Interface]</span><br><span class="line">PrivateKey &#x3D; bBbBbBbBbBbBbBbBbBbBbBbBbBbBbBbBbBbBbBbBbBb&#x3D;  # 此处为了隐私略去真实私钥</span><br><span class="line">#PublicKey &#x3D; 8TYMD&#x2F;dmDLgbAp1VSvhemGEe6e8Yr&#x2F;7GGjRCAce6ZGA&#x3D;</span><br><span class="line">ListenPort &#x3D; 3243</span><br><span class="line"></span><br><span class="line">[Peer]</span><br><span class="line">PublicKey &#x3D; JFcFDUEB0ZUVhUhfYPNT8Ma9FoeMVf2x03CYFyE5jTg&#x3D;</span><br><span class="line">AllowedIPs &#x3D; 0.0.0.0&#x2F;0</span><br><span class="line">EndPoint &#x3D; 1.2.3.4:23450</span><br></pre></td></tr></table></figure><p>然后建立Wireguard连接：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ip link add dev wg_linode <span class="built_in">type</span> wireguard</span><br><span class="line">wg setconf wg_linode wireguard.conf</span><br><span class="line">ip link <span class="built_in">set</span> up dev wg_linode</span><br><span class="line">ip addr add 172.16.0.2/24 dev wg_linode</span><br></pre></td></tr></table></figure><p>然后就是建立GRETAP：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">ip link add name gretap_linode address 12:ab:34:<span class="built_in">cd</span>:56:ef <span class="built_in">type</span> gretap \</span><br><span class="line">    remote 172.16.0.1 <span class="built_in">local</span> 172.16.0.2 ttl 225</span><br><span class="line">ip link <span class="built_in">set</span> gretap_linode up</span><br><span class="line">ethtool --offload gretap_linode tx off</span><br></pre></td></tr></table></figure><p>这里面我人为指定了GRETAP的Mac地址，如果不这么做的话，Linux就会给你随机分配一个，这样就导致每次连接的Mac地址都不一样。而IPv6地址则是根据Mac地址通过<a href="https://community.cisco.com/t5/network-architecture-documents/understanding-ipv6-eui-64-bit-address/ta-p/3116953">EUI-64</a>来自动配置的，我需要一个固定的IPv6地址，这样我就可以给这个地址设置域名，然后从其他地方随时访问这个地址。</p><p>另外，我手动关闭了GRETAP的interface的offload，我也不知道这是不是个内核Bug，但是如果不关的话，会出现校验和没人算的尴尬场面，进而导致所有的TCP包都出错。</p><h1 id="在Vultr上的尝试"><a href="#在Vultr上的尝试" class="headerlink" title="在Vultr上的尝试"></a>在Vultr上的尝试</h1><p>劝我写本文的这位朋友，也在自己的Vultr主机上尝试实现了我的这种网络，来给他的移动设备提供IPv6地址。大的方法基本上跟这里无差，只不过不一样的是，Linode给你<code>/64</code>网段的方法，是在他们的路由表里面，把所有到这个网段的包全都路由到你的主机上去。而Vultr的IPv6，上来就给你的是一个<code>/64</code>的网段，你在Vultr的主机本身也只是监听Router Advertisement来自动配置IPv6地址而已。Vultr那边，不会帮你把到那个地址的所有包全都自动路由到你的主机，而是你得自己去响应Vultr的路由器的IPv6 Neighbor Discovery这种东西，让Vultr知道你的存在，他的路由器才会理你。这种设计，其实更简单了：我们不再需要自己的radvd了，只需要把你的interface跟GRE的那一堆interface桥接到一起就好，Vultr的网络设施，就会自动给你的网络发送Router Advertisement，而你也是有事直接找Vultr,你自己的主机需要做的事情很少。这实际上，相当于Vultr帮你做了一部分工作。具体的配制方法，也很简单，在配置核心节点的那一步，略去radvd的配置，然后设置bridge的时候，把你主机的出口interface也一并加到bridge里面来即可。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;讲一下我自己给自己搭建的网络环境吧，好友很久之前就劝我写了，但那时候工作生活乐趣无穷，没心思写博客，反倒最近烦心事多了，想找点东西换换脑子转移注意力，就跑来写博客了。其实我最早开始玩网络，是因为被学校无端指责我用P2P软件，我去跟他们理论无果，他们拒绝向我提供任何的报告，而我也拒绝向他们认错，于是他们把我家里网“封锁”了，而我在寻求一种穿透他们的方法。经过不断的尝试与探索，我自己的网络结构也演化了好几代，反倒变得比被学校断网之前方便了好多，也引入了IPv6的支持，这样我就可以随时用手机访问自己家里任何设备的任何端口了。&lt;/p&gt;
&lt;p&gt;我之所以搭建自己的网络环境，主要是为了提供如下的功能：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;把我在世界各地的局域网连接到一起去，让他们互相之间能够访问到，并且为这些网络提供可路由的公网IPv6地址。&lt;/li&gt;
&lt;li&gt;突破一些封锁，比如学校的DHNet给我的断网，以及天朝的GFW。&lt;/li&gt;
&lt;li&gt;在外面的便携设备，可以随时连接进来，获得可路由的公网IPv6地址。&lt;/li&gt;
&lt;/ul&gt;</summary>
    
    
    
    <category term="网络" scheme="https://zasdfgbnm.github.io/categories/%E7%BD%91%E7%BB%9C/"/>
    
    
    <category term="GRE" scheme="https://zasdfgbnm.github.io/tags/GRE/"/>
    
    <category term="GRETAP" scheme="https://zasdfgbnm.github.io/tags/GRETAP/"/>
    
    <category term="Wireguard" scheme="https://zasdfgbnm.github.io/tags/Wireguard/"/>
    
    <category term="GUE" scheme="https://zasdfgbnm.github.io/tags/GUE/"/>
    
    <category term="UDP" scheme="https://zasdfgbnm.github.io/tags/UDP/"/>
    
    <category term="iptables" scheme="https://zasdfgbnm.github.io/tags/iptables/"/>
    
    <category term="IPv6" scheme="https://zasdfgbnm.github.io/tags/IPv6/"/>
    
    <category term="Router Advertisement" scheme="https://zasdfgbnm.github.io/tags/Router-Advertisement/"/>
    
    <category term="网桥" scheme="https://zasdfgbnm.github.io/tags/%E7%BD%91%E6%A1%A5/"/>
    
  </entry>
  
  <entry>
    <title>PyTorch JIT Source Code Read Note</title>
    <link href="https://zasdfgbnm.github.io/2018/09/20/PyTorch-JIT-Source-Code-Read-Note/"/>
    <id>https://zasdfgbnm.github.io/2018/09/20/PyTorch-JIT-Source-Code-Read-Note/</id>
    <published>2018-09-21T00:12:21.000Z</published>
    <updated>2021-04-04T05:17:59.765Z</updated>
    
    <content type="html"><![CDATA[<p>This is my note for reading PyTorch’s JIT source. We begin by looking at <code>torch.jit.script</code> and <code>torch.jit.script_method</code> to find the frontend that compiles the Python code into PyTorch’s tree views, and the backend that compiles tree views to graph. We also read the structure of the internal representation of PyTorch’s graph. Finally we go to graph executor to look at how the computation graph is further compiled into instructions and how the action of these instructions are defined and executed.</p><span id="more"></span><p>PyTorch is under very active development. So the PyTorch’s source code at the time the reader reading this article won’t be the same as when I wrote this article. To get the same source code as in this article, the readers could run the following command:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout 76ab26cc3eff1d7ba822d8db93723f5c9598eead</span><br></pre></td></tr></table></figure><h1 id="Starting-point-script-and-script-method"><a href="#Starting-point-script-and-script-method" class="headerlink" title="Starting point: script and script_method"></a>Starting point: script and script_method</h1><p>In PyTorch, a Python function can be just-in-time compiled by doing something like:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@torch.jit.script</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">x</span>):</span></span><br><span class="line">    <span class="keyword">return</span> x + x</span><br></pre></td></tr></table></figure><p>the <code>torch.jit.script</code> is a decorator of your function <code>f</code>. If you are unfamiliar with Python’s decorator, please refer to <a href="https://realpython.com/primer-on-python-decorators/">this article</a>.</p><p>It is also possible to create a module with its method JIT compiled by doing something like:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModule</span>(<span class="params">torch.jit.ScriptModule</span>):</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @torch.jit.script_method</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">self.x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> x * x</span><br><span class="line"></span><br><span class="line"><span class="meta">    @torch.jit.script_method</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> x + self.f(x)</span><br></pre></td></tr></table></figure><h2 id="Scripting-a-function"><a href="#Scripting-a-function" class="headerlink" title="Scripting a function"></a>Scripting a function</h2><p>We will start by looking at <code>torch.jit.script</code>. To read <code>torch.jit.script</code>, we begin by looking at <code>torch/jit/__init__.py</code>. To quickly locate <code>script</code>, search <code>def script</code> in your editor, and you will immediately find it:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">script</span>(<span class="params">fn, optimize=<span class="literal">True</span>, _frames_up=<span class="number">0</span></span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> _enabled:</span><br><span class="line">        <span class="keyword">return</span> fn</span><br><span class="line">    rcb = createResolutionCallback(_frames_up + <span class="number">1</span>)</span><br><span class="line">    ast = get_jit_ast(fn, is_method=<span class="literal">False</span>)</span><br><span class="line">    graph = _jit_script_compile(ast, rcb)</span><br><span class="line">    mod = ScriptModule()</span><br><span class="line">    mod._create_method_from_graph(<span class="string">&#x27;forward&#x27;</span>, graph)</span><br><span class="line">    <span class="comment"># <span class="doctag">TODO:</span> refactor everything so we&#x27;re not 1) creating a ScriptModule</span></span><br><span class="line">    <span class="comment"># 2) Throwing everything away except for the graph 3) Creating a new</span></span><br><span class="line">    <span class="comment"># ScriptModule and dumping that graph in 4) Re-populating the schema</span></span><br><span class="line">    <span class="comment"># because it was lost doing the previous</span></span><br><span class="line">    mod.__getattr__(<span class="string">&#x27;forward&#x27;</span>).forward_schema(ast, <span class="literal">False</span>)</span><br><span class="line">    <span class="comment"># Forward docstrings</span></span><br><span class="line">    mod.__doc__ = fn.__doc__</span><br><span class="line">    <span class="keyword">return</span> mod</span><br></pre></td></tr></table></figure><p>In the beginning, <code>createResolutionCallback</code> is called. This function is defined in the same file. The source code tells us that it just returns a function that maps names to its values in the scope of the caller of <code>script</code>, this would be used later in C++ to read values from Python.</p><p>The <code>get_jit_ast</code> in next line is imported from <code>torch.jit.frontend</code>. From the name of this function and its owning module, we can tell that this is the frontend of PyTorch’s JIT compiler that compiles the source code of the scripted function into abstract syntax tree(AST).</p><p>The next line uses <code>_jit_script_compile</code> to compiles the AST obtained in the previous step into computation graph. By searching <code>_jit_script_compile</code>, we find something that reads: <code>torch._C._jit_script_compile</code>, which tells us that <code>_jit_script_compile</code> is implemented in C++.</p><p>The next couple lines basically create a <code>ScriptModule</code> whose <code>forward</code> method is the compiled graph.</p><h2 id="Scripting-a-module"><a href="#Scripting-a-module" class="headerlink" title="Scripting a module"></a>Scripting a module</h2><p>We start by looking at <code>torch.jit.script_method</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">ScriptMethodStub = namedtuple(<span class="string">&#x27;ScriptMethodStub&#x27;</span>, (<span class="string">&#x27;resolution_callback&#x27;</span>, <span class="string">&#x27;def_&#x27;</span>, <span class="string">&#x27;original_method&#x27;</span>))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">script_method</span>(<span class="params">fn</span>):</span></span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> _enabled:</span><br><span class="line">        <span class="keyword">return</span> fn</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line">    rcb = createResolutionCallback(frames_up=<span class="number">2</span>)</span><br><span class="line">    ast = get_jit_ast(fn, is_method=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> ScriptMethodStub(rcb, ast, fn)</span><br></pre></td></tr></table></figure><p>This is similar to <code>script</code>, but instead of creating and returning a module and put the compiled function into its <code>forward</code> method, it simply use a named tuple to store the resolution callback, AST and the original function.</p><p>This can not be the end of the story because a named tuple can never be called to do the computation. So there must be some magic somewhere that replace the named tuples with something that actually do the job. For readers familiar with Python’s class meta-programming, it’s not hard to imagine how the magic happens. For those not familiar with class meta-programming, I would refer to the book <a href="http://shop.oreilly.com/product/0636920032519.do">Fluent Python</a>. I will explain a bit of detail on that:</p><p>In Python, everything is an object, and a class itself is not an exception. Classes in Python are objects of a special type of classes called meta-class. During import time, when Python see the following code:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModule</span>(<span class="params">torch.jit.ScriptModule</span>):</span></span><br><span class="line"></span><br><span class="line"><span class="meta">    @torch.jit.script_method</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f</span>(<span class="params">self.x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> x * x</span><br><span class="line"></span><br><span class="line"><span class="meta">    @torch.jit.script_method</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span>(<span class="params">self, x</span>):</span></span><br><span class="line">        <span class="keyword">return</span> x + self.f(x)</span><br></pre></td></tr></table></figure><p>It will execute the body of the class definition, that is: compile the <code>return x * x</code>, create an function object with that compiled code, pass this function object to <code>torch.jit.script_method</code>, and set the returned named tuple as <code>f</code>. Then do the same thing for <code>forward</code>. After that, Python will have a map of attribute names and values of the class to be constructed. This map will then be passed to the meta-class of <code>MyModule</code> to actually construct <code>MyModule</code> as an instance of that meta-class.</p><p>To know in detail how this is achieved in PyTorch, we should take a look at <code>ScriptMeta</code> and <code>ScriptModule</code>. These two classes are lengthy, so I will not copy their full code here, but to use pseudocode to show what is done:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ScriptMeta</span>(<span class="params"><span class="built_in">type</span>(<span class="params">torch._C.ScriptModule</span>)</span>):</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span>(<span class="params">cls, name, bases, attrs</span>):</span></span><br><span class="line">        <span class="comment"># delete all ScriptMethodStub</span></span><br><span class="line"></span><br><span class="line"><span class="meta">        @functools.wraps(<span class="params">original_init</span>)</span></span><br><span class="line">        <span class="function"><span class="keyword">def</span> <span class="title">init_then_register</span>(<span class="params">self, *args, **kwargs</span>):</span></span><br><span class="line">            <span class="comment"># invoke the original __init__</span></span><br><span class="line">            self._create_methods(defs, rcbs)</span><br><span class="line"></span><br><span class="line">        cls.__init__ = init_then_register</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">super</span>(ScriptMeta, cls).__init__(name, bases, attrs)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ScriptModule</span>(<span class="params">with_metaclass(<span class="params">ScriptMeta, torch._C.ScriptModule, Module</span>)</span>):</span></span><br><span class="line">    <span class="comment"># ......</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getattr__</span>(<span class="params">self, attr</span>):</span></span><br><span class="line">        <span class="keyword">if</span> self._has_method(attr):</span><br><span class="line">            <span class="comment"># ......</span></span><br><span class="line">            <span class="keyword">return</span> self._get_method(attr)</span><br><span class="line">        <span class="comment"># .....</span></span><br><span class="line">        <span class="keyword">return</span> Module.__getattr__(self, attr)</span><br></pre></td></tr></table></figure><p>In the above pseudocode, <code>_create_methods</code>, <code>_has_method</code>, and <code>_get_method</code> are inherited from <code>torch._C.ScriptModule</code>. So a natural question to ask is then: what does <code>torch._C.ScriptModule</code> do? Before answering this question, let’s first take a look at the frontend.</p><h1 id="The-frontend"><a href="#The-frontend" class="headerlink" title="The frontend"></a>The frontend</h1><p>A good starting point of the frontend is the <code>get_jit_ast</code> we just saw. This function is defined at <code>torch/jit/frontend.py</code>. The code is:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_jit_ast</span>(<span class="params">fn, is_method</span>):</span></span><br><span class="line">    source = dedent(inspect.getsource(fn))</span><br><span class="line">    py_ast = ast.parse(source)</span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(py_ast.body) != <span class="number">1</span> <span class="keyword">or</span> <span class="keyword">not</span> <span class="built_in">isinstance</span>(py_ast.body[<span class="number">0</span>], ast.FunctionDef):</span><br><span class="line">        <span class="keyword">raise</span> RuntimeError(<span class="string">&quot;expected a single top-level function&quot;</span>)</span><br><span class="line">    type_line = torch.jit.annotations.get_type_line(source)</span><br><span class="line">    ctx = SourceContext(source, _uses_true_division(fn))</span><br><span class="line">    <span class="keyword">return</span> build_def(ctx, py_ast.body[<span class="number">0</span>], type_line, is_method)</span><br></pre></td></tr></table></figure><p>The first 4 lines of function body just use the standard tools provided by Python, <code>dedent</code>, <code>inspect</code>, and <code>ast</code>, to construct the Python AST, and do some check to make sure the thing being compiled is “a single top-level function”.</p><p>The following line <code>type_line = torch.jit.annotations.get_type_line(source)</code> is interesting. After looking at <code>torch/jit/annotations.py</code>, we can see that PyTorch’s JIT allows the user to specify the type of arguments and return value by writing something like <code># type: (Tensor, torch.Tensor) -&gt; Tuple[Tensor, Tensor]</code>.</p><p>In the next line <code>ctx = SourceContext(source, _uses_true_division(fn))</code>, the <code>_uses_true_division</code> is defined in the same file to handle the different behavior of <code>/</code> in Python2 with or without <code>from __future__ import division</code> (see <a href="https://www.python.org/dev/peps/pep-0238/">PEP 238</a> for the difference). The <code>SourceContext</code> is also defined in the same file. It is a subclass of <code>SourceRangeFactory</code> with additional field to store if the division is true division. The <code>SourceRangeFactory</code> is imported by <code>from torch._C._jit_tree_views import *</code>. After reading its definition at <code>torch/csrc/jit/script/python_tree_views.cpp</code>, we can see that this is basically a class designed to store the range of source code, e.g. where in the source code a token is located.</p><p>The core is the <code>build_def</code> in the last line, so we move on:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_def</span>(<span class="params">ctx, py_def, type_line, is_method</span>):</span></span><br><span class="line">    returns = []</span><br><span class="line">    ret_body = []</span><br><span class="line">    body = py_def.body</span><br><span class="line">    r = ctx.make_range(py_def.lineno, py_def.col_offset,</span><br><span class="line">                       py_def.col_offset + <span class="built_in">len</span>(<span class="string">&quot;def&quot;</span>))</span><br><span class="line">    param_list = build_param_list(ctx, py_def.args)</span><br><span class="line">    return_type = <span class="literal">None</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">getattr</span>(py_def, <span class="string">&#x27;returns&#x27;</span>, <span class="literal">None</span>) <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        return_type = build_expr(ctx, py_def.returns)</span><br><span class="line">    decl = Decl(r, param_list, return_type)</span><br><span class="line">    <span class="keyword">if</span> type_line <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">        type_comment_decl = torch._C.parse_type_comment(type_line)</span><br><span class="line">        decl = torch._C.merge_type_from_type_comment(decl, type_comment_decl, is_method)</span><br><span class="line">    <span class="keyword">return</span> Def(Ident(r, py_def.name),</span><br><span class="line">               decl,</span><br><span class="line">               build_stmts(ctx, body))</span><br></pre></td></tr></table></figure><p>Reading through this, we can see that what basically this does is to convert the Python’s AST into the internal representation. Names like <code>Decl</code>, <code>Def</code>, <code>Ident</code> are all imported by <code>from torch._C._jit_tree_views import *</code>. In the last line, we can see that the function body is constructed by <code>build_stmts</code>, so let’s go further to read <code>build_stmts</code>:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_stmts</span>(<span class="params">ctx, stmts</span>):</span></span><br><span class="line">    stmts = [build_stmt(ctx, s) <span class="keyword">for</span> s <span class="keyword">in</span> stmts]</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">list</span>(<span class="built_in">filter</span>(<span class="literal">None</span>, stmts))</span><br></pre></td></tr></table></figure><p>This is a very simple function: call <code>build_stmt</code> for each item and filter out those not needed. But what is <code>build_stmt</code>? It is defined as: <code>build_stmt = StmtBuilder()</code>. The definition of <code>StmtBuilder</code> looks like:</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">StmtBuilder</span>(<span class="params">Builder</span>):</span></span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_Expr</span>(<span class="params">ctx, stmt</span>):</span></span><br><span class="line">        value = stmt.value</span><br><span class="line">        <span class="keyword">if</span> value.__class__.__name__ == <span class="string">&#x27;Str&#x27;</span>:</span><br><span class="line">            <span class="comment"># If a statement is a string literal expression,</span></span><br><span class="line">            <span class="comment"># then it is a docstring. Just ignore it.</span></span><br><span class="line">            <span class="keyword">return</span> <span class="literal">None</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> ExprStmt([build_expr(ctx, value)])</span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_assign_lhs_expr</span>(<span class="params">ctx, expr</span>):</span></span><br><span class="line">        <span class="comment"># ...</span></span><br><span class="line">    <span class="comment"># ...</span></span><br><span class="line"><span class="meta">    @staticmethod</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_Assign</span>(<span class="params">ctx, stmt</span>):</span></span><br><span class="line">        <span class="comment">#...</span></span><br><span class="line">    <span class="comment"># ......</span></span><br></pre></td></tr></table></figure><p>We can see that, this is a class with many static methods that define what to do for different types of Python AST. I will not go deep into how each type is handled. Since at this point, the readers should be able to catch all the details on how each type of nodes in Python AST are dealt with by themselves. So We will stop our frontend reading right here.</p><h1 id="ScriptModule-and-ScriptMethod"><a href="#ScriptModule-and-ScriptMethod" class="headerlink" title="ScriptModule and ScriptMethod"></a>ScriptModule and ScriptMethod</h1><p>To find where <code>ScriptModule</code> in C++ is defined, run <code>grep &#39;ScriptModule&#39; -r torch/csrc/</code> and you will locate it at <code>torch/csrc/jit/script/init.cpp</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// torch.jit.ScriptModule is a subclass of this C++ object.</span></span><br><span class="line"><span class="comment">// Methods here are prefixed with _ since they should not be</span></span><br><span class="line"><span class="comment">// public.</span></span><br><span class="line">py::class_&lt;Module, std::shared_ptr&lt;Module&gt;&gt;(m, <span class="string">&quot;ScriptModule&quot;</span>)</span><br><span class="line">    .<span class="built_in">def</span>(py::init&lt;&gt;())</span><br><span class="line">    .<span class="built_in">def</span>(<span class="string">&quot;save&quot;</span>, &amp;Module::save)</span><br><span class="line">    .<span class="built_in">def</span>(<span class="string">&quot;_set_optimized&quot;</span>, &amp;Module::set_optimized)</span><br><span class="line">    .<span class="built_in">def</span>(</span><br><span class="line">        <span class="string">&quot;_define&quot;</span>,</span><br><span class="line">        [](std::shared_ptr&lt;Module&gt; m,</span><br><span class="line">            <span class="keyword">const</span> std::string&amp; script,</span><br><span class="line">            ResolutionCallback rcb, <span class="keyword">bool</span> has_self) &#123;</span><br><span class="line">          <span class="keyword">auto</span> self = has_self ? std::make_shared&lt;ModuleValue&gt;(m) : <span class="literal">nullptr</span>;</span><br><span class="line">          <span class="keyword">return</span> <span class="built_in">defineMethodsInModule</span>(*m, script, <span class="built_in">pythonResolver</span>(rcb), self);</span><br><span class="line">        &#125;)</span><br><span class="line">    .<span class="built_in">def</span>(<span class="string">&quot;_create_methods&quot;</span>, [](std::shared_ptr&lt;Module&gt; m, <span class="keyword">const</span> std::vector&lt;Def&gt;&amp; defs, <span class="keyword">const</span> std::vector&lt;ResolutionCallback&gt;&amp; rcbs) &#123;</span><br><span class="line">      std::vector&lt;Resolver&gt; resolvers;</span><br><span class="line">      <span class="keyword">for</span>(<span class="keyword">auto</span> &amp; callback : rcbs) &#123;</span><br><span class="line">        resolvers.<span class="built_in">push_back</span>(<span class="built_in">pythonResolver</span>(callback));</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="built_in">defineMethodsInModule</span>(</span><br><span class="line">        *m,</span><br><span class="line">        defs,</span><br><span class="line">        resolvers,</span><br><span class="line">        std::make_shared&lt;ModuleValue&gt;(m));</span><br><span class="line">    &#125;)</span><br><span class="line">    .<span class="built_in">def</span>(<span class="string">&quot;_get_method&quot;</span>,</span><br><span class="line">    [](Module&amp; self, <span class="keyword">const</span> std::string&amp; name) -&gt; <span class="keyword">const</span> Method&amp; &#123;</span><br><span class="line">      <span class="keyword">return</span> self.<span class="built_in">get_method</span>(name);</span><br><span class="line">    &#125;, py::return_value_policy::reference_internal)</span><br><span class="line">    <span class="comment">//.def more ...</span></span><br><span class="line"></span><br><span class="line">py::class_&lt;Method&gt;(m, <span class="string">&quot;ScriptMethod&quot;</span>, py::<span class="built_in">dynamic_attr</span>())</span><br><span class="line">    .<span class="built_in">def</span>(<span class="string">&quot;graph&quot;</span>, [&amp;](Method&amp; self) &#123;</span><br><span class="line">      <span class="keyword">return</span> self.<span class="built_in">graph</span>();</span><br><span class="line">    &#125;)</span><br><span class="line">    .<span class="built_in">def</span>(<span class="string">&quot;__call__&quot;</span>, invokeScriptMethodFromPython)</span><br><span class="line">    <span class="comment">//.def more ...</span></span><br></pre></td></tr></table></figure><p>We can see that <code>ScriptModule</code> is basically a binding for the C++ class <code>Module</code>. By skim through the list of methods defined here, we can see that it has methods for adding, getting, and checking existence of methods, parameters, submodules, buffers, etc. The class for methods is <code>Method</code>, which binds to Python as <code>ScriptMethod</code>. Methods in modules are created by <code>defineMethodsInModule</code> and invoked by <code>invokeScriptMethodFromPython</code>. <code>defineMethodsInModule</code> is a bit complicated, and we will postpone its reading to the backend compiler part of this article. But <code>invokeScriptMethodFromPython</code> is very simple. Searching with <code>grep</code>, we can easily find its definition in <code>torch/csrc/jit/pybind_utils.h</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span> py::object <span class="title">invokeScriptMethodFromPython</span><span class="params">(</span></span></span><br><span class="line"><span class="function"><span class="params">    script::Method&amp; method,</span></span></span><br><span class="line"><span class="function"><span class="params">    py::args args, py::kwargs kwargs)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> stack = <span class="built_in">createStackForSchema</span>(method.<span class="built_in">getSchema</span>(), std::<span class="built_in">move</span>(args), std::<span class="built_in">move</span>(kwargs));</span><br><span class="line">  &#123;</span><br><span class="line">    AutoNoGIL no_gil_guard;</span><br><span class="line">    method.<span class="built_in">run</span>(stack);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">createPyObjectForStack</span>(std::<span class="built_in">move</span>(stack));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>We can easily tell that it just create a stack from the input parameters, invoke <code>Method::run</code> to consume elements on the stack as input and leave the output of graph on the stack, and finally convert elements on the stack into Python objects.</p><p>Now let’s move on to <code>Module</code> and <code>Method</code>. It’s easy to guess from the name that these classes are defined at <code>torch/csrc/jit/script/module.&#123;h,cpp&#125;</code>. Read through these two files, we would see that <code>Module</code> is just a container of things: it just uses ordered dictionary to store methods, parameters and submodules, and provide methods to access or run them.</p><p>What <code>Method</code> does is more interesting. One important thing that the designer of <code>Method</code> must worry about is, since methods have access to not only its arguments, but also other class members of the same object, there must be a mechanism for such kind of access. We will see how this is handled very soon. From its constructor, we can see that a method can be created either from the graph and initial class members directly, or from a method creator. The method creator is invoked lazily, i.e. it is not invoked inside the constructor, but wait until someone call <code>ensure_defined</code>. The following member functions of <code>Method</code> defines how an object of <code>Method</code> is run:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">(Stack &amp; stack)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span>(at::Tensor* tp : member_inputs) &#123;</span><br><span class="line">    stack.<span class="built_in">push_back</span>(*tp);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="built_in">get_executor</span>().<span class="built_in">run</span>(stack);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function">IValue <span class="title">operator</span><span class="params">()</span><span class="params">(std::vector&lt;IValue&gt; stack)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">checkInputsAgainstSchema</span>(stack);</span><br><span class="line">  <span class="built_in">run</span>(stack);</span><br><span class="line">  <span class="keyword">if</span> (stack.<span class="built_in">size</span>() != <span class="number">1</span>) &#123;</span><br><span class="line">    <span class="keyword">return</span> Tuple::<span class="built_in">create</span>(std::<span class="built_in">move</span>(stack));</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> stack.<span class="built_in">front</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>By looking at the types of names appearing in the above code, we can see that: graph is an object of <code>Graph</code>, and the virtual machine that execute the graph is an object of <code>GraphExecutor</code>. <code>GraphExecutor</code> operate on data type <code>IValue</code>, and its stack is a <code>vector</code> of that data type. To run a method, one need to first push the arguments onto the stack, and invoke <code>Method::run</code>, which will further push other member inputs onto the stack, and invoke <code>GraphExecutor::run</code> to run the graph. The graph executor will leave its output on the stack.</p><p>At this point, we still don’t know how things like <code>Graph</code> and <code>GraphExecutor</code> works, but before looking deep into that, let’s pause a little bit to take a look at the backend compiler.</p><h1 id="From-Python-AST-to-PyTorch-IR-part-1"><a href="#From-Python-AST-to-PyTorch-IR-part-1" class="headerlink" title="From Python AST to PyTorch IR: part 1"></a>From Python AST to PyTorch IR: part 1</h1><p>Now let’s move on to read <code>_jit_script_compile</code>. To find where it is located, simply run the command <code>grep _jit_script_compile -r .</code>. We will find something like:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">./torch/csrc/jit/script/init.cpp:  m.<span class="built_in">def</span>(<span class="string">&quot;_jit_script_compile&quot;</span>, [](<span class="keyword">const</span> Def &amp;def, ResolutionCallback rcb) &#123;</span><br></pre></td></tr></table></figure><p>So, <code>torch/csrc/jit/script/init.cpp</code> would be a good start point. The complete definition of <code>_jit_script_compile</code> is:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">m.<span class="built_in">def</span>(<span class="string">&quot;_jit_script_compile&quot;</span>, [](<span class="keyword">const</span> Def &amp;def, ResolutionCallback rcb) &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">compileFunction</span>(def, <span class="built_in">PythonResolver</span>(rcb));</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><p>So, let’s move on to <code>compileFunction</code>. Using grep to search, we would find its definition in <code>torch/csrc/jit/script/compiler.cpp</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">std::shared_ptr&lt;Graph&gt; <span class="title">compileFunction</span><span class="params">(Def def, <span class="keyword">const</span> Resolver&amp; resolver)</span> </span>&#123;</span><br><span class="line">  Module m;</span><br><span class="line">  <span class="built_in">defineMethodsInModule</span>(m, &#123;def&#125;, &#123;resolver&#125;, <span class="literal">nullptr</span>);</span><br><span class="line">  <span class="keyword">return</span> m.<span class="built_in">get_method</span>(def.<span class="built_in">name</span>().<span class="built_in">name</span>()).<span class="built_in">graph</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>We see the <code>defineMethodsInModule</code> that we saw before on the definition of Python bindings for <code>Module</code>. Move on to <code>defineMethodsInModule</code>, on the same file:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">defineMethodsInModule</span><span class="params">(Module &amp; m, <span class="keyword">const</span> std::vector&lt;Def&gt;&amp; definitions, <span class="keyword">const</span> std::vector&lt;Resolver&gt;&amp; resolvers, SugaredValuePtr self)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// ......</span></span><br><span class="line">  <span class="keyword">for</span>(Def def : definitions) &#123;</span><br><span class="line">    <span class="comment">// ......</span></span><br><span class="line">    <span class="keyword">auto</span> creator = [def, &amp;table, resolver, self](Method&amp; method) &#123;</span><br><span class="line">      <span class="built_in">to_ir</span>(def, table, resolver, self,  method);</span><br><span class="line">    &#125;;</span><br><span class="line">    Method&amp; method = m.<span class="built_in">create_method</span>(name, creator);</span><br><span class="line">    <span class="comment">// ......</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// ......</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Less important parts of the code is omitted. From above, we can find that the core of compiling an AST into a compute graph is done at <code>to_ir</code>. Skimming through <code>to_ir</code> we find that it is a struct of ~1000 lines of code, with member functions that handles different cases of Python AST. Without knowing PyTorch’s IR, it’s not easy to understand what <code>to_ir</code> does. So let’s pause a little bit to take a look at PyTorch IR and come back later.</p><h1 id="The-PyTorch-IR"><a href="#The-PyTorch-IR" class="headerlink" title="The PyTorch IR"></a>The PyTorch IR</h1><p>A good starting point is the class <code>Graph</code>, located at <code>torch/csrc/jit/ir.h</code>. Skimming through this file, as well as <code>to_ir</code>, we keep seeing things like <code>aten::mul</code>, <code>prim::Constant</code>. What are they? They seems to be very relevant, actually they seems to be <strong>the node</strong> in the graph. By doing some <code>grep</code> search, we find a good document of them at <code>torch/csrc/jit/interned_strings.h</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// &#x27;prim&#x27; symbols are synthetic operators that occur only in the IR</span></span><br><span class="line"><span class="comment">// and don&#x27;t have corresponding implementations in ATen.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// &#x27;onnx&#x27; symbols correspond to ONNX operators.  Their semantics</span></span><br><span class="line"><span class="comment">// are defined in https://github.com/onnx/onnx/blob/master/docs/Operators.md</span></span><br><span class="line"><span class="comment">// The particular version we are targeting is specified by &#x27;_onnx_opset_version&#x27;</span></span><br><span class="line"><span class="comment">// in torch.onnx.symbolic</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">// In general, most ONNX operators won&#x27;t get an entry here, because they</span></span><br><span class="line"><span class="comment">// are handled from the Python end.  However, you may occasionally need</span></span><br><span class="line"><span class="comment">// to intern an ONNX symbol here so that you can conveniently write an</span></span><br><span class="line"><span class="comment">// optimization on ONNX operations.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// &#x27;attr&#x27; symbols are attribute keys.  They are shared between both ONNX and ATen</span></span><br><span class="line"><span class="comment">// operators (you disambiguate their meaning by looking at the operator itself).</span></span><br><span class="line"><span class="comment">// In general, you only need to define attribute keys that are used by</span></span><br><span class="line"><span class="comment">// onnx or prim; ATen attributes are automatically generated in FORALL_ATTR_BASE_SYMBOLS.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Note [Symbol allocation]</span></span><br><span class="line"><span class="comment">// ~~~~~~~~~~~~~~~~~~~~~~~~</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//  1. Symbol namespace is split up into namespaces.</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"><span class="comment">//  2. The intended access pattern for built-in symbols is onnx::MatMul</span></span><br><span class="line"><span class="comment">//  in the torch::jit namespace (this is a Symbol).</span></span><br><span class="line"><span class="comment">//</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment">// Built-in constant definition strategy:</span></span><br><span class="line"><span class="comment">// - Enum is the most convenient way to generate a contiguous sequence</span></span><br><span class="line"><span class="comment">//   of numbers for an identifier.</span></span><br><span class="line"><span class="comment">// - However, an enum gives you a fresh type.  We want onnx::MatMul to</span></span><br><span class="line"><span class="comment">//   be type Symbol, not some random enum type!</span></span><br><span class="line"><span class="comment">// - Therefore, after using enums to generate the sequence of integers,</span></span><br><span class="line"><span class="comment">//   we then declare constexpr Symbols to get everything the actual Symbol</span></span><br><span class="line"><span class="comment">//   type we want.  Symbols must be constexpr to be valid to be &quot;case&quot;ed on.</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">unique_t</span> = <span class="keyword">uint32_t</span>;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">const</span> std::string domain_prefix = <span class="string">&quot;org.PyTorch.&quot;</span>;</span><br><span class="line"></span><br><span class="line"><span class="comment">// A Symbol is like an interned string, but with a little extra</span></span><br><span class="line"><span class="comment">// structure; it is namespaced via SymbolNamespace and the resulting</span></span><br><span class="line"><span class="comment">// intern pointers support efficient namespace testing.</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">TORCH_API</span> <span class="title">Symbol</span> &#123;</span></span><br><span class="line"><span class="comment">// more code omitted ......</span></span><br></pre></td></tr></table></figure><p>This very well explains what those things are: they are instances of <code>Symbol</code> to represent operators. Knowing this level of detail about these things is enough for us, so let’s go back to IR.</p><p>The beginning of file <code>torch/csrc/jit/ir.h</code> very well explains what things are:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Graph represents one &quot;function&quot; of computation.</span></span><br><span class="line"><span class="comment">// It uses a simple ownership model where the graph owns all the nodes inside it.</span></span><br><span class="line"><span class="comment">// All references inside the graph are raw pointers.</span></span><br><span class="line"><span class="comment">// Destroying the Graph will invalidate any pointers to nodes in the graph.</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Graph</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Node is the base class of the IR graph. It represents one computation</span></span><br><span class="line"><span class="comment">// and dependencies on a list of Values. The &quot;prim-ops&quot;, so to speak.</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Node</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// A Value represents an input or output to node that is either a</span></span><br><span class="line"><span class="comment">// Tensor or an opaque Handle object, as determined by type().</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Value</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// ......</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// A list of nodes, with inputs and outputs</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Block</span>;</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Each use is represented by this type, see Node::uses()</span></span><br><span class="line"><span class="comment">// &#x27;user&#x27; is the consumer of the value, offset is the index into</span></span><br><span class="line"><span class="comment">// &#x27;user&#x27;s input this where the produces will be found.</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Use</span> &#123;</span></span><br><span class="line">  <span class="built_in">Use</span>(Node * user, <span class="keyword">size_t</span> offset)</span><br><span class="line">  : <span class="built_in">user</span>(user), <span class="built_in">offset</span>(offset) &#123;&#125;</span><br><span class="line">  Node * user;</span><br><span class="line">  <span class="keyword">size_t</span> offset;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ......</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// Scope is a node of a trie that represents the tree of nested scopes.</span></span><br><span class="line"><span class="comment">// Individual scopes are pushed and popped from Graph, which holds a</span></span><br><span class="line"><span class="comment">// pointer to the current scope. Each Node in Graph holds a pointer</span></span><br><span class="line"><span class="comment">// to the scope that was current when the node was created.</span></span><br><span class="line"><span class="comment">// The trie never needs to shrink, it only grows until it is disposed</span></span><br><span class="line"><span class="comment">// of when Graph is deallocated. Hence, pointers to scopes held by nodes</span></span><br><span class="line"><span class="comment">// will always be valid as long as Graph is alive.</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Scope</span> &#123;</span></span><br></pre></td></tr></table></figure><p>Reading through the whole file, we can summarize how it works:</p><p>A <code>Graph</code> object owns all <code>Node</code>s, <code>Value</code>s, and <code>Block</code>s. The internal structure is not maintained by the <code>Graph</code> object, but inside <code>Node</code>s, <code>Value</code>s, and <code>Block</code>s.</p><p>Each <code>Node</code> keeps pointers to its input, and output <code>Value</code>s. It also maintains pointers to siblings in a doubly-linked list of <code>Node</code>s. This doubly-linked list is a topological sort of the <code>Node</code>s in the <code>Graph</code>. Each <code>Node</code> has a <code>NodeKind</code> as an object of <code>Symbol</code>. <code>Node</code>s also maintains a pointer to the <code>Block</code> owning this <code>Node</code>, as well as pointers to subblocks.</p><p>Each <code>Value</code> must be an output of some <code>Node</code>, and it has a <code>Node</code> pointer pointing to the <code>Node</code> that outputs this <code>Value</code>. It also has a <code>Use</code> list storing where this <code>Value</code> is used as input.</p><p>Each <code>Block</code> maintains pointers to its input and output <code>Node</code>s, as well as the <code>Node</code> owning this <code>Block</code>.</p><h1 id="From-Python-AST-to-PyTorch-IR-part-2"><a href="#From-Python-AST-to-PyTorch-IR-part-2" class="headerlink" title="From Python AST to PyTorch IR: part 2"></a>From Python AST to PyTorch IR: part 2</h1><p>With the knowledge of IR, let’s go back to read the backend compiler.</p><p>In the code in <code>torch/csrc/jit/script/compiler.cpp</code>, we have been seeing <code>SugaredValue</code> many times. What <code>SugaredValue</code> does is explained in <code>torch/csrc/jit/script/compiler.h</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// The AST can contain nodes like `self`, `self.b` or `Python_fn` that</span></span><br><span class="line"><span class="comment">// are not first-class values in the graph representation, but instead</span></span><br><span class="line"><span class="comment">// will be desugared based on how they are used in the AST.</span></span><br><span class="line"></span><br><span class="line"><span class="comment">// SugaredValue is used to temporarily represent these values in a way</span></span><br><span class="line"><span class="comment">// that separates their behavior from the AST -&gt; IR converter itself.</span></span><br><span class="line"><span class="comment">// This allows us to keep dependencies on Python minimal.</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">SugaredValue</span> :</span> <span class="keyword">public</span> std::enable_shared_from_this&lt;SugaredValue&gt; &#123;</span><br></pre></td></tr></table></figure><p>From the comments above, together with what we see when skimming through the code, we can see that, <code>SugaredValue</code> is a super class of different types of values. These values might be first-class values like tensors or integers, or <code>ScriptModule</code> such as <code>self</code>, or Python modules like <code>torch</code>, or some builtin functions like <code>print</code>. Different types of values are handled by different subclasses: <code>SimpleValue</code> for first class values, <code>BuiltinFunction</code> for operators like <code>aten::relu</code>, <code>BuiltinModule</code> for something like <code>torch</code>, <code>NoneValue</code> for <code>None</code>, <code>PrintValue</code> for <code>print</code>, <code>CastValue</code> for types like <code>int</code>, <code>float</code>, etc. These subclasses listed above are all defined in <code>torch/csrc/jit/script/compiler.&#123;cpp, h&#125;</code>.</p><p>Now let’s move on to read the constructor of the struct <code>to_ir</code>. It basically:</p><ol><li>Read the information of parameters from the Python AST, and set them up in graph.</li><li>Call <code>emitStatements</code> to emit IR for function body.</li><li>Set up output values for the graph based on the return statement in the end of function body (compiling functions that has a return statement on somewhere other than the end is not supported).</li></ol><p>In step 1, there is a little bit of trouble that for functions that is a method of some module, the first parameter is always the reference to the object owing this method (aka. the so called “self”). So it requires a little bit of special case when checking against schema. Also, we need to add the identifier for the first parameter to the symbol table (here the symbol table is <code>Environment::value_table</code>, an object of <code>ValueTable</code>). The input to the graph is not only those appears explicitly in the argument list, but also those members access inside the function body. Recall that when we read the code of <code>Method::run</code>, there is a step that push members onto the stack. This issue is not handled here, and we will see how it is handled later.</p><p>In step 2, things started to get complicated. In <code>emitStatements</code>, code emitting are dispatched to different specialized private methods of the struct by its type:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">emitStatements</span><span class="params">(List&lt;Stmt&gt;::const_iterator begin, List&lt;Stmt&gt;::const_iterator end)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span> (; begin != end; ++begin) &#123;</span><br><span class="line">    <span class="keyword">auto</span> stmt = *begin;</span><br><span class="line">    <span class="built_in"><span class="keyword">switch</span></span> (stmt.<span class="built_in">kind</span>()) &#123;</span><br><span class="line">      <span class="keyword">case</span> TK_IF:</span><br><span class="line">        <span class="built_in">emitIf</span>(<span class="built_in">If</span>(stmt));</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> TK_WHILE:</span><br><span class="line">        <span class="built_in">emitWhile</span>(<span class="built_in">While</span>(stmt));</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> TK_FOR:</span><br><span class="line">        <span class="built_in">emitFor</span>(<span class="built_in">For</span>(stmt));</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> TK_ASSIGN:</span><br><span class="line">        <span class="built_in">emitAssignment</span>(<span class="built_in">Assign</span>(stmt));</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> TK_GLOBAL:</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> ident : <span class="built_in">Global</span>(stmt).<span class="built_in">names</span>()) &#123;</span><br><span class="line">          <span class="keyword">const</span> <span class="keyword">auto</span>&amp; name = <span class="built_in">Ident</span>(ident).<span class="built_in">name</span>();</span><br><span class="line">          environment_stack-&gt;<span class="built_in">setVar</span>(ident.<span class="built_in">range</span>(), name, graph-&gt;<span class="built_in">addInput</span>(name));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> TK_EXPR_STMT: &#123;</span><br><span class="line">        <span class="keyword">auto</span> exprs = <span class="built_in">ExprStmt</span>(stmt).<span class="built_in">exprs</span>();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>&amp; expr : exprs) &#123;</span><br><span class="line">          <span class="built_in">emitSugaredExpr</span>(expr, <span class="number">0</span>);</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> TK_RETURN:</span><br><span class="line">        <span class="keyword">throw</span> <span class="built_in">ErrorReport</span>(stmt) &lt;&lt; <span class="string">&quot;return statements can appear only at the end &quot;</span></span><br><span class="line">                                &lt;&lt; <span class="string">&quot;of the function body&quot;</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>There are so many specialized emits, I will not go over these in detail one by one. I will only go deep into <code>emitSugaredExpr</code> as an example here. <code>emitSugaredExpr</code> is defined as follows:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// any expression that can produce a SugaredValue is handled here</span></span><br><span class="line"><span class="comment">// expressions that only return a single Value* are handled in emitSimpleExpr</span></span><br><span class="line"><span class="function">std::shared_ptr&lt;SugaredValue&gt; <span class="title">emitSugaredExpr</span><span class="params">(Expr tree, <span class="keyword">size_t</span> n_binders)</span> </span>&#123;</span><br><span class="line">  <span class="built_in"><span class="keyword">switch</span></span>(tree.<span class="built_in">kind</span>()) &#123;</span><br><span class="line">    <span class="keyword">case</span> TK_VAR:</span><br><span class="line">      <span class="keyword">return</span> environment_stack-&gt;<span class="built_in">getSugaredVar</span>(<span class="built_in">Var</span>(tree).<span class="built_in">name</span>());</span><br><span class="line">    <span class="keyword">case</span> <span class="string">&#x27;.&#x27;</span>: &#123;</span><br><span class="line">      <span class="keyword">auto</span> select = <span class="built_in">Select</span>(tree);</span><br><span class="line">      <span class="keyword">auto</span> sv = <span class="built_in">emitSugaredExpr</span>(select.<span class="built_in">value</span>(), <span class="number">1</span>);</span><br><span class="line">      <span class="keyword">return</span> sv-&gt;<span class="built_in">attr</span>(select.<span class="built_in">range</span>(), method, select.<span class="built_in">selector</span>().<span class="built_in">name</span>());</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">case</span> TK_APPLY: &#123;</span><br><span class="line">      <span class="keyword">auto</span> apply = <span class="built_in">Apply</span>(tree);</span><br><span class="line">      <span class="keyword">auto</span> inputs = <span class="built_in">getNamedValues</span>(apply.<span class="built_in">inputs</span>(), <span class="literal">true</span>);</span><br><span class="line">      <span class="keyword">auto</span> attributes = <span class="built_in">fmap</span>(apply.<span class="built_in">attributes</span>(), [&amp;](<span class="keyword">const</span> Attribute&amp; attr) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">NamedValue</span>(attr.<span class="built_in">range</span>(), attr.<span class="built_in">name</span>().<span class="built_in">name</span>(), <span class="built_in">emitExpr</span>(attr.<span class="built_in">value</span>()));</span><br><span class="line">      &#125;);</span><br><span class="line">      <span class="comment">// the apply is directly an identifier &#x27;foo&#x27;</span></span><br><span class="line">      <span class="keyword">if</span>(apply.<span class="built_in">callee</span>().<span class="built_in">kind</span>() == TK_VAR) &#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="built_in">emitApplyIdent</span>(<span class="built_in">Var</span>(apply.<span class="built_in">callee</span>()).<span class="built_in">name</span>(), inputs, attributes, n_binders);</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">emitApplyExpr</span>(apply.<span class="built_in">callee</span>(), inputs, attributes, n_binders);</span><br><span class="line">    &#125; <span class="keyword">break</span>;</span><br><span class="line">    <span class="keyword">default</span>:</span><br><span class="line">      <span class="keyword">return</span> std::make_shared&lt;SimpleValue&gt;(<span class="built_in">emitSimpleExpr</span>(tree));</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>What it does is basically: for cases that guaranteed to produce a <code>SimpleValue</code>, we just call <code>emitSimpleExpr</code> to emit the code, otherwise it must be one of the following three format: <code>foo</code>, <code>foo.bar</code>, <code>foo(bar)</code>. For the <code>foo</code> case, we just lookup <code>foo</code> in the symbol table, for the <code>foo.bar</code> case, we first emit <code>foo</code> and lookup its attribute <code>bar</code>. For the <code>foo(bar)</code> case, depending on whether <code>foo</code> is an identifier or an expression, invoke <code>emitApplyIdent</code> or <code>emitApplyExpr</code> correspondingly to do code emitting.</p><p>The <code>self</code> argument of the method is handled a bit differently: there is a subclass of <code>SugaredValue</code> called <code>ModuleValue</code> defined in <code>torch/csrc/jit/script/init.cpp</code>, in its override method <code>attr</code>, we see:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span>(NamedParameter* v = <span class="keyword">module</span>-&gt;<span class="built_in">find_parameter</span>(field)) &#123;</span><br><span class="line">  <span class="keyword">return</span> std::make_shared&lt;SimpleValue&gt;(m.<span class="built_in">get_or_add_parameter</span>(v-&gt;<span class="built_in">slot</span>()));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Where the <code>get_or_add_parameter</code> defined in <code>torch/csrc/jit/script/module.h</code> reads:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">Value * <span class="title">get_or_add_parameter</span><span class="params">(at::Tensor* slot)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> it = member_input_index.<span class="built_in">find</span>(slot);</span><br><span class="line">  <span class="keyword">if</span>(it != member_input_index.<span class="built_in">end</span>()) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">graph</span>()-&gt;<span class="built_in">inputs</span>().<span class="built_in">at</span>(it-&gt;second);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// add it as a new parameter</span></span><br><span class="line">  member_inputs.<span class="built_in">push_back</span>(slot);</span><br><span class="line">  member_input_index[slot] = <span class="built_in">graph</span>()-&gt;<span class="built_in">inputs</span>().<span class="built_in">size</span>();</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">graph</span>()-&gt;<span class="built_in">addInput</span>();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>That tells us: adding members as parameters of the graph actually happens at code emitting of <code>self.bar</code>, where the <code>attr</code> of <code>ModuleValue</code> called.</p><h1 id="The-Graph-Executor"><a href="#The-Graph-Executor" class="headerlink" title="The Graph Executor"></a>The Graph Executor</h1><p>Now we have seen how the compilation is done and what does PyTorch JIT’s IR looks like, the thing left is how the IR are executed. From above we already know that the executor is obtained by invoking <code>Method::get_executor</code> and run by invoking <code>GraphExecutor::run</code>. Let’s first take a look at <code>Method::get_executor</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">GraphExecutor&amp; <span class="title">get_executor</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  std::<span class="built_in">call_once</span>(executor_init, [&amp;]&#123;</span><br><span class="line">    executor = <span class="built_in">GraphExecutor</span>(<span class="built_in">graph</span>(), optimize);</span><br><span class="line">  &#125;);</span><br><span class="line">  <span class="keyword">return</span> executor;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>We know that a graph executor is created from a graph, and does optimization if asked. It’s not hard to guess from name that <code>GraphExecutor</code> is defined in <code>torch/csrc/jit/graph_executor.&#123;h, cpp&#125;</code>.</p><p>The constructor and <code>run</code> tells us that <code>GraphExecutor</code> is just a wrapper of <code>GraphExecutorImpl</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">GraphExecutor::<span class="built_in">GraphExecutor</span>(std::shared_ptr&lt;Graph&gt; graph, <span class="keyword">bool</span> optimize)</span><br><span class="line">: <span class="built_in">pImpl</span>(<span class="keyword">new</span> <span class="built_in">GraphExecutorImpl</span>(std::<span class="built_in">move</span>(graph), optimize)) &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">GraphExecutor::run</span><span class="params">(Stack &amp; inputs)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> pImpl-&gt;<span class="built_in">run</span>(inputs);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>So let’s move on to <code>GraphExecutorImpl</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">GraphExecutorImpl</span>(std::shared_ptr&lt;Graph&gt; graph, <span class="keyword">bool</span> optimize)</span><br><span class="line">  : <span class="built_in">graph</span>(<span class="built_in">prepareGraph</span>(graph))</span><br><span class="line">  , <span class="built_in">optimize</span>(optimize)</span><br><span class="line">  , <span class="built_in">num_inputs</span>(<span class="keyword">this</span>-&gt;graph-&gt;<span class="built_in">inputs</span>().<span class="built_in">size</span>())</span><br><span class="line">  , <span class="built_in">num_flat_inputs</span>(<span class="built_in">countFlatInputs</span>(graph))</span><br><span class="line">  , <span class="built_in">num_outputs</span>(<span class="keyword">this</span>-&gt;graph-&gt;<span class="built_in">outputs</span>().<span class="built_in">size</span>()) &#123;&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// entry point where execution begins</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">(Stack &amp; stack)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">AT_CHECK</span>(stack.<span class="built_in">size</span>() &gt;= num_inputs, <span class="string">&quot;expected &quot;</span>, num_inputs, <span class="string">&quot; inputs, but got only &quot;</span>, stack.<span class="built_in">size</span>());</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span>(tracer::<span class="built_in">isTracing</span>()) &#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">runTraced</span>(stack);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">auto</span> &amp; execution_plan = optimize ? <span class="built_in">getOrCompile</span>(stack) : <span class="built_in">getOrCompileFallback</span>();</span><br><span class="line">  <span class="keyword">return</span> execution_plan.<span class="built_in">run</span>(stack);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>We see that the graph is compiled at the first time it runs to get an execution plan. The <code>run</code> method of execution plan is called to run the graph. Compilation of graph to execution plan is done by <code>getOrCompile</code> or <code>getOrCompileFallback</code> depending on if optimization is enabled. These two methods are copied below:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">const</span> ExecutionPlan &amp; <span class="title">getOrCompileFallback</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(compile_mutex)</span></span>;</span><br><span class="line">  <span class="keyword">if</span>(!fallback) &#123;</span><br><span class="line">    <span class="keyword">auto</span> graph_ = graph-&gt;<span class="built_in">copy</span>();</span><br><span class="line">    <span class="built_in">runRequiredPasses</span>(graph_);</span><br><span class="line">    fallback = <span class="built_in">ExecutionPlan</span>(graph_);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> fallback;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">const</span> ExecutionPlan &amp; <span class="title">getOrCompile</span><span class="params">(<span class="keyword">const</span> Stack&amp; stack)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// outside lock guard, to minimize the time holding the lock on the fast path</span></span><br><span class="line">  <span class="comment">// ArgumentSpec even computes its hashCode here.</span></span><br><span class="line">  <span class="function">ArgumentSpec <span class="title">spec</span><span class="params">(autograd::GradMode::is_enabled(), last(stack, num_inputs), num_flat_inputs)</span></span>;</span><br><span class="line">  &#123;</span><br><span class="line">    <span class="function">std::lock_guard&lt;std::mutex&gt; <span class="title">lock</span><span class="params">(compile_mutex)</span></span>;</span><br><span class="line">    <span class="keyword">auto</span> it = plan_cache.<span class="built_in">find</span>(spec);</span><br><span class="line">    <span class="keyword">if</span> (it != plan_cache.<span class="built_in">end</span>())</span><br><span class="line">      <span class="keyword">return</span> it-&gt;second;</span><br><span class="line">    <span class="keyword">auto</span> plan = <span class="built_in">compileSpec</span>(spec);</span><br><span class="line">    <span class="keyword">auto</span> r = plan_cache.<span class="built_in">emplace</span>(std::<span class="built_in">move</span>(spec), std::<span class="built_in">move</span>(plan));</span><br><span class="line">    <span class="keyword">return</span> r.first-&gt;second;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>These code explain itself well: if optimization is turned off, then we only run required passes and cache the result. Otherwise, depending on the characteristic of inputs (<code>ArgumentSpec</code>), we run full optimization and cache the generated plan for each different <code>ArgumentSpec</code>. The plan is created by the constructor of <code>ExecutionPlan</code>.</p><p>It worth a look at what passes are called:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">ExecutionPlan <span class="title">compileSpec</span><span class="params">(<span class="keyword">const</span> ArgumentSpec &amp; spec)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> opt_graph = graph-&gt;<span class="built_in">copy</span>();</span><br><span class="line">  <span class="built_in">setInputTypes</span>(*opt_graph, spec);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Phase 1. Specialize to input definedness (this is very important for</span></span><br><span class="line">  <span class="comment">//          gradient graphs), and run required passes to bring the graph</span></span><br><span class="line">  <span class="comment">//          to an executable form.</span></span><br><span class="line">  <span class="built_in">runRequiredPasses</span>(opt_graph);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Phase 2. Propagate detailed information about the spec through the</span></span><br><span class="line">  <span class="comment">//          graph (enabled more specializations in later passes).</span></span><br><span class="line">  <span class="comment">//          Shape propagation sometimes depends on certain arguments being</span></span><br><span class="line">  <span class="comment">//          constants, and constant propagation doesn&#x27;t need shape information</span></span><br><span class="line">  <span class="comment">//          anyway, so it&#x27;s better to run it first.</span></span><br><span class="line">  <span class="built_in">ConstantPropagation</span>(opt_graph);</span><br><span class="line">  <span class="built_in">PropagateInputShapes</span>(*opt_graph);</span><br><span class="line">  <span class="built_in">PropagateRequiresGrad</span>(opt_graph);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Phase 3. Run differentiable optimizations (i.e. simple graph rewrites that</span></span><br><span class="line">  <span class="comment">//          we can still execute using autograd).</span></span><br><span class="line">  <span class="built_in">runOptimization</span>(opt_graph, spec);</span><br><span class="line"></span><br><span class="line">  <span class="comment">// Phase 4. If this graph will be differentiated, we need to slice out the</span></span><br><span class="line">  <span class="comment">//          symbolically differentiable subgraphs for further optimizations.</span></span><br><span class="line">  <span class="comment">// Phase 5. Apply non-differentiable optimizations to the graphs we&#x27;ve found</span></span><br><span class="line">  <span class="comment">//          (or the whole grpah if we know we won&#x27;t need its derivative).</span></span><br><span class="line">  <span class="keyword">if</span> (<span class="built_in">needsGradient</span>(opt_graph)) &#123;</span><br><span class="line">    <span class="keyword">auto</span> diff_nodes = <span class="built_in">CreateAutodiffSubgraphs</span>(*opt_graph);</span><br><span class="line">    <span class="keyword">for</span> (Node * dnode : diff_nodes) &#123;</span><br><span class="line">      <span class="keyword">auto</span> diff_graph = std::<span class="built_in">move</span>(dnode-&gt;<span class="built_in">g</span>(attr::Subgraph));</span><br><span class="line">      Gradient gradient = <span class="built_in">differentiate</span>(diff_graph);</span><br><span class="line">      <span class="built_in">runNondiffOptimization</span>(gradient.f);</span><br><span class="line">      <span class="built_in">packGradient</span>(gradient, dnode);</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="built_in">InlineAutodiffSubgraphs</span>(opt_graph);</span><br><span class="line">  &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    <span class="built_in">runNondiffOptimization</span>(opt_graph);</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Make sure there are no leftovers from any passes.</span></span><br><span class="line">  <span class="built_in">EliminateDeadCode</span>(opt_graph);</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">ExecutionPlan</span>(opt_graph);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">runOptimization</span><span class="params">(std::shared_ptr&lt;Graph&gt;&amp; graph, <span class="keyword">const</span> ArgumentSpec&amp; spec)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">EliminateDeadCode</span>(graph);</span><br><span class="line">  <span class="built_in">EliminateCommonSubexpression</span>(graph);</span><br><span class="line">  <span class="built_in">UnrollLoops</span>(graph);</span><br><span class="line">  <span class="built_in">PeepholeOptimize</span>(graph);</span><br><span class="line">  <span class="built_in">CheckInplace</span>(graph);</span><br><span class="line">  <span class="built_in">BatchMM</span>(graph);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">runNondiffOptimization</span><span class="params">(std::shared_ptr&lt;Graph&gt;&amp; graph)</span> </span>&#123;</span><br><span class="line">  <span class="built_in">FuseGraph</span>(graph);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="comment">// ......</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">runRequiredPasses</span><span class="params">(<span class="keyword">const</span> std::shared_ptr&lt;Graph&gt;&amp; g)</span>  </span>&#123;</span><br><span class="line">  <span class="built_in">specializeUndef</span>(*g);</span><br><span class="line">  <span class="built_in">LowerGradOf</span>(*g);</span><br><span class="line">  <span class="comment">// implicit inserted expand nodes are not necessarily always valid</span></span><br><span class="line">  <span class="comment">// when used inside script methods that might have unstable shapes</span></span><br><span class="line">  <span class="comment">// we remove the implicitly created ones, and have shape analysis</span></span><br><span class="line">  <span class="comment">// add valid expand nodes when the shapes are stable</span></span><br><span class="line">  <span class="built_in">RemoveExpands</span>(g);</span><br><span class="line">  <span class="built_in">CanonicalizeOps</span>(g);</span><br><span class="line">  <span class="built_in">EliminateDeadCode</span>(g);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>I will not go deep into these passes here, interested readers can read them at <code>torch/csrc/jit/passes/</code>.</p><p>Now it’s time to look at <code>ExecutionPlan</code>:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ExecutionPlan</span> &#123;</span></span><br><span class="line">  <span class="built_in">ExecutionPlan</span>() = <span class="keyword">default</span>;</span><br><span class="line">  <span class="built_in">ExecutionPlan</span>(std::shared_ptr&lt;Graph&gt; graph)</span><br><span class="line">    : <span class="built_in">code</span>(graph)</span><br><span class="line">    , <span class="built_in">graph</span>(std::<span class="built_in">move</span>(graph)) &#123;&#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">(Stack&amp; stack)</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">InterpreterState</span>(code).<span class="built_in">runOneStage</span>(stack);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">operator</span> <span class="title">bool</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> <span class="keyword">static_cast</span>&lt;<span class="keyword">bool</span>&gt;(graph);</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="function">ExecutionPlanState <span class="title">getDebugState</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    ExecutionPlanState state;</span><br><span class="line">    state.code = &amp;code;</span><br><span class="line">    state.graph = graph.<span class="built_in">get</span>();</span><br><span class="line">    <span class="keyword">return</span> state;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  Code code;</span><br><span class="line">  std::shared_ptr&lt;Graph&gt; graph;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>It just convert the graph into an object of <code>Code</code>, and the running is done by <code>InterpreterState</code>.</p><h1 id="Compiling-to-Interpreter-Instructions"><a href="#Compiling-to-Interpreter-Instructions" class="headerlink" title="Compiling to Interpreter Instructions"></a>Compiling to Interpreter Instructions</h1><p><code>Code</code> and <code>InterpreterState</code> are defined in <code>torch/csrc/jit/interpreter.&#123;h,cpp&#125;</code>. These two classes are just a wrapper of its implementations:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">Code::<span class="built_in">Code</span>(std::shared_ptr&lt;Graph&gt;&amp; graph)</span><br><span class="line">    : <span class="built_in">pImpl</span>(<span class="keyword">new</span> <span class="built_in">CodeImpl</span>(graph)) &#123;&#125;</span><br><span class="line">Code::~<span class="built_in">Code</span>() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">const</span> std::vector&lt;GraphExecutor*&gt;&amp; <span class="title">Code::grad_executors</span><span class="params">()</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> pImpl-&gt;<span class="built_in">grad_executors</span>();</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">InterpreterState::<span class="built_in">InterpreterState</span>(<span class="keyword">const</span> Code &amp; code)</span><br><span class="line">  : <span class="built_in">pImpl</span>(<span class="keyword">new</span> <span class="built_in">InterpreterStateImpl</span>(code)) &#123;&#125;</span><br><span class="line">InterpreterState::~<span class="built_in">InterpreterState</span>() = <span class="keyword">default</span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">InterpreterState::runOneStage</span><span class="params">(Stack &amp; stack)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">return</span> pImpl-&gt;<span class="built_in">runOneStage</span>(stack);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><code>CodeImpl</code> is a long struct, but quite logical. A selected list of fields it has is listed below:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">PreprocessGraph preprocess;</span><br><span class="line">std::vector&lt;Instruction&gt; instructions;</span><br></pre></td></tr></table></figure><p>Its constructor is:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">CodeImpl</span>(std::shared_ptr&lt;Graph&gt;&amp; graph_)</span><br><span class="line">    : <span class="built_in">preprocess</span>(*graph_) &#123;</span><br><span class="line">  graph = preprocess.graph;</span><br><span class="line">  <span class="comment">// std::cout &lt;&lt; &quot;into code graph:\n&quot; &lt;&lt; *graph &lt;&lt; &quot;\n&quot;;</span></span><br><span class="line">  <span class="built_in">insertNodesFromBlock</span>(graph-&gt;<span class="built_in">block</span>());</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Clearly we can see what it does is: 1. preprocess the graph, and then 2. emit instructions for interpreter.</p><p>The preprocessing of graph is very well explained in the beginning of file:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// Before we translate to intepreter instructions, we do</span></span><br><span class="line"><span class="comment">// some preprocessing of the graph to turn it into a form that is closer</span></span><br><span class="line"><span class="comment">// to what the instructions will look like.</span></span><br><span class="line"><span class="comment">// In particular we:</span></span><br><span class="line"><span class="comment">// * (TODO) desugar Loop trip counts into c = 0, c += 1 instructions in the loop</span></span><br><span class="line"><span class="comment">// * flatten stages so that each stage starts with a load from the stack</span></span><br><span class="line"><span class="comment">//   and ends with a store to the stack</span></span><br><span class="line"><span class="comment">// *. computes move_flags (see Outputs), and inserts</span></span><br><span class="line"><span class="comment">// *  Drop nodes are inserted for any node that is unused to create a dummy use</span></span><br><span class="line"><span class="comment">//    that will cause the interpreter to free the node.</span></span><br><span class="line"><span class="comment">//    A drop node is just a node with no outputs that just pops its inputs off the stack,</span></span><br><span class="line"><span class="comment">//    to ensure the interpreter release references to nodes that are never used.</span></span><br><span class="line"><span class="comment">//    Drop nodes are also inserted when the last use of a node is in some conditionally</span></span><br><span class="line"><span class="comment">//    run control flow (e.g. one side of an If) and the interpreter must free</span></span><br><span class="line"><span class="comment">//    the node only after the control flow has reconverged</span></span><br><span class="line"><span class="comment">// Outputs are:</span></span><br><span class="line"><span class="comment">// * graph - the post processed copy of g</span></span><br><span class="line"><span class="comment">// * move_flags[n] - a list of booleans, one for each input,</span></span><br><span class="line"><span class="comment">//   indicating whether this is the last use of the value. The interpreter</span></span><br><span class="line"><span class="comment">//   should generate a move rather than a copy in this case.</span></span><br><span class="line"><span class="comment">// * stage_input_types: the type annotations on the inputs to each stage</span></span><br><span class="line"><span class="comment">//   these can be removed once the the backward tracer is no longer used</span></span><br></pre></td></tr></table></figure><p>as well as in its definition</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">PreprocessGraph</span> &#123;</span></span><br><span class="line">  <span class="built_in">PreprocessGraph</span>(Graph &amp; g)</span><br><span class="line">  : <span class="built_in">graph</span>(g.<span class="built_in">copy</span>()) &#123;</span><br><span class="line">    <span class="built_in">desugarTripCounts</span>(graph-&gt;<span class="built_in">block</span>());</span><br><span class="line">    stage_input_types = <span class="built_in">flattenStages</span>(*graph);</span><br><span class="line">    <span class="built_in">dropUnused</span>(graph-&gt;<span class="built_in">block</span>());</span><br><span class="line">    <span class="comment">// fill in move_flags by scanning blocks;</span></span><br><span class="line">    move_flags = <span class="built_in">findLastUses</span>(*graph);</span><br><span class="line">    <span class="comment">//<span class="doctag">TODO:</span> desugar Loop trip counts, for now we drop trip counts</span></span><br><span class="line">  &#125;</span><br><span class="line">  <span class="comment">// Outputs of the preprocessing:</span></span><br><span class="line">  std::shared_ptr&lt;Graph&gt; graph;</span><br><span class="line">  <span class="comment">// for each input, should we move rather than copy the inputs</span></span><br><span class="line">  std::unordered_map&lt;Node*, std::vector&lt;<span class="keyword">uint8_t</span>&gt;&gt; move_flags;</span><br><span class="line">  std::vector&lt;std::vector&lt;TypePtr&gt;&gt; stage_input_types;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>The <code>insertNodesFromBlock</code> emits instructions. It is also very self-explained:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">insertNodesFromBlock</span><span class="params">(Block* block)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">for</span>(<span class="keyword">auto</span> node : block-&gt;<span class="built_in">nodes</span>()) &#123;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">auto</span> &amp; source_location = node-&gt;<span class="built_in">getSourceLocation</span>();</span><br><span class="line">    <span class="built_in"><span class="keyword">switch</span></span>(node-&gt;<span class="built_in">kind</span>()) &#123;</span><br><span class="line">      <span class="keyword">case</span> prim::If: &#123;</span><br><span class="line">        <span class="comment">// x = if c:</span></span><br><span class="line">        <span class="comment">//   &lt;then_block&gt;</span></span><br><span class="line">        <span class="comment">//   -&gt; (vt)</span></span><br><span class="line">        <span class="comment">// else:</span></span><br><span class="line">        <span class="comment">//    &lt;else_block&gt;</span></span><br><span class="line">        <span class="comment">//   -&gt; (vf)</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// turns into:</span></span><br><span class="line">        <span class="comment">//   JumpNZ c, then</span></span><br><span class="line">        <span class="comment">//   &lt;else_block&gt;</span></span><br><span class="line">        <span class="comment">//   x = vf</span></span><br><span class="line">        <span class="comment">//   Jump end</span></span><br><span class="line">        <span class="comment">// then:</span></span><br><span class="line">        <span class="comment">//   &lt;then_block&gt;</span></span><br><span class="line">        <span class="comment">//   x = vt</span></span><br><span class="line">        <span class="comment">// end:</span></span><br><span class="line"></span><br><span class="line">        <span class="comment">// prim::Placeholder instructions are replaced with branch instructions</span></span><br><span class="line">        <span class="comment">// when the branch target locations are known</span></span><br><span class="line">        <span class="keyword">auto</span> cond_branch = <span class="built_in">insertInstruction</span>(prim::Placeholder, source_location, node-&gt;<span class="built_in">inputs</span>(), <span class="built_in">moveFlags</span>(node), &#123;&#125;);</span><br><span class="line">        <span class="keyword">auto</span> then_block = node-&gt;<span class="built_in">blocks</span>()[<span class="number">0</span>];</span><br><span class="line">        <span class="keyword">auto</span> else_block = node-&gt;<span class="built_in">blocks</span>()[<span class="number">1</span>];</span><br><span class="line">        <span class="built_in">insertNodesFromBlock</span>(else_block);</span><br><span class="line">        <span class="built_in">insertAssign</span>(source_location,else_block-&gt;<span class="built_in">outputs</span>(), <span class="built_in">moveFlags</span>(else_block), node-&gt;<span class="built_in">outputs</span>());</span><br><span class="line">        <span class="keyword">auto</span> jump = <span class="built_in">insertInstruction</span>(prim::Placeholder, source_location, &#123;&#125;, &#123;&#125;, &#123;&#125;);</span><br><span class="line">        <span class="keyword">auto</span> then_block_start = instructions.<span class="built_in">size</span>();</span><br><span class="line">        <span class="built_in">insertNodesFromBlock</span>(then_block);</span><br><span class="line">        <span class="built_in">insertAssign</span>(source_location, then_block-&gt;<span class="built_in">outputs</span>(), <span class="built_in">moveFlags</span>(then_block), node-&gt;<span class="built_in">outputs</span>());</span><br><span class="line">        <span class="built_in">createJump</span>(jump, instructions.<span class="built_in">size</span>());</span><br><span class="line">        <span class="built_in">createJumpNZ</span>(cond_branch, then_block_start);</span><br><span class="line">      &#125; <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">case</span> prim::Loop: &#123;</span><br><span class="line">        <span class="comment">// omitted ......</span></span><br><span class="line">      &#125; <span class="keyword">break</span>;</span><br><span class="line">      <span class="keyword">default</span>: &#123;</span><br><span class="line">        <span class="built_in">insertInstruction</span>(node);</span><br><span class="line">      &#125; <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// each stage ends with a load instruction</span></span><br><span class="line">    <span class="comment">// we record where these instructions occur, and use them to</span></span><br><span class="line">    <span class="comment">// exit the interpreter</span></span><br><span class="line">    <span class="keyword">if</span>(node-&gt;<span class="built_in">kind</span>() == prim::Load) &#123;</span><br><span class="line">      stage_end.<span class="built_in">push_back</span>(instructions.<span class="built_in">size</span>());</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Since the nodes are topologically sorted, we just need to iterate the linked list and generate code for each node.</p><h1 id="The-Virtual-Machine"><a href="#The-Virtual-Machine" class="headerlink" title="The Virtual Machine"></a>The Virtual Machine</h1><p><code>InterpreterStateImpl</code> is the virtual machine that executes instructions.</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">InterpreterStateImpl</span>(<span class="keyword">const</span> Code &amp; code)</span><br><span class="line">: <span class="built_in">function</span>(code.pImpl),</span><br><span class="line">  <span class="built_in">int_data</span>(function-&gt;int_data.<span class="built_in">data</span>()),</span><br><span class="line">  <span class="built_in">bool_data</span>(function-&gt;bool_data),</span><br><span class="line">  <span class="built_in">registers</span>(function-&gt;register_size) &#123;</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">runOneStage</span><span class="params">(Stack &amp; stack)</span> </span>&#123;</span><br><span class="line">  <span class="comment">// std::cout &lt;&lt; &quot;running stage: &quot; &lt;&lt; current_stage &lt;&lt; &quot; of &quot; &lt;&lt; function-&gt;stage_end.size() &lt;&lt; &quot;\n&quot;;</span></span><br><span class="line">  <span class="comment">// std::cout &lt;&lt; *function-&gt;graph &lt;&lt; &quot;\n&quot;;</span></span><br><span class="line">  <span class="comment">// function-&gt;dump(std::cout);</span></span><br><span class="line">  <span class="keyword">size_t</span> pc = current_pc;</span><br><span class="line">  <span class="keyword">size_t</span> last = function-&gt;stage_end[current_stage];</span><br><span class="line">  <span class="keyword">auto</span> &amp; instructions = function-&gt;instructions;</span><br><span class="line">  <span class="keyword">while</span>(pc &lt; last) &#123;</span><br><span class="line">      <span class="comment">// std::cout &lt;&lt; &quot;executing &quot; &lt;&lt; pc &lt;&lt; &quot;: &quot;;</span></span><br><span class="line">      <span class="comment">// function-&gt;dumpInstruction(std::cout, pc);</span></span><br><span class="line">      <span class="comment">// std::cout &lt;&lt; &quot;\n&quot;;</span></span><br><span class="line">      <span class="keyword">try</span> &#123;</span><br><span class="line">        <span class="keyword">auto</span> &amp; inst = instructions[pc];</span><br><span class="line">        <span class="built_in">loadTensorsFromRegisters</span>(inst.inputs, stack);</span><br><span class="line">        <span class="keyword">size_t</span> new_pc = pc + <span class="number">1</span> + inst.<span class="built_in">callback</span>(stack);</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = inst.outputs.size - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i--) &#123;</span><br><span class="line">          <span class="keyword">int</span> reg = <span class="built_in">get</span>(inst.outputs,i);</span><br><span class="line">          registers[reg] = <span class="built_in">pop</span>(stack);</span><br><span class="line">          <span class="comment">// std::cout &lt;&lt; &quot;pop reg[&quot; &lt;&lt; reg &lt;&lt; &quot;];\n&quot; &lt;&lt; registers[reg].pImpl &lt;&lt; &quot;\n&quot;;</span></span><br><span class="line">        &#125;</span><br><span class="line">        pc = new_pc;</span><br><span class="line">      &#125; <span class="built_in"><span class="keyword">catch</span></span>(std::exception &amp; e) &#123;</span><br><span class="line">        <span class="keyword">if</span>(!instructions[pc].debug_location)</span><br><span class="line">          <span class="keyword">throw</span>; <span class="comment">// rethrow original exception</span></span><br><span class="line">        <span class="comment">// throw a new exception with enhanced debugging information</span></span><br><span class="line">        instructions[pc].debug_location-&gt;<span class="built_in">wrapAndRethrowException</span>(e, <span class="string">&quot;operation failed in interpreter&quot;</span>);</span><br><span class="line">      &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  current_pc = pc;</span><br><span class="line">  current_stage++;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>There is nothing special, just mimicking the behavior of processors. We can easily tell from the above code that the actions is defined at <code>Instruction::callback</code> and branching is implemented as returning a non-zero value from that callback function. Some of the callbacks are defined inside <code>CodeImpl</code>, such as:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// jump when input is not 0</span></span><br><span class="line"><span class="function"><span class="keyword">void</span> <span class="title">createJumpNZ</span><span class="params">(<span class="keyword">int</span> from_inst, <span class="keyword">int</span> to_inst)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> &amp; inst = instructions[from_inst];</span><br><span class="line">  <span class="built_in">JIT_ASSERT</span>(inst.debug_name == prim::Placeholder);</span><br><span class="line">  <span class="keyword">auto</span> offset = <span class="built_in">relativeJump</span>(from_inst, to_inst);</span><br><span class="line">  inst.callback = [offset](Stack &amp; stack) &#123;</span><br><span class="line">    <span class="keyword">auto</span> t = <span class="built_in">pop</span>(stack).<span class="built_in">toInt</span>();</span><br><span class="line">    <span class="keyword">return</span> (t != <span class="number">0</span>) ? offset : <span class="number">0</span>;</span><br><span class="line">  &#125;;</span><br><span class="line">  inst.debug_name = prim::JumpNZ;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>while others are defined by its node kind:</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">size_t</span> <span class="title">insertInstruction</span><span class="params">(Node * n)</span> </span>&#123;</span><br><span class="line">  <span class="keyword">auto</span> inst = <span class="built_in">insertInstruction</span>(n-&gt;<span class="built_in">kind</span>(), n-&gt;<span class="built_in">getSourceLocation</span>(), n-&gt;<span class="built_in">inputs</span>(), <span class="built_in">moveFlags</span>(n) , n-&gt;<span class="built_in">outputs</span>());</span><br><span class="line">  instructions[inst].callback = <span class="built_in">getOperation</span>(n);</span><br><span class="line">  <span class="keyword">return</span> inst;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>where <code>getOperation</code> is defined in <code>torch/csrc/jit/operator.&#123;h, cpp&#125;</code>. Further reading through these two files, we can see that operations are registered by calling <code>registerOperator</code>, which is done through calling <code>RegisterOperators</code>. Using <code>grep RegisterOperators -r torch/csrc/</code>, we can locate the definition of all operations:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line">torch&#x2F;csrc&#x2F;jit&#x2F;generated&#x2F;register_aten_ops.cpp:RegisterOperators reg(&#123;</span><br><span class="line">torch&#x2F;csrc&#x2F;jit&#x2F;fusers&#x2F;common&#x2F;fusion_handle_impl.cpp:RegisterOperators reg_fused_operators(&#123;</span><br><span class="line">torch&#x2F;csrc&#x2F;jit&#x2F;custom_operator.h:&#x2F;&#x2F;&#x2F; so in the global scope when a &#96;RegisterOperators&#96; object is assigned to a</span><br><span class="line">torch&#x2F;csrc&#x2F;jit&#x2F;custom_operator.h:struct TORCH_API RegisterOperators &#123;</span><br><span class="line">torch&#x2F;csrc&#x2F;jit&#x2F;custom_operator.h:  RegisterOperators() &#x3D; default;</span><br><span class="line">torch&#x2F;csrc&#x2F;jit&#x2F;custom_operator.h:  RegisterOperators(std::vector&lt;Operator&gt; operators) &#123;</span><br><span class="line">torch&#x2F;csrc&#x2F;jit&#x2F;custom_operator.h:  RegisterOperators(const std::string&amp; name, Implementation&amp;&amp; implementation) &#123;</span><br><span class="line">torch&#x2F;csrc&#x2F;jit&#x2F;custom_operator.h:  RegisterOperators&amp; op(</span><br><span class="line">torch&#x2F;csrc&#x2F;jit&#x2F;Python_interpreter.cpp:RegisterOperators reg(&#123;</span><br><span class="line">torch&#x2F;csrc&#x2F;jit&#x2F;register_special_ops.cpp:RegisterOperators reg(&#123;</span><br><span class="line">torch&#x2F;csrc&#x2F;jit&#x2F;graph_executor.cpp:RegisterOperators reg_graph_executor_ops(&#123;</span><br><span class="line">torch&#x2F;csrc&#x2F;jit&#x2F;constants.cpp:RegisterOperators reg(&#123;</span><br><span class="line">torch&#x2F;csrc&#x2F;jit&#x2F;register_prim_ops.cpp:RegisterOperators reg(&#123;</span><br><span class="line">torch&#x2F;csrc&#x2F;jit&#x2F;register_prim_ops.cpp:RegisterOperators reg2(&#123;</span><br><span class="line">torch&#x2F;csrc&#x2F;jit&#x2F;test_jit.cpp:    RegisterOperators reg(&#123;createOperator(</span><br><span class="line">torch&#x2F;csrc&#x2F;jit&#x2F;test_jit.cpp:    RegisterOperators reg(&#123;createOperator(</span><br><span class="line">torch&#x2F;csrc&#x2F;jit&#x2F;test_jit.cpp:    RegisterOperators reg(&#123;createOperator(</span><br><span class="line">torch&#x2F;csrc&#x2F;jit&#x2F;test_jit.cpp:    RegisterOperators reg(</span><br></pre></td></tr></table></figure><p>At this point, we are done with getting the whole big picture of PyTorch’s JIT. It’s time to stop here, and interested readers can read the code by themselves for more details.</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;This is my note for reading PyTorch’s JIT source. We begin by looking at &lt;code&gt;torch.jit.script&lt;/code&gt; and &lt;code&gt;torch.jit.script_method&lt;/code&gt; to find the frontend that compiles the Python code into PyTorch’s tree views, and the backend that compiles tree views to graph. We also read the structure of the internal representation of PyTorch’s graph. Finally we go to graph executor to look at how the computation graph is further compiled into instructions and how the action of these instructions are defined and executed.&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="https://zasdfgbnm.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习" scheme="https://zasdfgbnm.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="PyTorch" scheme="https://zasdfgbnm.github.io/tags/PyTorch/"/>
    
    <category term="深度学习" scheme="https://zasdfgbnm.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>从头开始阅读PyTorch代码 -- Operators篇</title>
    <link href="https://zasdfgbnm.github.io/2018/06/11/%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E9%98%85%E8%AF%BBPyTorch%E4%BB%A3%E7%A0%81%20--%20Operators%E7%AF%87/"/>
    <id>https://zasdfgbnm.github.io/2018/06/11/%E4%BB%8E%E5%A4%B4%E5%BC%80%E5%A7%8B%E9%98%85%E8%AF%BBPyTorch%E4%BB%A3%E7%A0%81%20--%20Operators%E7%AF%87/</id>
    <published>2018-06-11T12:50:00.000Z</published>
    <updated>2021-04-04T05:17:59.766Z</updated>
    
    <content type="html"><![CDATA[<p>这篇是阅读PyTorch源代码整理的笔记，方便以后翻阅。这里主要是想知道PyTorch的operators的定义都是怎么组织的，以及如果要添加新的operator的话，该怎么做。</p><span id="more"></span><p>由于pytorch开发非常活跃，代码也在不断地更改，本文内容跟读者实际看到的最新的代码肯定也有所区别。如果读者想要查看作者写文时候的代码，可以在pytorch仓库中:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git checkout 14cbd9adb8efafbd51444fdd88d6a34e6438b1c5</span><br></pre></td></tr></table></figure><h1 id="init-py跟setup-py"><a href="#init-py跟setup-py" class="headerlink" title="__init__.py跟setup.py"></a><code>__init__.py</code>跟<code>setup.py</code></h1><p>比较不错的着手点是<code>torch</code>这个模块的<code>__init__.py</code>跟安装用的<code>setup.py</code>。 把两个文件都浏览一遍有个大体的概念。然后在<code>__init__.py</code>里面搜<code>__all__</code>，通过观察这些operators是怎么被添加到<code>__all__</code>里面去的，就能知道我们用的所有的那些个operators是怎么来的了。</p><p>搜<code>__all__</code>发现的关键的一段是：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> torch._C <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line">__all__ += [name <span class="keyword">for</span> name <span class="keyword">in</span> <span class="built_in">dir</span>(_C)</span><br><span class="line">            <span class="keyword">if</span> name[<span class="number">0</span>] != <span class="string">&#x27;_&#x27;</span> <span class="keyword">and</span></span><br><span class="line">            <span class="keyword">not</span> name.endswith(<span class="string">&#x27;Base&#x27;</span>)]</span><br></pre></td></tr></table></figure><p>这段干的事情就是把<code>torch._C</code>中定义的各种东西按需加入<code>__all__</code>里面去，所以要想知道哪些operators是怎么来的，还是需要去看<code>torch._C</code>。从名字一看就知道，<code>torch._C</code>这个东西，是PyTorch的用C/C++之类的语言写的那一部分。这就涉及到这一部分是怎么构建的了，这个要从<code>setup.py</code>里面翻找，发现的相关的代码段如下：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">main_sources = [</span><br><span class="line">    <span class="string">&quot;torch/csrc/PtrWrapper.cpp&quot;</span>,</span><br><span class="line">    <span class="comment">#......</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line"><span class="comment">#.....</span></span><br><span class="line"></span><br><span class="line">extensions = []</span><br><span class="line">packages = find_packages(exclude=(<span class="string">&#x27;tools&#x27;</span>, <span class="string">&#x27;tools.*&#x27;</span>, <span class="string">&#x27;caffe2&#x27;</span>, <span class="string">&#x27;caffe2.*&#x27;</span>, <span class="string">&#x27;caffe&#x27;</span>, <span class="string">&#x27;caffe.*&#x27;</span>))</span><br><span class="line">C = Extension(<span class="string">&quot;torch._C&quot;</span>,</span><br><span class="line">              libraries=main_libraries,</span><br><span class="line">              sources=main_sources,</span><br><span class="line">              language=<span class="string">&#x27;c++&#x27;</span>,</span><br><span class="line">              extra_compile_args=main_compile_args + extra_compile_args,</span><br><span class="line">              include_dirs=include_dirs,</span><br><span class="line">              library_dirs=library_dirs,</span><br><span class="line">              extra_link_args=extra_link_args + main_link_args + [make_relative_rpath(<span class="string">&#x27;lib&#x27;</span>)],</span><br><span class="line">              )</span><br><span class="line">extensions.append(C)</span><br></pre></td></tr></table></figure><p>基本上就可以断定<code>torch._C</code>这个东西就是从<code>torch/csrc/</code>这个目录里面的一大堆文件编译出来的了。<code>torch/csrc/</code>里面文件一大堆，从哪里着手是个问题。因为<code>torch._C</code>是python的一个模块，那么肯定得有地方通过python的C-binding创建这个模块才是，这就是个不错的着手点。要找到这个模块是从哪里创建的，这时候就要祭出grep大法了，在<code>torch/csrc/</code>这个目录里面运行这样一条命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep <span class="string">&#x27;torch._C&#x27;</span> -r .</span><br></pre></td></tr></table></figure><p>就可以得到所有有关的代码行了，发现的最像的一行是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;Module.cpp:  ASSERT_TRUE(module &#x3D; Py_InitModule(&quot;torch._C&quot;, methods.data()));</span><br></pre></td></tr></table></figure><p>这一行一看就是在初始化这个模块，而且文件名叫做<code>Module.cpp</code>也很符合，那下一步就从这里开始好了。<code>__init__.py</code>跟<code>setup.py</code>也可以退出我们的历史舞台了。</p><p>另外要注意，在施展grep大法之前，一定要先把PyTorch给编译一遍，因为PyTorch的很多代码是编译的时候根据其他文件生成的，带着生成的文件一起查找比较好。</p><h1 id="Module-cpp跟autograd"><a href="#Module-cpp跟autograd" class="headerlink" title="Module.cpp跟autograd"></a><code>Module.cpp</code>跟autograd</h1><p>把这个文件从头到尾浏览一遍，基本上就可以断定初始化模块是在<code>initModule</code>里面完成的了，这个函数里面初始化了一大堆东西，主要还是找找具体的哪一行是负责初始化那堆operators的。注意到<code>initModule</code>里面有好多类似</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifdef</span> WITH_CUDA</span></span><br><span class="line">  <span class="comment">// do something ....</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span></span></span><br></pre></td></tr></table></figure><p>这种，这种就可以直接跳过不读了，因为不管你是否启用了这一堆的feature，那些个operators都是存在的，那就当你没启用这堆好了。还有一堆东西，看名字就不相关，就直接不用搭理了。所以到最后基本上筛选出来的看起来可能是的也只有：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">THPUtils_addPyMethodDefs</span>(methods, TorchMethods);</span><br><span class="line"><span class="built_in">THPUtils_addPyMethodDefs</span>(methods, torch::autograd::<span class="built_in">python_functions</span>());</span><br><span class="line"><span class="comment">//....</span></span><br><span class="line"><span class="built_in">ASSERT_TRUE</span>(<span class="built_in">THPVariable_initModule</span>(<span class="keyword">module</span>));</span><br><span class="line"><span class="built_in">ASSERT_TRUE</span>(<span class="built_in">THPFunction_initModule</span>(<span class="keyword">module</span>));</span><br></pre></td></tr></table></figure><p>那就先从<code>TorchMethods</code>看起，这个东西就定义在<code>Module.cpp</code>里面，看一眼就会知道跟operators没啥关系。<code>torch::autograd::python_functions()</code>这个东西，使用grep大法，可以发现他的定义位于<code>torch/csrc/autograd/init.cpp</code>，也不是啥想要的，继续看<code>THPVariable_initModule</code>，使用grep大法，就会发现这个函数是在<code>torch/csrc/autograd/python_variable.cpp</code>里面定义的，翻看一下这个函数的定义，注意到下面这行：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">THPUtils_addPyMethodDefs</span>(methods, torch::autograd::variable_methods);</span><br></pre></td></tr></table></figure><p>整个函数定义里面，也只有这一行最像是定义operators的了，于是继续深挖，继续使用grep大法：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep variable_methods -r .</span><br></pre></td></tr></table></figure><p>就会发现这个变量是定义在<code>torch/csrc/</code>下的<code>autograd/generated/python_variable_methods.cpp</code>里面的，打开看看，发现如下的内容：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">PyMethodDef variable_methods[] = &#123;</span><br><span class="line">  &#123;<span class="string">&quot;__add__&quot;</span>, (PyCFunction)THPVariable_add, METH_VARARGS | METH_KEYWORDS, <span class="literal">NULL</span>&#125;,</span><br><span class="line">  <span class="comment">//......</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>这就是一个长长的列表，列举了所有的的operators，每个operator对应一个<code>THPVariable_</code>开头的函数定义在同一个文件里面，而这个文件的开头，则说明了这个文件是从<code>tools/autograd/templates/python_variable_methods.cpp</code>这个模板生成而来。</p><p>浏览一下所有的<code>THPVariable_</code>开头的函数，就会发现所有的不同的这些个函数都大同小异，基本上核心部分只有下面的内容：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">wrap</span>(<span class="built_in">dispatch_xxxxx</span>(...));</span><br></pre></td></tr></table></figure><p>其中<code>dispatch_xxxxx</code>应该就是<code>xxxxx</code>这个operator的核心实现部分。继续动用grep大法挖，只需要随便挑选一个operator搜索就行了，例如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep dispatch_acos -r .</span><br></pre></td></tr></table></figure><p>搜了就会发现这些个<code>dispatch_</code>开头的函数，是定义在同目录以下的<code>python_variable_methods_dispatch.h</code>文件里面的。翻开这个文件，浏览一下这些dispatch函数的定义，都大同小异，下面摘录其中一个：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">inline</span> Tensor <span class="title">dispatch_add</span><span class="params">(Tensor &amp; self, Scalar alpha, <span class="keyword">const</span> Tensor &amp; other)</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">  AutoNoGIL no_gil;</span><br><span class="line">  <span class="function">AutoGPU <span class="title">auto_gpu</span><span class="params">(self)</span></span>;</span><br><span class="line">  <span class="keyword">return</span> self.<span class="built_in">add</span>(other, alpha);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>从代码发现，这些个operator，实际上是<code>Tensor</code>这个类的成员函数，所以我们就知道，下一步应该挖的，就是<code>Tensor</code>这个类了。除此以外，还有一个很重要的东西就是搞明白代码生成的原理，这样就能知道代码生成器是怎样找到这些operators的定义，进而生成这些函数的了。</p><p>Tensor这个类的出处在<code>python_variable_methods_dispatch.h</code>文件的头部可以找到：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">using</span> at::Tensor;</span><br></pre></td></tr></table></figure><p>由此可见Tensor是ATen里面定义的，由此看来autograd也基本要退出我们的历史舞台了，轮到ATen登场了。</p><h1 id="ATen"><a href="#ATen" class="headerlink" title="ATen"></a>ATen</h1><p>要学习ATen其实非常简单，在<code>aten</code>目录里面乱扒乱翻一通，挨个文件夹都点开瞅两眼，把所有的<code>README.md</code>都读一遍，就会发现，实际上ATen的算符是怎么定义的，实际上，已经在<code>aten/src/ATen/native/README.md</code>文件中，进行了非常详细的说明。</p><p>综合各个<code>README.md</code>的信息，并简单总结一下，就是：PyTorch的算符，都是定义在ATen里面的，而ATen里面的算符的实现，一部分是从老的Lua Torch继承而来，这一部分的代码，位于<code>aten/src/TH*</code>这些个目录里面，这些都是历史遗留的遗产，继承过来直接用，并不是PyTorch最终想要的operator的实现方式。最终“好”的实现方式，是在<code>aten/src/ATen/native/</code>目录里面。很多算符，也已经在这个目录下，被重新实现了一遍。这些老的算符的列表，是在<code>aten/src/ATen/Declarations.cwrap</code>中定义的。而新的算符的列表的定义，是在<code>aten/src/ATen/native/native_functions.yaml</code>中。本文只去探讨新的算符的实现方式。</p><p>到了这里，想要继续扒一下新的算符实现的，就需要去扒一下<code>native_functions.yaml</code>这个文件是怎么被读取的了。在PyTorch的根目录下，继续用grep大法，搜索关键字<code>native_functions.yaml</code>，得到的结果中，一条看起来很像是我们想要的结果的是：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;aten&#x2F;src&#x2F;ATen&#x2F;gen.py:    native_files &#x3D; filter_by_extension(options.files, &#39;native_functions.yaml&#39;)</span><br></pre></td></tr></table></figure><p>打开<code>gen.py</code>这个文件查看，就会发现下面比较有趣的代码：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">TEMPLATE_PATH = options.source_path + <span class="string">&quot;/templates&quot;</span></span><br><span class="line"><span class="comment"># ......</span></span><br><span class="line">TENSOR_DERIVED_H = CodeTemplate.from_file(TEMPLATE_PATH + <span class="string">&quot;/TensorDerived.h&quot;</span>)</span><br><span class="line">TENSOR_H = CodeTemplate.from_file(TEMPLATE_PATH + <span class="string">&quot;/Tensor.h&quot;</span>)</span><br><span class="line">TENSOR_METHODS_H = CodeTemplate.from_file(TEMPLATE_PATH + <span class="string">&quot;/TensorMethods.h&quot;</span>)</span><br></pre></td></tr></table></figure><p>以及：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">generate_outputs</span>():</span></span><br><span class="line">    cwrap_files = filter_by_extension(options.files, <span class="string">&#x27;.cwrap&#x27;</span>)</span><br><span class="line">    nn_files = filter_by_extension(options.files, <span class="string">&#x27;nn.yaml&#x27;</span>, <span class="string">&#x27;.h&#x27;</span>)</span><br><span class="line">    native_files = filter_by_extension(options.files, <span class="string">&#x27;native_functions.yaml&#x27;</span>)</span><br><span class="line"></span><br><span class="line">    declarations = [d</span><br><span class="line">                    <span class="keyword">for</span> file <span class="keyword">in</span> cwrap_files</span><br><span class="line">                    <span class="keyword">for</span> d <span class="keyword">in</span> cwrap_parser.parse(file)]</span><br><span class="line"></span><br><span class="line">    declarations += nn_parse.run(nn_files)</span><br><span class="line">    declarations += native_parse.run(native_files)</span><br><span class="line">    declarations = preprocess_declarations.run(declarations)</span><br><span class="line">    <span class="comment"># ......</span></span><br></pre></td></tr></table></figure><p>继续在这附近翻找上下文，就会发现，ATen的代码生成，是通过<code>gen.py</code>等的Python脚本，解析之前说过的那若干个列表文件，然后根据<code>aten/src/ATen/templates/</code>目录下的文件生成的。这些文件，都是模板，不长，全都浏览一遍就是了。阅读的过程，就会发现非常多的重要信息，比如在<code>Tensor.h</code>中有：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> at &#123;</span><br><span class="line"><span class="comment">// ......</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Tensor</span> :</span> <span class="keyword">public</span> detail::TensorBase &#123;</span><br><span class="line"><span class="comment">// ......</span></span><br><span class="line">$&#123;tensor_method_declarations&#125;</span><br><span class="line"><span class="comment">// ......</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="comment">// ......</span></span><br><span class="line">&#125; <span class="comment">// namespace at</span></span><br></pre></td></tr></table></figure><p>以及<code>TensorMethods.h</code>中的：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">namespace</span> at &#123;</span><br><span class="line"></span><br><span class="line"><span class="keyword">inline</span> Tensor &amp; Tensor::<span class="keyword">operator</span>=(Tensor <span class="keyword">const</span> &amp; rhs) &amp;&amp; &#123;</span><br><span class="line">  <span class="keyword">return</span> <span class="built_in">copy_</span>(rhs);</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">// ......</span></span><br><span class="line"><span class="comment">// all static inline to allow for inlining of the non-dynamic part of dispatch</span></span><br><span class="line">$&#123;tensor_method_definitions&#125;</span><br><span class="line"><span class="comment">// ......</span></span><br><span class="line">&#125; <span class="comment">// namespace at</span></span><br></pre></td></tr></table></figure><p>基本上，上面的看完，就已经知道，Tensor类是怎么定义的了。最后一步，就是看一下<code>tensor_method_definitions</code>是怎么填充的了。</p><p>继续动用grep大法扒，在PyTorch的根目录用grep搜索<code>tensor_method_definitions</code>，会得到下面有意思的结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;aten&#x2F;src&#x2F;ATen&#x2F;function_wrapper.py:            top_env[&#39;tensor_method_definitions&#39;].append(</span><br></pre></td></tr></table></figure><p>看了这个，直接跳到<code>function_wrapper.py</code>文件去扒，发现下面一段：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> is_method:</span><br><span class="line">    top_env[<span class="string">&#x27;tensor_method_declarations&#x27;</span>].append(</span><br><span class="line">        TENSOR_METHOD_DECLARATION.substitute(env))</span><br><span class="line">    top_env[<span class="string">&#x27;tensor_method_definitions&#x27;</span>].append(</span><br><span class="line">        TENSOR_METHOD_DEFINITION.substitute(env))</span><br><span class="line">    method_of.append(<span class="string">&#x27;Tensor&#x27;</span>)</span><br></pre></td></tr></table></figure><p>而上面代码中的<code>TENSOR_METHOD_DECLARATION</code>跟<code>TENSOR_METHOD_DEFINITION</code>，就定义在同一个文件中：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># add non-virtual declaration to Tensor.h</span></span><br><span class="line">TENSOR_METHOD_DECLARATION = CodeTemplate(<span class="string">&quot;&quot;&quot;\</span></span><br><span class="line"><span class="string">$&#123;return_type&#125; $&#123;api_name&#125;($&#123;method_formals_with_defaults&#125;)$&#123;const_mark&#125;;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>)</span><br><span class="line"><span class="comment"># add non-virtual declaration to Tensor.cpp</span></span><br><span class="line">TENSOR_METHOD_DEFINITION = CodeTemplate(<span class="string">&quot;&quot;&quot;\</span></span><br><span class="line"><span class="string">inline $&#123;return_type&#125; Tensor::$&#123;api_name&#125;($&#123;method_formals&#125;)$&#123;const_mark&#125; &#123;</span></span><br><span class="line"><span class="string">    return type().$&#123;api_name&#125;($&#123;method_actuals&#125;);</span></span><br><span class="line"><span class="string">&#125;</span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span>)</span><br></pre></td></tr></table></figure><p>至此，基本上，整个ATen的代码生成，基本上算是扒完了，具体做事情的时候，再去返回这些涉及到的文件查看即可。</p><p>本文完结</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;这篇是阅读PyTorch源代码整理的笔记，方便以后翻阅。这里主要是想知道PyTorch的operators的定义都是怎么组织的，以及如果要添加新的operator的话，该怎么做。&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="https://zasdfgbnm.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="机器学习" scheme="https://zasdfgbnm.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    <category term="PyTorch" scheme="https://zasdfgbnm.github.io/tags/PyTorch/"/>
    
    <category term="深度学习" scheme="https://zasdfgbnm.github.io/tags/%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>Using docker image as your desktop system</title>
    <link href="https://zasdfgbnm.github.io/2017/12/29/Using-docker-image-as-your-desktop-system/"/>
    <id>https://zasdfgbnm.github.io/2017/12/29/Using-docker-image-as-your-desktop-system/</id>
    <published>2017-12-30T01:08:54.000Z</published>
    <updated>2021-04-04T05:17:59.766Z</updated>
    
    <content type="html"><![CDATA[<p>In recent years, docker has created a containerization boom around the world by providing a way to easily create and run application containers. Containers save people from dependency hell by packaging the software with the operating environment it needs. Although docker was designed to be neither an operating system container nor an operating system running directly on the bare metal, docker’s powerful suite of tools will also give us tremendous convenience in managing our desktop system running on bare metal.</p><p>Why using docker image as a desktop system is a good idea? Let’s begin with talking about the inconvenience of the normal way how people are managing their desktop systems. Nowadays, most of us has more than one computer, and we want these computers to be “consistent”. Here when I say “consistent”, I mean, for example, I begin writing a document on one computer (say, at home) and am unable to finish it before having to switch to another computer (say, at work). I don’t want to worry about copying it manually to another computer, instead, I want it to be able to magically appear there so I can access it at any time. This is exactly what cloud sync disks like Dropbox do for us.  However, for geeks, what cloud sync disks do is far from enough. For example, you are busy with a project,  which uses a number of programming languages, libraries, and a bunch of  GUI and non-GUI tools. As you keep trying new things, you install new tools and change configurations continually on your system. It would be nice if these changes can be synced across different devices automatically so that when you install something you won’t need to install it one by one on each of your computers.</p><span id="more"></span><h1 id="The-philosophy-of-docker"><a href="#The-philosophy-of-docker" class="headerlink" title="The philosophy of docker"></a>The philosophy of docker</h1><p>Readers unfamiliar with docker can check out <a href="https://docs.docker.com/get-started/">the official tutorial at here</a>. Docker is easy to use: we start by writing a Dockerfile containing commands that install and configure the libraries and tools we want. Readers unfamiliar with docker can take a look at the Dockerfile example below <a href="https://github.com/kstaken/dockerfile-examples/blob/master/nodejs/Dockerfile">that I borrow</a> to get a quick idea on how a Dockerfile looks like:</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> ubuntu</span><br><span class="line"><span class="keyword">MAINTAINER</span> Kimbro Staken</span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get install -y software-properties-common python</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> add-apt-repository ppa:chris-lea/node.js</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;deb http://us.archive.ubuntu.com/ubuntu/ precise universe&quot;</span> &gt;&gt; /etc/apt/sources.list</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get update</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get install -y nodejs</span></span><br><span class="line"><span class="comment">#RUN apt-get install -y nodejs=0.6.12~dfsg1-1ubuntu1</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> mkdir /var/www</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> app.js /var/www/app.js</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">&quot;/usr/bin/node&quot;</span>, <span class="string">&quot;/var/www/app.js&quot;</span>] </span></span><br></pre></td></tr></table></figure><p>With a Dockerfile, a docker image can be created with just a single <code>docker build</code> command. The Docker company offers a service called DockerHub that can host public images for free. Use <code>docker push</code> to upload the image to DockerHub. To get the latest version of your image from DockerHub from a different computer, you only need a <code>docker pull</code>. DockerHub also supports auto-build. By connecting your DockerHub account with your GitHub account, you can make DockerHub automatically regenerates the image whenever the Dockerfile on GitHub changes.</p><p>Docker is actually giving us the solution to the maintenance of consistency mentioned at the beginning of the article: we create a docker image that has everything we needed for our project. In that case, everything related to this project, such as development, testing, deployment, etc., can be done by first opening a container with <code>docker run</code> and then doing all the work inside. When we want to install something new or change some settings, we simply make the appropriate changes in the Dockerfile, rebuild the image, and then update it with <code>docker pull</code> on all the machines using it. This philosophy of use provides a very elegant solution to the problem of consistency through a centralized repository. The only drawback is that not all programs can run in the container, and not all of the programs are easy to run in the container. If you are using a GUI program, or some system-level program, then using the programs inside a container can be a lot of hassle.  So, to overcome this drawback, it is natural to ask: can we mount a docker image directly as the root directory when we boot, so that we can run the image on the bare machine and use it as our daily desktop system?</p><p>There are other benefits to this approach other than the convenience of maintaining consistency:</p><ul><li>The entire system is stored in the cloud, the local content is only a cache of the cloud, so there is no need for regular backup of the system.</li><li>How your system is configured from scratch to the way you want is clearly written in the Dockerfile. Dockerfile then becomes your best note.</li><li>No need to worry about junk files or data corruption of some programs after using your system for a long time. Because every time you turn your computer on, you are using a brand new system.</li><li>When you get a new machine, you don’t have to install the operating system from scratch: just pull the image from DockerHub.</li><li>The process of a system update is nothing but rebuilding a Dockerfile from the latest software repository. Less human intervention will be needed compared to the normal system upgrade, which sometimes encounters file conflicts or dependency problems.</li></ul><h1 id="Docker-storage-driver"><a href="#Docker-storage-driver" class="headerlink" title="Docker storage driver"></a>Docker storage driver</h1><p>There is <a href="https://docs.docker.com/engine/userguide/storagedriver/imagesandcontainers/">an introduction to docker’s storage driver on the official site</a>, so we only discuss it briefly here. Docker uses the concept of layers. When building the image, docker executes the Dockerfile line by line and a new layer is created when executing each line. Only the diff is stored for each layer. When we do a <code>docker pull</code> or <code>docker push</code>, what docker actually does is download or upload the delta between layers instead of the whole layer. Whenever we do a <code>docker run</code>, docker will stack these downloaded deltas together to get a complete image. A new read-write layer (we will call it rwlayer in later contexts) on the top would also be created so that all writes to the container go to the rwlayer and the image itself is kept read-only. The concept of “layer” is actually implemented differently for different file systems where the docker directory (usually the directory <code>/var/lib/docker</code> on your computer) resides. These implementations are called graph drivers. Build-in graph drivers include aufs, overlay, btrfs, zfs, devicemapper and so on. Most graph drivers use copy-on-write techniques so that the process of creating a new layer does not require making a new copy of the data. The actual copy takes place when a write happens.</p><p>As the author only uses btrfs, this article will focus on btrfs. Btrfs is a copy-on-write system. To make use of the copy-on-write feature of btrfs, whenever stacking a new layer, docker creates a snapshot of the original layer’s subvolume and write the diff into the new snapshot. When creating a container from an image, docker would create a snapshot of the top layer’s subvolume and use it as the rwlayer.</p><h1 id="Boot-to-a-docker-image"><a href="#Boot-to-a-docker-image" class="headerlink" title="Boot to a docker image"></a>Boot to a docker image</h1><p>Besides the knowledge on how docker storage drivers work just discussed, we still need to know the Linux startup process to achieve our goal. During boot, the boot manager would load the kernel and a ramdisk called initramfs into memory. After some very basic initializations, the kernel will extract the initramfs to the root directory <code>/</code> and then start the init program in the memory disk (usually <code>/ init</code>). This init program will do some further initialization (for example, loading the file system drivers, do fsck, etc.). Then, this init program will mount the real root directory based on the kernel options <code>root</code>, <code>rootflags</code>, etc. and uses the <code>switch_root</code> program to switch the <code>/</code> from the initramfs to the mounted new root. The init program will be started by <code>switch_root</code> to make final initializations, such as mounting entries in fstab, loading graphics interface and so on. Many distributions provide tools to generate initramfs.  These tools are often modular and allow users to add their own hooks. The Arch Linux’s such tool is called “mkinitcpio”.</p><p>Now we have all the knowledge needed to boot into a docker image, and here is the idea: we can add a hook to initramfs, which creates a snapshot from the desired image’s subvolume in docker’s local cache as a rwlayer before the new root is mounted. The real root is set to be the rwlayer, which will then be mounted and <code>switch_root</code>ed by the init in initramfs. In detail, when writing the kernel option in boot manager’s config file, <code>root</code> should be the partition where your <code>/var/ lib/docker</code> is located, and <code>rootflags</code> must have a <code>subvol=XXXXX</code>, where XXXXX is the relative location of the rwlayer that we plan to create with respect to <code>root</code>. The most important thing to do is to write a hook that: find the btrfs subvolume for the desired docker image, and then create a snapshot of that subvolume named XXXXX (the same name as in the kernel option). If you are using Arch Linux like the author, then all of the works have been done and the reader can use the author’s hook at GitHub directly.</p><p>The code is located at: <a href="https://github.com/zasdfgbnm/mkinitcpio-docker-hooks">https://github.com/zasdfgbnm/mkinitcpio-docker-hooks</a> .  Besides, the readers can also install <code>mkinitcpio-docker-hooks</code> directly from AUR.  A step-by-step tutorial to use this hook is given in the following section.</p><h1 id="Make-a-docker-image-your-desktop-system-using-mkinitcpio-docker-hooks"><a href="#Make-a-docker-image-your-desktop-system-using-mkinitcpio-docker-hooks" class="headerlink" title="Make a docker image your desktop system using mkinitcpio-docker-hooks"></a>Make a docker image your desktop system using mkinitcpio-docker-hooks</h1><p>The usage of mkinitcpio-docker-hooks is roughly divided into the following steps:</p><ol><li>Make sure your <code>/var/lib/docker</code> is in a btrfs partition</li><li>Prepare a docker image suitable for booting on bare metal</li><li>Install and configure mkinitcpio-docker-hooks in this docker image</li><li>Prepare the kernel and initramfs</li><li>Prepare the top layer content</li><li>Setup boot manager</li></ol><h2 id="Prepare-a-docker-image"><a href="#Prepare-a-docker-image" class="headerlink" title="Prepare a docker image"></a>Prepare a docker image</h2><p>To run a docker image on bare metal, you first need to have a docker image that is suitable for doing so. Many docker images, in order to reduce the size of the image, do not come with software packages that are only useful to bare metal running (such as dhcpcd).  So we need to manually install these packages in Dockerfile. For Arch Linux, this can be done simply by installing the group named <code>base</code>. </p><p>Since the next step is to install mkinitcpio-docker-hooks, it is recommended to base your docker image from an image that comes with yaourt. Personally, I use <a href="https://cloud.docker.com/swarm/zasdfgbnm/repository/docker/zasdfgbnm/archlinux-yaourt/general">my own archlinux-yaourt image named <code>zasdfgbnm/archlinux-yaourt</code></a>. Therefore, the first few lines of Dockerfile looks like this:</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> zasdfgbnm/archlinux-yaourt</span><br><span class="line"><span class="keyword">USER</span> root</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> pacman -Syu --noconfirm base</span></span><br></pre></td></tr></table></figure><p>Since this is just a demo, I will not install any other package here. The readers may want to install other packages according to their needs.</p><h2 id="Installation-and-configuration-of-mkinitcpio-docker-hooks"><a href="#Installation-and-configuration-of-mkinitcpio-docker-hooks" class="headerlink" title="Installation and configuration of mkinitcpio-docker-hooks"></a>Installation and configuration of mkinitcpio-docker-hooks</h2><p>The mkinitcpio-docker-hooks package should be installed inside the docker image that we plan to use as our desktop. The reason is mainly that the Linux kernel does not provide ABI stability. Therefore, the kernel modules must be strictly consistent the kernel version, otherwise, the modules cannot be loaded. In order to maintain this consistency, what we do is to install mkinitcpio-docker-hooks and generate initramfs in docker, and use the kernel from the docker image to boot. Doing so will ensure that the kernel, modules copied to initramfs, and the <code>/lib/modules</code> inside the docker image are for the same kernel. To install mkinitcpio-docker-hooks, add the following to Dockerfile:</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="bash"> sudo -u user yaourt -S --noconfirm mkinitcpio-docker-hooks</span></span><br></pre></td></tr></table></figure><p>The configuration file for mkinitcpio-docker-hooks is <code>/etc/docker-btrfs.json</code>, whose default value reads:</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;docker_image&quot;</span>: <span class="string">&quot;archlinux/base&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;docker_tag&quot;</span>: <span class="string">&quot;latest&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>All we need to do is replace the values of these two variables with the values we want, for example, I’m going to name my demo docker image “sample_image”. At the same time, we also need to add the <code>docker-btrfs</code> hook to<code>/etc/mkinitcpio.conf</code>. The following two lines in Dockerfile does the above configuration:</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="bash"> sed -i <span class="string">&#x27;s/archlinux\/base/sample_image/g&#x27;</span> /etc/docker-btrfs.json</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> perl -i -p -e <span class="string">&#x27;s/(?&lt;=^HOOKS=\()(.*)(?=\))/$1 docker-btrfs/g&#x27;</span> /etc/mkinitcpio.conf</span></span><br></pre></td></tr></table></figure><p>Now we have a ready-to-use demo Dockerfile:</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> zasdfgbnm/archlinux-yaourt</span><br><span class="line"><span class="keyword">USER</span> root</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> pacman -Syu --noconfirm base</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> sudo -u user yaourt -S --noconfirm mkinitcpio-docker-hooks</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> sed -i <span class="string">&#x27;s/archlinux\/base/sample_image/g&#x27;</span> /etc/docker-btrfs.json</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> perl -i -p -e <span class="string">&#x27;s/(?&lt;=^HOOKS=\()(.*)(?=\))/$1 docker-btrfs/g&#x27;</span> /etc/mkinitcpio.conf</span></span><br></pre></td></tr></table></figure><p>We can the use the command <code>docker build . -t sample_image</code> to create our docker image from this Dockerfile.</p><h2 id="Prepare-kernel-and-initramfs"><a href="#Prepare-kernel-and-initramfs" class="headerlink" title="Prepare kernel and initramfs"></a>Prepare kernel and initramfs</h2><p>After the image is generated, the next step is to prepare the kernel and initramfs. Note that this step is best done on the machine that you intend to use to start the docker image because mkinitcpio automatically places the appropriate kernel modules into initramfs based on the machine, and if run on other machines, there may be wrong drivers will be packed into initramfs. As mentioned earlier, this step is done inside the docker container.</p><p>First, run the container and open an interactive shell:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -v $(<span class="built_in">pwd</span>):/workspace -w /workspace -it sample_image bash</span><br></pre></td></tr></table></figure><p>Then, run the following commands inside the shell:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkinitcpio -p linux</span><br><span class="line">cp /boot/* .</span><br><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></table></figure><p>Now you can see the <code>vmlinuz-linux</code> and generated <code>initramfs-linux-fallback.img</code> and <code>initramfs-linux.img</code> in the current directory.</p><h2 id="Prepare-the-top-layer-content"><a href="#Prepare-the-top-layer-content" class="headerlink" title="Prepare the top layer content"></a>Prepare the top layer content</h2><p>The top layer is a new concept introduced by mkinitcpio-docker-hooks. It refers to a directory in a drive that will be copied to the rwlayer via busybox’s <code>cp -a</code> at startup, before mounting the real root and after the creation of rwlayer. Why do you need top layer? Because we need to start the same image on multiple machines, different machines often need to have different configuration files, such as <code>/etc/fstab</code> and <code>/etc/X11/xorg.conf</code>. In addition, DockerHub free account can only host very few private images, but <code>/etc/passwd</code>, <code>/etc/shadow</code> and other private files are not suitable to be in a public image.</p><p>Preparation of the top layer is to find a folder to store separate configuration files, in a structure the same way as in image’s file system. For example, if you want a separate <code>/etc/fstab</code>, you should add the file<code>etc/fstab</code> in the top layer’s directory. Here’s the suggested operation flow: first, enter the shell in the container through <code>docker run -v $(pwd): /workspace -w /workspace -it sample_image bash</code>; then, config the system in the shell, such as <code>useradd ...</code>; finally, copy new configuration file to the top layer folder.</p><h2 id="Setup-boot-manager"><a href="#Setup-boot-manager" class="headerlink" title="Setup boot manager"></a>Setup boot manager</h2><p>Now the only thing we need is to set the boot manager. Here we take refind as an example. Everything (docker directory, the top layer, kernel, initramfs) is assumed to be in a btrfs partition labeled “linux”. The docker directory (i.e. the <code>/var/lib/docker</code>) is in a subvolume called “docker” at the root of this partition. The kernel, initramfs, and top layer are all located in the “boot_docker” folder at the root of the partition. We want to name the rwlayer “docker_rwlayer”. Then the menuentry in <code>refind.conf</code> should read:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">menuentry archlinux-docker &#123;</span><br><span class="line">        icon EFI&#x2F;refind&#x2F;icons&#x2F;os_arch.png</span><br><span class="line">        volume linux</span><br><span class="line">        loader boot_docker&#x2F;vmlinuz-linux</span><br><span class="line">        initrd boot_docker&#x2F;initramfs-linux.img</span><br><span class="line">        options &quot;root&#x3D;LABEL&#x3D;linux rootflags&#x3D;subvol&#x3D;docker_rwlayer rw docker_path&#x3D;docker toplayer&#x3D;LABEL&#x3D;linux toplayer_path&#x3D;boot_docker&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Among the kernel options, we specify the partition where the docker directory is located by <code>root</code>. The <code>subvol</code> inside <code>rootflags</code> is used to specify the location of the rwlayer. The <code>docker_path</code> is used to specify the relative position of the docker directory in <code>root</code>. The partition where the top layer is located is specified by <code>toplayer</code>, and <code>toplayerflags</code> is used to specify the mount option for that partition. The <code>toplayer_path</code> is used to specify the relative position of the top layer directory in the<code> toplayer</code> partition.</p><p>Everything is done. Reboot and enjoy!</p><p>In addition, interested readers can take a look at the docker image that the author is using:<br><a href="https://cloud.docker.com/swarm/zasdfgbnmsystem/repository/docker/zasdfgbnmsystem/archlinux-kde/general">https://cloud.docker.com/swarm/zasdfgbnmsystem/repository/docker/zasdfgbnmsystem/archlinux-kde/general</a><br><a href="https://github.com/zasdfgbnm-dockers/archlinux-kde">https://github.com/zasdfgbnm-dockers/archlinux-kde</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;In recent years, docker has created a containerization boom around the world by providing a way to easily create and run application containers. Containers save people from dependency hell by packaging the software with the operating environment it needs. Although docker was designed to be neither an operating system container nor an operating system running directly on the bare metal, docker’s powerful suite of tools will also give us tremendous convenience in managing our desktop system running on bare metal.&lt;/p&gt;
&lt;p&gt;Why using docker image as a desktop system is a good idea? Let’s begin with talking about the inconvenience of the normal way how people are managing their desktop systems. Nowadays, most of us has more than one computer, and we want these computers to be “consistent”. Here when I say “consistent”, I mean, for example, I begin writing a document on one computer (say, at home) and am unable to finish it before having to switch to another computer (say, at work). I don’t want to worry about copying it manually to another computer, instead, I want it to be able to magically appear there so I can access it at any time. This is exactly what cloud sync disks like Dropbox do for us.  However, for geeks, what cloud sync disks do is far from enough. For example, you are busy with a project,  which uses a number of programming languages, libraries, and a bunch of  GUI and non-GUI tools. As you keep trying new things, you install new tools and change configurations continually on your system. It would be nice if these changes can be synced across different devices automatically so that when you install something you won’t need to install it one by one on each of your computers.&lt;/p&gt;</summary>
    
    
    
    <category term="Linux" scheme="https://zasdfgbnm.github.io/categories/Linux/"/>
    
    
    <category term="Linux" scheme="https://zasdfgbnm.github.io/tags/Linux/"/>
    
    <category term="docker" scheme="https://zasdfgbnm.github.io/tags/docker/"/>
    
    <category term="initramfs" scheme="https://zasdfgbnm.github.io/tags/initramfs/"/>
    
  </entry>
  
  <entry>
    <title>把docker镜像当作桌面系统来用</title>
    <link href="https://zasdfgbnm.github.io/2017/12/28/%E6%8A%8Adocker%E9%95%9C%E5%83%8F%E5%BD%93%E4%BD%9C%E6%A1%8C%E9%9D%A2%E7%B3%BB%E7%BB%9F%E6%9D%A5%E7%94%A8/"/>
    <id>https://zasdfgbnm.github.io/2017/12/28/%E6%8A%8Adocker%E9%95%9C%E5%83%8F%E5%BD%93%E4%BD%9C%E6%A1%8C%E9%9D%A2%E7%B3%BB%E7%BB%9F%E6%9D%A5%E7%94%A8/</id>
    <published>2017-12-28T15:41:58.000Z</published>
    <updated>2021-04-04T05:17:59.799Z</updated>
    
    <content type="html"><![CDATA[<p>博主一直都很喜欢思考怎样管理装在自己电脑上的桌面系统，这篇算是前作<a href="2017/06/29/%E8%83%BD%E5%BD%93%E4%B8%BB%E5%8A%9B%EF%BC%8C%E8%83%BD%E5%85%A5%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%8C%E8%BF%98%E8%83%BD%E9%9A%8F%E6%97%B6%E6%89%93%E5%8C%85%E5%B8%A6%E8%B5%B0%EF%BC%8CLinux%E5%B0%B1%E6%98%AF%E8%BF%99%E4%B9%88%E5%BC%BA%E5%A4%A7/">能当主力，能入虚拟机，还能随时打包带走，Linux就是这么强大</a>的后续探索吧。</p><p>近些年来，Docker由于提供了一套非常方便地创建并运行应用容器的方法，而在全球掀起了一股容器化的热潮。容器通过将软件及其所需要的运行环境一同打包带走，从而将人们从依赖的苦海中拯救出来。虽然Docker设计的初衷并不是操作系统容器，更不是一个直接运行在裸机上的操作系统，但是docker这套强大的工具也会给我们管理操作系统带来巨大的便利。</p><p>为什么要用Docker镜像当作桌面系统？这就要从普通桌面系统的不方便之处说起。通常我们都拥有不止一台电脑，我们希望这些电脑能够保持一致。这里所说的“一致”，用一个例子来讲，就是我在一台电脑上编辑了一半的文件，不需要认为拷贝到另一台电脑上，而是直接打开电脑就能编辑。如果这个文件只是一个纯文本文件，或者一个Microsoft Word文档，那么实现这个一致性非常简单：把文件扔到Dropbox之类的云同步盘就好。然而对于专业用户来讲，这种一致性的保持并非单纯的扔到Dropbox里面那么简单：比如说你最近忙于一个项目，这个项目要用到若干编程语言，然后在电脑里装了一堆库，一堆工具软件，有图形界面的，也有命令行的。在工作的过程中，你有可能不断安装新的工具，或者决定弃用某个之前计划使用的库或者工具。要让你的工作在你的若干台电脑上都能工作，就要一直维护不同机器的环境的一致性：在一台机器上安装的工具，要在所有机器上重新安装一遍。在一台机器上升级了的库，要在所有机器上都升级，稍微有所差池，就有可能出现某个脚本/程序在一台机器上跑的好好的，在另一台机器上却无法运行的问题。</p><span id="more"></span><h1 id="docker哲学"><a href="#docker哲学" class="headerlink" title="docker哲学"></a>docker哲学</h1><p>不熟悉docker的读者可以戳<a href="https://docs.docker.com/get-started/">这里</a>来了解docker。Docker的使用非常简单：我们通过写一个Dockerfile，在Dockerfile中写入相应的命令来安装以及配置我们想要的库跟工具。不熟悉docker的读者可以看一下下面这个<a href="https://github.com/kstaken/dockerfile-examples/blob/master/nodejs/Dockerfile">抄来的Dockerfile的例子</a>，来了解一下Dockerfile长啥样子：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> ubuntu</span><br><span class="line"><span class="keyword">MAINTAINER</span> Kimbro Staken</span><br><span class="line"></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get install -y software-properties-common python</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> add-apt-repository ppa:chris-lea/node.js</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> <span class="built_in">echo</span> <span class="string">&quot;deb http://us.archive.ubuntu.com/ubuntu/ precise universe&quot;</span> &gt;&gt; /etc/apt/sources.list</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get update</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> apt-get install -y nodejs</span></span><br><span class="line"><span class="comment">#RUN apt-get install -y nodejs=0.6.12~dfsg1-1ubuntu1</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> mkdir /var/www</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">ADD</span><span class="bash"> app.js /var/www/app.js</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">CMD</span><span class="bash"> [<span class="string">&quot;/usr/bin/node&quot;</span>, <span class="string">&quot;/var/www/app.js&quot;</span>] </span></span><br></pre></td></tr></table></figure><p>有了Dockerfile，只需要<code>docker build</code>一条命令就可以创建一个docker镜像。同时Docker公司提供一个叫做DockerHub的服务，可以免费托管公开镜像。只需要使用<code>docker push</code>就可以直接把镜像上传到DockerHub。在不同的电脑上只需要<code>docker pull</code>就可以从DockerHub获取最新版的镜像。DockerHub还支持自动构建，通过把DockerHub帐号跟GitHub帐号关联起来，就可以让DockerHub在GitHub上面的Dockerfile出现更改的时候自动重新生成镜像。</p><p>本文开头所说的这种一致性的维护，docker实际上已经在给我们提供答案了：我们通过构建一个docker镜像，让这个镜像包含着我们项目所需要的所有的一切。这样的话，我们开发，测试，部署等等一切任务，都可以在先用<code>docker run</code>来开启一个容器，然后在容里面进行所有的工作。当我们决定修改运行环境，比如引入新的库的时候，就在Dockerfile中进行相应的修改，重新生成镜像，然后在不同的机器上用<code>docker pull</code>来更新一下就好。这种使用哲学，通过一个中心化了的仓库，非常优雅地解决了不同机器上环境一致的问题。美中不足的是，并不是所有的程序都能在容器里运行的，也并不是所有的程序都方便在容器里运行的。如果你用到了图形界面的程序，或者说是一些系统级别的程序，那么在容器里面使用这些程序会麻烦很多，有的甚至根本无法实现。于是自然地就会想到，如果我们能够在每次开机的时候，直接把某个docker生成的镜像挂载起来当根目录来使用，就可以让这个镜像直接在裸机上（而不是在容器中）运行，来做我们的日常桌面系统了。</p><p>这种做法，除了在保持一致性方面带来的便利以外，还有一些其他的好处：</p><ul><li>整个系统保存在云端，本地的内容仅仅是云端的一份缓存而已，这样就完全没有必要定期对系统进行备份了。</li><li>你的系统是如何从零开始一步一步配置成你想要的样子的，所有的一切都清晰地展现在Dockerfile里面。Dockerfile就是你最好的笔记。</li><li>完全不用担心系统长时间使用产生一些残余的垃圾文件、或者某些系统中某些程序的数据出现损坏，因为每次开机，我们用的都是一个全新的系统。</li><li>要装一台新机器，并不需要从头安装操作系统，只要从DockerHub拉取镜像拿来用就好，安装系统这个过程变得极其方便。</li><li>系统更新的过程实际上就是根据Dockerfile从最新的软件仓库重新从头安装生成docker镜像的过程，不会出现某些更新遇到文件冲突或者依赖无法处理，需要人为干预才能完成的问题。</li></ul><h1 id="docker存储驱动的工作原理"><a href="#docker存储驱动的工作原理" class="headerlink" title="docker存储驱动的工作原理"></a>docker存储驱动的工作原理</h1><p>Docker的存储驱动<a href="https://docs.docker.com/engine/userguide/storagedriver/imagesandcontainers/">官方有介绍其工作原理</a>，这里只是简单概括一下。Docker使用了层的概念，docker在构建镜像的时候，会逐行执行我们的Dockerfile中的每一行，每执行一行的时候，docker就会创建出一个新的层来存放新的内容。当我们执行<code>docker pull</code>或者<code>docker push</code>的时候，docker实际上传跟下载的是这些层之间的增量。每当执行<code>docker run</code>，docker就会把这些下载下来的层组合到一起，组合成一个完整的镜像，然后新建一个读写层，所有运行过程中的写入都会被写入到读写层中，而镜像本身则是保持只读，不会被更改。“层”这个概念具体实现起来，根据docker目录（通常为<code>/var/lib/docker</code>这个目录）所在的文件系统的不同而不同，具体的实现在docker中被称为graph driver，docker自带的graph driver包括aufs、 overlay、btrfs、zfs、devicemapper等。这些graph driver大多使用了写时复制的技术，这样在把各个层组合在一起的过程不需要重新拷贝一份数据，实际的拷贝是在写入的时候发生的。</p><p>由于笔者使用的是btrfs，所以本文就以btrfs为例子来介绍怎么让系统启动到docker镜像上去。btrfs是一个写时复制的系统，由于docker的镜像是由一个一个的层叠在一起组成的，docker在使用btrfs的时候，每往上叠一层，docker就会创建一个原来层的快照，然后把新层的内容写到快照里面去。然后docker会在从镜像创建容器的时候，给镜像的最顶层做个快照，把这个快照当作容器读写层来用。</p><h1 id="启动到docker镜像中去"><a href="#启动到docker镜像中去" class="headerlink" title="启动到docker镜像中去"></a>启动到docker镜像中去</h1><p>明白了docker存储驱动的工作原理，还需要知道Linux的启动过程才能达成我们的目标。Linux在启动的时候，一般会让启动器给内核装载一个内存盘initramfs，然后内核完成简单的早期初始化以后，就会解压内存盘的内容到根目录<code>/</code>，然后启动内存盘中的init程序（一般为<code>/init</code>），这个init程序会进行进一步的初始化（比如说加载文件系统的驱动，对文件系统进行fsck等），这一步初始化完成了以后，这个init程序就会根据内核选项中的<code>root</code>、<code>rootflags</code>等内容挂载真正的根目录，然后通过<code>switch_root</code>程序启动真正根目录中的init程序，这个init程序则会完成最后的初始化工作，比如挂载fstab、加载图形界面等等。很多发行版都提供制作initramfs的工具，比如archlinux的mkinitcpio，这些工具通常都是模块化的，允许用户自己添加hook。</p><p>让系统启动到docker镜像所需要的知识已经完备了。思路也清晰了：通过给initramfs中添加hook，让initramfs中的init在挂载root之前从docker本地缓存中的镜像中创建出一个快照作为读写层，然后把这个读写层当作真正的root来挂载。具体操作上，在启动管理器里面写启动项的内核选项的时候，<code>root</code>就写<code>/var/lib/docker</code>所在的分区，而<code>rootflags</code>里面至少要有一项<code>subvol=XXXXX</code>，其中XXXXX是我们打算创建的读写层的位置。然后重中之重则是，写一个hook，这个hook干的事情是：找到想要的docker镜像对应的btrfs子卷，给这个子卷创建一个快照，命名为XXXXX（跟内核选项中的名字保持一致）。这样的话，在Linux把控制权交给initramfs中的init程序以后，init程序会先去从docker缓存中的子卷创造出XXXXX快照，然后把XXXXX快照当作root来挂载以及进行接下来的操作。如果读者跟笔者一样使用Arch Linux的话，那么所有的这些工作笔者已经做了，读者可以直接拿来用。</p><p>笔者的源码位于GitHub： <a href="https://github.com/zasdfgbnm/mkinitcpio-docker-hooks">https://github.com/zasdfgbnm/mkinitcpio-docker-hooks</a> ，同时读者也可以直接从AUR中搜索<code>mkinitcpio-docker-hooks</code>来安装笔者的hook。下面就来介绍一下这个hook的使用方法。</p><h1 id="mkinitcpio-docker-hooks的使用"><a href="#mkinitcpio-docker-hooks的使用" class="headerlink" title="mkinitcpio-docker-hooks的使用"></a>mkinitcpio-docker-hooks的使用</h1><p>mkinitcpio-docker-hooks的使用流程大概分为如下几步：</p><ol><li>确保你的<code>/var/lib/docker</code>位于某个btrfs分区中</li><li>准备一个适合在裸机上启动的docker镜像</li><li>然后在这个镜像中安装并配置mkinitcpio-docker-hooks</li><li>准备内核跟initramfs</li><li>准备top layer的内容</li><li>设置启动管理器</li></ol><h2 id="docker镜像的准备"><a href="#docker镜像的准备" class="headerlink" title="docker镜像的准备"></a>docker镜像的准备</h2><p>要想启动到docker镜像中去，首先你得有一个适合在裸机上启动的docker镜像。很多docker镜像，为了减小镜像的大小，是不会附带只有裸机上才能用到的软件包（比如<code>dhcpcd</code>）的，所以读者可能需要在Dockerfile中手动安装这些软件包，对于Arch Linux来讲，只需要安装base组就可以了。由于接下来要安装<code>mkinitcpio-docker-hooks</code>，这里推荐使用一个已经内置yaourt的镜像，笔者使用的是自己的archlinux-yaourt镜像<a href="https://cloud.docker.com/swarm/zasdfgbnm/repository/docker/zasdfgbnm/archlinux-yaourt/general">zasdfgbnm/archlinux-yaourt</a>。所以，Dockerfile的开头看起来是这个样子的：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> zasdfgbnm/archlinux-yaourt</span><br><span class="line"><span class="keyword">USER</span> root</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> pacman -Syu --noconfirm base</span></span><br></pre></td></tr></table></figure><p>作为示例，这里就不安装base之外的其他软件了，读者请自己根据需要安装其他软件。</p><h2 id="安装并配置mkinitcpio-docker-hooks"><a href="#安装并配置mkinitcpio-docker-hooks" class="headerlink" title="安装并配置mkinitcpio-docker-hooks"></a>安装并配置mkinitcpio-docker-hooks</h2><p><code>mkinitcpio-docker-hooks</code>的安装是在docker里面而不是当前运行在裸机上的系统中进行的。之所以要把这个软件包安装在docker镜像里面，很重要的原因是因为Linux内核不提供ABI的稳定性，所以内核模块跟内核的版本必须严格对应，不然模块是无法加载的。为了保持这种一致性，我们采取的措施是，在docker里面安装<code>mkinitcpio-docker-hooks</code>，在docker中生成initramfs，并且在启动的时候用镜像里面的内核启动，就可以确保内核、initramfs中的模块、启动到镜像以后的<code>/lib/modules</code>三者保持一致。安装过程在Dockerfile中的写法如下：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="bash"> sudo -u user yaourt -S --noconfirm mkinitcpio-docker-hooks</span></span><br></pre></td></tr></table></figure><p>安装完了<code>mkinitcpio-docker-hooks</code>以后还需要配置，配置文件在<code>/etc/docker-btrfs.json</code>，初始内容如下：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">    <span class="attr">&quot;docker_image&quot;</span>: <span class="string">&quot;archlinux/base&quot;</span>,</span><br><span class="line">    <span class="attr">&quot;docker_tag&quot;</span>: <span class="string">&quot;latest&quot;</span></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们需要做的就是把这两个变量的值替换为我们想要的值，比如说这里我打算把我的docker镜像的名字叫做“sample_image”。同时，我们还需要在<code>/etc/mkinitcpio.conf</code>中添加<code>docker-btrfs</code>这个hook。<br>综上，可以在Dockerfile中使用如下命令来配置：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">RUN</span><span class="bash"> sed -i <span class="string">&#x27;s/archlinux\/base/sample_image/g&#x27;</span> /etc/docker-btrfs.json</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> perl -i -p -e <span class="string">&#x27;s/(?&lt;=^HOOKS=\()(.*)(?=\))/$1 docker-btrfs/g&#x27;</span> /etc/mkinitcpio.conf</span></span><br></pre></td></tr></table></figure><p>现在，我们有了一个完整的示例Dockerfile了：</p><figure class="highlight dockerfile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">FROM</span> zasdfgbnm/archlinux-yaourt</span><br><span class="line"><span class="keyword">USER</span> root</span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> pacman -Syu --noconfirm base</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> sudo -u user yaourt -S --noconfirm mkinitcpio-docker-hooks</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> sed -i <span class="string">&#x27;s/archlinux\/base/sample_image/g&#x27;</span> /etc/docker-btrfs.json</span></span><br><span class="line"><span class="keyword">RUN</span><span class="bash"> perl -i -p -e <span class="string">&#x27;s/(?&lt;=^HOOKS=\()(.*)(?=\))/$1 docker-btrfs/g&#x27;</span> /etc/mkinitcpio.conf</span></span><br></pre></td></tr></table></figure><p>只需要通过<code>docker build . -t sample_image</code>就可以构建自己的镜像了。</p><h2 id="准备内核跟initramfs"><a href="#准备内核跟initramfs" class="headerlink" title="准备内核跟initramfs"></a>准备内核跟initramfs</h2><p>镜像生成好了以后，下一步就是准备内核跟构建initramfs了。注意这一步操作尽量在你打算用来启动docker镜像的机器上进行，因为mkinitcpio会自动根据机器把相应的内核模块放入initramfs中去，如果在别的机器上进行的话，那就可能会有一些驱动没有被自动装入initramfs中。如前所述，这一步的工作是在docker容器中进行的。首先运行容器并开启一个shell：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">docker run -v $(<span class="built_in">pwd</span>):/workspace -w /workspace -it sample_image bash</span><br></pre></td></tr></table></figure><p>然后在容器中执行如下命令：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mkinitcpio -p linux</span><br><span class="line">cp /boot/* .</span><br><span class="line"><span class="built_in">exit</span></span><br></pre></td></tr></table></figure><p>然后就可以在当前目录下看到准备好的<code>initramfs-linux-fallback.img</code>、<code>initramfs-linux.img</code>以及<code>vmlinuz-linux</code>了。</p><h2 id="准备top-layer的内容"><a href="#准备top-layer的内容" class="headerlink" title="准备top layer的内容"></a>准备top layer的内容</h2><p>Top layer是<code>mkinitcpio-docker-hooks</code>引入的新概念，它指的是某个驱动器中的某个目录，这个目录会在启动的时候读写层创建之后，真正的root挂载之前，通过busybox的<code>cp -a</code>命令整个拷贝到读写层里面去。为什么需要top layer呢？因为我们需要在多台机器上启动同一个镜像，而不同机器上的往往会根据需要配置不同的配置文件，比如<code>/etc/fstab</code>以及<code>/etc/X11/xorg.conf</code>。另外，DockerHub免费账户上的镜像都是公开的，<code>/etc/passwd</code>、<code>/etc/shadow</code>等的私密性文件也不适合放在镜像里面存储。</p><p>准备top layer的内容，实际上就是找一个文件夹，把需要单独配置的文件，按照从根目录算起的相对路径存放在这个文件夹里面。比如说如果你想给某台机器单独配置<code>/etc/fstab</code>，那么你就应该在top layer的目录中添加<code>etc/fstab</code>这个文件。这里推荐的具体的操作流程是：首先通过<code>docker run -v $(pwd):/workspace -w /workspace -it sample_image bash</code>进入容器中的shell，然后在其中做各种配置，比如<code>useradd ...</code>，完了以后把新生成的配置文件拷贝到top layer的文件夹中去</p><h2 id="设置启动管理器"><a href="#设置启动管理器" class="headerlink" title="设置启动管理器"></a>设置启动管理器</h2><p>设置好了top layer以后，我们基本上可以算是万事具备只差东风了。我们只需要简单设置一下启动管理器就可以启动我们的系统了。这里以refind为例子，这里假设我们的所有东西放在一个label为“linux”的btrfs分区中，docker目录（也就是你系统启动以后会挂载到<code>/var/lib/docker</code>的目录）存放在这个分区根目录下的一个叫做“docker”的子卷中，而内核、initramfs以及top layer都是位于分区根目录下的“boot_docker”文件夹中，而我们希望创建的读写层名字叫做“docker_rwlayer”，那么相应的<code>refind.conf</code>中的菜单项的代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">menuentry archlinux-docker &#123;</span><br><span class="line">        icon EFI&#x2F;refind&#x2F;icons&#x2F;os_arch.png</span><br><span class="line">        volume linux</span><br><span class="line">        loader boot_docker&#x2F;vmlinuz-linux</span><br><span class="line">        initrd boot_docker&#x2F;initramfs-linux.img</span><br><span class="line">        options &quot;root&#x3D;LABEL&#x3D;linux rootflags&#x3D;subvol&#x3D;docker_rwlayer rw docker_path&#x3D;docker toplayer&#x3D;LABEL&#x3D;linux toplayer_path&#x3D;boot_docker&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中内核选项中，我们通过<code>root</code>来指定docker目录所在的分区，<code>rootflags</code>中的<code>subvol</code>来指定读写层的位置，<code>docker_path</code>来指定docker目录在<code>root</code>中的相对位置；通过<code>toplayer</code>来指定top layer目录所在的分区，<code>toplayerflags</code>来指定top layer所在分区的挂载选项，<code>toplayer_path</code>来指定top layer的目录在<code>toplayer</code>分区中的相对位置。</p><p>一切就绪，重启并享受吧！</p><p>另外，有兴趣的读者可以看一下笔者自用的docker镜像作为参考：<br><a href="https://cloud.docker.com/swarm/zasdfgbnmsystem/repository/docker/zasdfgbnmsystem/archlinux-kde/general">https://cloud.docker.com/swarm/zasdfgbnmsystem/repository/docker/zasdfgbnmsystem/archlinux-kde/general</a><br><a href="https://github.com/zasdfgbnm-dockers/archlinux-kde">https://github.com/zasdfgbnm-dockers/archlinux-kde</a></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;博主一直都很喜欢思考怎样管理装在自己电脑上的桌面系统，这篇算是前作&lt;a href=&quot;2017/06/29/%E8%83%BD%E5%BD%93%E4%B8%BB%E5%8A%9B%EF%BC%8C%E8%83%BD%E5%85%A5%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%8C%E8%BF%98%E8%83%BD%E9%9A%8F%E6%97%B6%E6%89%93%E5%8C%85%E5%B8%A6%E8%B5%B0%EF%BC%8CLinux%E5%B0%B1%E6%98%AF%E8%BF%99%E4%B9%88%E5%BC%BA%E5%A4%A7/&quot;&gt;能当主力，能入虚拟机，还能随时打包带走，Linux就是这么强大&lt;/a&gt;的后续探索吧。&lt;/p&gt;
&lt;p&gt;近些年来，Docker由于提供了一套非常方便地创建并运行应用容器的方法，而在全球掀起了一股容器化的热潮。容器通过将软件及其所需要的运行环境一同打包带走，从而将人们从依赖的苦海中拯救出来。虽然Docker设计的初衷并不是操作系统容器，更不是一个直接运行在裸机上的操作系统，但是docker这套强大的工具也会给我们管理操作系统带来巨大的便利。&lt;/p&gt;
&lt;p&gt;为什么要用Docker镜像当作桌面系统？这就要从普通桌面系统的不方便之处说起。通常我们都拥有不止一台电脑，我们希望这些电脑能够保持一致。这里所说的“一致”，用一个例子来讲，就是我在一台电脑上编辑了一半的文件，不需要认为拷贝到另一台电脑上，而是直接打开电脑就能编辑。如果这个文件只是一个纯文本文件，或者一个Microsoft Word文档，那么实现这个一致性非常简单：把文件扔到Dropbox之类的云同步盘就好。然而对于专业用户来讲，这种一致性的保持并非单纯的扔到Dropbox里面那么简单：比如说你最近忙于一个项目，这个项目要用到若干编程语言，然后在电脑里装了一堆库，一堆工具软件，有图形界面的，也有命令行的。在工作的过程中，你有可能不断安装新的工具，或者决定弃用某个之前计划使用的库或者工具。要让你的工作在你的若干台电脑上都能工作，就要一直维护不同机器的环境的一致性：在一台机器上安装的工具，要在所有机器上重新安装一遍。在一台机器上升级了的库，要在所有机器上都升级，稍微有所差池，就有可能出现某个脚本/程序在一台机器上跑的好好的，在另一台机器上却无法运行的问题。&lt;/p&gt;</summary>
    
    
    
    <category term="Linux" scheme="https://zasdfgbnm.github.io/categories/Linux/"/>
    
    
    <category term="Linux" scheme="https://zasdfgbnm.github.io/tags/Linux/"/>
    
    <category term="docker" scheme="https://zasdfgbnm.github.io/tags/docker/"/>
    
    <category term="initramfs" scheme="https://zasdfgbnm.github.io/tags/initramfs/"/>
    
  </entry>
  
  <entry>
    <title>Adding new expressions to nftables</title>
    <link href="https://zasdfgbnm.github.io/2017/09/07/Extending-nftables/"/>
    <id>https://zasdfgbnm.github.io/2017/09/07/Extending-nftables/</id>
    <published>2017-09-07T19:50:12.000Z</published>
    <updated>2021-04-04T05:17:59.763Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h1><p>I’m recently writing something that uses Linux’s firewall framework to do some non-standard operations packets. Extending the kernel is required for my task but unfortunately documentations about this topic I find online are quite dated. These old documents are mainly for kernel version 2.4 and earlier 2.6.x, in which new matches or targets are registered by calling <code>ipt_register_match</code> and <code>ipt_register_target</code>. The related subsystem of kernel has changed a lot since then, and iptables has been replaced by nftables. Although we can use <code>xt_register_match</code> and <code>xt_register_target</code> instead, I prefer to move to the new nftables framework. Due to the lack of documentation, I have to dig into the source code of Linux kernel to figure out how things works, and this post is the note for that. As Linus Torvalds says in 2008, “Linux is evolution, not intelligent design”, the design and API of nftables might be changing very fast. So I’m not only trying to make a brief review on the design or API of nftables. But also, this post will serve as a guide on how to find the correct way of doing things by reading the kernel source code. The eager reader can go directly to <a href="#summary">the summary section</a>. This post is based on kernel version 4.13, the most recent version when this post is started writing.</p><p>Here in this post, we will solve a toy problem: monitor all outgoing TCP traffic from port 80, if it contains the string given by the user, log it. I don’t assume any knowledge in the design or kernel API of nftables, but I do assume the reader has read and understand well <a href="https://wiki.nftables.org/">the official documents on how to use nftables</a>.</p><span id="more"></span><h1 id="Starting-point-of-kernel-code"><a href="#Starting-point-of-kernel-code" class="headerlink" title="Starting point of kernel code"></a>Starting point of kernel code</h1><p>The starting point is to find which source file to read. The following command gives a nice overview on nftables in Linux kernel:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -P <span class="string">&#x27;nftables|nf_tables&#x27;</span> -r .</span><br></pre></td></tr></table></figure><p>The output shall be something that looks like:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">.&#x2F;include&#x2F;net&#x2F;netfilter&#x2F;nf_tables_core.h:int nf_tables_core_module_init(void);</span><br><span class="line">.&#x2F;include&#x2F;net&#x2F;netfilter&#x2F;nf_tables_core.h:void nf_tables_core_module_exit(void);</span><br><span class="line">.&#x2F;include&#x2F;net&#x2F;netfilter&#x2F;nf_tables_ipv4.h:#include &lt;net&#x2F;netfilter&#x2F;nf_tables.h&gt;</span><br><span class="line">.&#x2F;include&#x2F;net&#x2F;netfilter&#x2F;nf_tables.h:#include &lt;linux&#x2F;netfilter&#x2F;nf_tables.h&gt;</span><br><span class="line">.&#x2F;include&#x2F;net&#x2F;netfilter&#x2F;nf_tables.h: *  struct nft_verdict - nf_tables verdict</span><br><span class="line">.&#x2F;include&#x2F;net&#x2F;netfilter&#x2F;nf_tables.h: *  @code: nf_tables&#x2F;netfilter verdict code</span><br><span class="line">.&#x2F;include&#x2F;net&#x2F;netfilter&#x2F;nf_tables.h: *  struct nft_regs - nf_tables register set</span><br><span class="line">.&#x2F;include&#x2F;net&#x2F;netfilter&#x2F;nf_tables.h: *  struct nft_ctx - nf_tables rule&#x2F;set context</span><br><span class="line">...........</span><br></pre></td></tr></table></figure><p>The files listed in the output will be the files to look at. A good tool to read Linux kernel source code is <a href="http://elixir.free-electrons.com/linux/v4.13/source">FreeElectrons</a>. We can start by looking at the file names in directory <a href="http://elixir.free-electrons.com/linux/v4.13/source/include/net/netfilter">include/net/netfilter</a> on its website. We can see nft_masq.h, nft_redir.h, nft_reject.h in that directory. These are all actions in nftables. Following the references of symbols defined in these files will lead us towards sample codes on how to create new actions. Let’s take reject as an example. From its <a href="http://elixir.free-electrons.com/linux/v4.13/source/include/net/netfilter/nft_reject.h">header</a>, we can find an interesting symbol <code>nft_reject_init</code>. Looking around <a href="http://elixir.free-electrons.com/linux/v4.13/ident/nft_reject_init">all the definitions and references of that symbol</a>, we are able to find the core code at <a href="http://elixir.free-electrons.com/linux/v4.13/source/net/ipv4/netfilter/nft_reject_ipv4.c">net/ipv4/netfilter/nft_reject_ipv4.c</a>.  In its core code, <a href="http://elixir.free-electrons.com/linux/v4.13/source/net/ipv4/netfilter/nft_reject_ipv4.c#L61">L61-L72</a> reads:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> __init <span class="title">nft_reject_ipv4_module_init</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">return</span> nft_register_expr(&amp;nft_reject_ipv4_type);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> __exit <span class="title">nft_reject_ipv4_module_exit</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">nft_unregister_expr(&amp;nft_reject_ipv4_type);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">module_init(nft_reject_ipv4_module_init);</span><br><span class="line">module_exit(nft_reject_ipv4_module_exit);</span><br></pre></td></tr></table></figure><p>We can immediately know from the above code that we should call <code>nft_register_expr</code> to register an expression and call <code>nft_unregister_expr</code> to unregister.</p><p>Now let’s take a look at <a href="http://elixir.free-electrons.com/linux/v4.13/source/include/net/netfilter/nf_tables.h#L999">the prototype of <code>nft_register_expr</code> in nf_tables.h</a>:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">nft_register_expr</span><span class="params">(struct nft_expr_type *)</span></span>;</span><br></pre></td></tr></table></figure><p>It takes one parameter of type <code>struct nft_expr_type *</code>. This struct is also defined in nf_tables.h at <a href="http://elixir.free-electrons.com/linux/v4.13/source/include/net/netfilter/nf_tables.h#L681">L681</a>.  The usage of <code>nft_register_expr</code> and <code>nft_expr_type</code> can be guessed by reading all the examples. The list of all examples can be found from its reference in <a href="http://elixir.free-electrons.com/linux/v4.13/ident/nft_register_expr">here</a>. In that list, there is one file that looks very interesting from its file name:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">net&#x2F;netfilter&#x2F;nf_tables_core.c, line 251</span><br></pre></td></tr></table></figure><p><a href="http://elixir.free-electrons.com/linux/v4.13/source/net/netfilter/nf_tables_core.c#L251">Open this link</a>, we can see all these basic expressions:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">nft_expr_type</span> *<span class="title">nft_basic_types</span>[] =</span> &#123;</span><br><span class="line">&amp;nft_imm_type,</span><br><span class="line">&amp;nft_cmp_type,</span><br><span class="line">&amp;nft_lookup_type,</span><br><span class="line">&amp;nft_bitwise_type,</span><br><span class="line">&amp;nft_byteorder_type,</span><br><span class="line">&amp;nft_payload_type,</span><br><span class="line">&amp;nft_dynset_type,</span><br><span class="line">&amp;nft_range_type,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> __init <span class="title">nf_tables_core_module_init</span><span class="params">(<span class="keyword">void</span>)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">int</span> err, i;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; ARRAY_SIZE(nft_basic_types); i++) &#123;</span><br><span class="line">err = nft_register_expr(nft_basic_types[i]);</span><br><span class="line"><span class="keyword">if</span> (err)</span><br><span class="line"><span class="keyword">goto</span> err;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">err:</span><br><span class="line"><span class="keyword">while</span> (i-- &gt; <span class="number">0</span>)</span><br><span class="line">nft_unregister_expr(nft_basic_types[i]);</span><br><span class="line"><span class="keyword">return</span> err;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>Now we know what to look at. The next step will be to read these examples to get a feeling on how to write our own expression.</p><h1 id="The-usage-of-kernel-API"><a href="#The-usage-of-kernel-API" class="headerlink" title="The usage of kernel API"></a>The usage of kernel API</h1><p>To know the usage of related API, we choose to read the reject operation for the inet family and compare operation as sample code. The source code of reject is located at <a href="http://elixir.free-electrons.com/linux/v4.13/source/net/netfilter/nft_reject_inet.c">net/netfilter/nft_reject_inet.c</a>. The source code of compare is loacated at <a href="http://elixir.free-electrons.com/linux/v4.13/source/net/netfilter/nft_cmp.c">net/netfilter/nft_cmp.c</a>. In the case that one expression only correspond to one operation, the usage is shown below by the source code of reject operation at <a href="http://elixir.free-electrons.com/linux/v4.13/source/net/netfilter/nft_reject_inet.c#L120">L120</a>:<a name="nft_expr_ops_and_nft_expr_type_reject"></a></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">nft_expr_type</span> <span class="title">nft_reject_inet_type</span>;</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">nft_expr_ops</span> <span class="title">nft_reject_inet_ops</span> =</span> &#123;</span><br><span class="line">.type= &amp;nft_reject_inet_type,</span><br><span class="line">.size= NFT_EXPR_SIZE(<span class="keyword">sizeof</span>(struct nft_reject)),</span><br><span class="line">.eval= nft_reject_inet_eval,</span><br><span class="line">.init= nft_reject_inet_init,</span><br><span class="line">.dump= nft_reject_inet_dump,</span><br><span class="line">.validate= nft_reject_validate,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">nft_expr_type</span> <span class="title">nft_reject_inet_type</span> __<span class="title">read_mostly</span> =</span> &#123;</span><br><span class="line">.family= NFPROTO_INET,</span><br><span class="line">.name= <span class="string">&quot;reject&quot;</span>,</span><br><span class="line">.ops= &amp;nft_reject_inet_ops,</span><br><span class="line">.policy= nft_reject_policy,</span><br><span class="line">.maxattr= NFTA_REJECT_MAX,</span><br><span class="line">.owner= THIS_MODULE,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>From the above code, we know that we should create an instance of both <code>struct nft_expr_ops</code> and <code>struct nft_expr_type</code> and point to each other at <code>nft_expr_ops.type</code> and <code>nft_expr_type.ops</code>.  In the case that one expression correspond to many operations, the usage is shown below by the source code of compare operation:<a name="nft_expr_ops_and_nft_expr_type_cmp"></a></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">nft_expr_ops</span> <span class="title">nft_cmp_ops</span> =</span> &#123;</span><br><span class="line">.type= &amp;nft_cmp_type,</span><br><span class="line">.size= NFT_EXPR_SIZE(<span class="keyword">sizeof</span>(struct nft_cmp_expr)),</span><br><span class="line">.eval= nft_cmp_eval,</span><br><span class="line">.init= nft_cmp_init,</span><br><span class="line">.dump= nft_cmp_dump,</span><br><span class="line">&#125;;</span><br><span class="line">...........</span><br><span class="line"><span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">nft_expr_ops</span> <span class="title">nft_cmp_fast_ops</span> =</span> &#123;</span><br><span class="line">.type= &amp;nft_cmp_type,</span><br><span class="line">.size= NFT_EXPR_SIZE(<span class="keyword">sizeof</span>(struct nft_cmp_fast_expr)),</span><br><span class="line">.eval= <span class="literal">NULL</span>,<span class="comment">/* inlined */</span></span><br><span class="line">.init= nft_cmp_fast_init,</span><br><span class="line">.dump= nft_cmp_fast_dump,</span><br><span class="line">&#125;;</span><br><span class="line">...........</span><br><span class="line"><span class="keyword">static</span> <span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">nft_expr_ops</span> *</span></span><br><span class="line"><span class="class"><span class="title">nft_cmp_select_ops</span>(<span class="title">const</span> <span class="keyword">struct</span> <span class="title">nft_ctx</span> *<span class="title">ctx</span>, <span class="title">const</span> <span class="keyword">struct</span> <span class="title">nlattr</span> * <span class="title">const</span> <span class="title">tb</span>[])</span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">nft_data_desc</span> <span class="title">desc</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">nft_data</span> <span class="title">data</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">enum</span> <span class="title">nft_cmp_ops</span> <span class="title">op</span>;</span></span><br><span class="line"><span class="keyword">int</span> err;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (tb[NFTA_CMP_SREG] == <span class="literal">NULL</span> ||</span><br><span class="line">    tb[NFTA_CMP_OP] == <span class="literal">NULL</span> ||</span><br><span class="line">    tb[NFTA_CMP_DATA] == <span class="literal">NULL</span>)</span><br><span class="line"><span class="keyword">return</span> ERR_PTR(-EINVAL);</span><br><span class="line"></span><br><span class="line">op = ntohl(nla_get_be32(tb[NFTA_CMP_OP]));</span><br><span class="line"><span class="keyword">switch</span> (op) &#123;</span><br><span class="line"><span class="keyword">case</span> NFT_CMP_EQ:</span><br><span class="line"><span class="keyword">case</span> NFT_CMP_NEQ:</span><br><span class="line"><span class="keyword">case</span> NFT_CMP_LT:</span><br><span class="line"><span class="keyword">case</span> NFT_CMP_LTE:</span><br><span class="line"><span class="keyword">case</span> NFT_CMP_GT:</span><br><span class="line"><span class="keyword">case</span> NFT_CMP_GTE:</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line"><span class="keyword">return</span> ERR_PTR(-EINVAL);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">err = nft_data_init(<span class="literal">NULL</span>, &amp;data, <span class="keyword">sizeof</span>(data), &amp;desc,</span><br><span class="line">    tb[NFTA_CMP_DATA]);</span><br><span class="line"><span class="keyword">if</span> (err &lt; <span class="number">0</span>)</span><br><span class="line"><span class="keyword">return</span> ERR_PTR(err);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (desc.type != NFT_DATA_VALUE) &#123;</span><br><span class="line">err = -EINVAL;</span><br><span class="line"><span class="keyword">goto</span> err1;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (desc.len &lt;= <span class="keyword">sizeof</span>(u32) &amp;&amp; op == NFT_CMP_EQ)</span><br><span class="line"><span class="keyword">return</span> &amp;nft_cmp_fast_ops;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> &amp;nft_cmp_ops;</span><br><span class="line">err1:</span><br><span class="line">nft_data_release(&amp;data, desc.type);</span><br><span class="line"><span class="keyword">return</span> ERR_PTR(-EINVAL);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">nft_expr_type</span> <span class="title">nft_cmp_type</span> __<span class="title">read_mostly</span> =</span> &#123;</span><br><span class="line">.name= <span class="string">&quot;cmp&quot;</span>,</span><br><span class="line">.select_ops= nft_cmp_select_ops,</span><br><span class="line">.policy= nft_cmp_policy,</span><br><span class="line">.maxattr= NFTA_CMP_MAX,</span><br><span class="line">.owner= THIS_MODULE,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>From this we can see that we should create an instance of <code>struct nft_expr_ops</code> for each operation, and use <code>select_ops</code> to choose dynamically which operation to use.  The <code>select_ops</code> should return the pointer to the operation chosen, or an <code>ERR_PTR</code> in case of error. Now Let’s discuss <code>struct nft_expr_ops</code> and <code>struct nft_expr_type</code> in detail separately.</p><h2 id="struct-nft-expr-ops"><a href="#struct-nft-expr-ops" class="headerlink" title="struct nft_expr_ops"></a>struct nft_expr_ops</h2><p>Let’s take a look at <code>struct nft_expr_ops</code> first. It’s definition is at <a href="http://elixir.free-electrons.com/linux/v4.13/source/include/net/netfilter/nf_tables.h#L722">include/net/netfilter/nf_tables.h#L722</a>:<a name="nft_expr_ops"></a></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> *struct nft_expr_ops - nf_tables expression operations</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> *@eval: Expression evaluation function</span></span><br><span class="line"><span class="comment"> *@size: full expression size, including private data size</span></span><br><span class="line"><span class="comment"> *@init: initialization function</span></span><br><span class="line"><span class="comment"> *@destroy: destruction function</span></span><br><span class="line"><span class="comment"> *@dump: function to dump parameters</span></span><br><span class="line"><span class="comment"> *@type: expression type</span></span><br><span class="line"><span class="comment"> *@validate: validate expression, called during loop detection</span></span><br><span class="line"><span class="comment"> *@data: extra data to attach to this expression operation</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">nft_expr</span>;</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">nft_expr_ops</span> &#123;</span></span><br><span class="line"><span class="keyword">void</span>(*eval)(<span class="keyword">const</span> struct nft_expr *expr,</span><br><span class="line">struct nft_regs *regs,</span><br><span class="line"><span class="keyword">const</span> struct nft_pktinfo *pkt);</span><br><span class="line"><span class="keyword">int</span>(*clone)(struct nft_expr *dst,</span><br><span class="line"> <span class="keyword">const</span> struct nft_expr *src);</span><br><span class="line"><span class="keyword">unsigned</span> <span class="keyword">int</span>size;</span><br><span class="line"></span><br><span class="line"><span class="keyword">int</span>(*init)(<span class="keyword">const</span> struct nft_ctx *ctx,</span><br><span class="line"><span class="keyword">const</span> struct nft_expr *expr,</span><br><span class="line"><span class="keyword">const</span> struct nlattr * <span class="keyword">const</span> tb[]);</span><br><span class="line"><span class="keyword">void</span>(*destroy)(<span class="keyword">const</span> struct nft_ctx *ctx,</span><br><span class="line">   <span class="keyword">const</span> struct nft_expr *expr);</span><br><span class="line"><span class="keyword">int</span>(*dump)(struct sk_buff *skb,</span><br><span class="line"><span class="keyword">const</span> struct nft_expr *expr);</span><br><span class="line"><span class="keyword">int</span>(*validate)(<span class="keyword">const</span> struct nft_ctx *ctx,</span><br><span class="line">    <span class="keyword">const</span> struct nft_expr *expr,</span><br><span class="line">    <span class="keyword">const</span> struct nft_data **data);</span><br><span class="line"><span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">nft_expr_type</span>*<span class="title">type</span>;</span></span><br><span class="line"><span class="keyword">void</span>*data;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>From the name and comments of these fields, we can see that <code>init</code>, <code>destroy</code>, <code>clone</code> play the role of constructor, destructor, and copy constructor. What to do in these functions is shown in <a href="#nft_expr_ops_and_nft_expr_type_reject">the code above</a>. In that code, <code>init</code> is defined as <code>nft_reject_inet_init</code> and <code>clone</code> and <code>destroy</code> are not defined. The source code for <code>nft_reject_inet_init</code> is located at <a href="http://elixir.free-electrons.com/linux/v4.13/source/net/netfilter/nft_reject_inet.c#L64">L64</a>:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">nft_reject_inet_init</span><span class="params">(<span class="keyword">const</span> struct nft_ctx *ctx,</span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">const</span> struct nft_expr *expr,</span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">const</span> struct nlattr * <span class="keyword">const</span> tb[])</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">nft_reject</span> *<span class="title">priv</span> =</span> nft_expr_priv(expr);</span><br><span class="line"><span class="keyword">int</span> icmp_code;</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (tb[NFTA_REJECT_TYPE] == <span class="literal">NULL</span>)</span><br><span class="line"><span class="keyword">return</span> -EINVAL;</span><br><span class="line"></span><br><span class="line">priv-&gt;type = ntohl(nla_get_be32(tb[NFTA_REJECT_TYPE]));</span><br><span class="line"><span class="keyword">switch</span> (priv-&gt;type) &#123;</span><br><span class="line"><span class="keyword">case</span> NFT_REJECT_ICMP_UNREACH:</span><br><span class="line"><span class="keyword">case</span> NFT_REJECT_ICMPX_UNREACH:</span><br><span class="line"><span class="keyword">if</span> (tb[NFTA_REJECT_ICMP_CODE] == <span class="literal">NULL</span>)</span><br><span class="line"><span class="keyword">return</span> -EINVAL;</span><br><span class="line"></span><br><span class="line">icmp_code = nla_get_u8(tb[NFTA_REJECT_ICMP_CODE]);</span><br><span class="line"><span class="keyword">if</span> (priv-&gt;type == NFT_REJECT_ICMPX_UNREACH &amp;&amp;</span><br><span class="line">    icmp_code &gt; NFT_REJECT_ICMPX_MAX)</span><br><span class="line"><span class="keyword">return</span> -EINVAL;</span><br><span class="line"></span><br><span class="line">priv-&gt;icmp_code = icmp_code;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> NFT_REJECT_TCP_RST:</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line"><span class="keyword">return</span> -EINVAL;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>By reading this function and looking into all other functions called by this function, we can see that the following things will happen: The kernel will allocate memory for an instance of <code>struct nft_reject</code>, which is the struct that stores operation specific data, at <code>expr-&gt;data</code>. In order for the kernel to know the size of memory to allocate for <code>struct nft_reject</code>, its size is passed to <code>nft_expr_ops.size</code> as shown in the 4th line at <a href="#nft_expr_ops_and_nft_expr_type_reject">the code snippet above</a>:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">.size = NFT_EXPR_SIZE(<span class="keyword">sizeof</span>(struct nft_reject))</span><br></pre></td></tr></table></figure><p>The <code>init</code> function is responsible to initialize the fields of this instance by reading attributes from <a href="https://en.wikipedia.org/wiki/Netlink">netlink</a> by calling functions like <code>nla_get_&lt;type&gt;</code>. Data from netlink is stored at the argument <code>tb</code>. In case of error, the <code>init</code> function should return a negative number, otherwise <code>0</code> should be returned. <a name="question_netlink"></a>Up to now, we are not sure how to let netlink know what attributes are expected and what are the length of these attributes yet, but don’t worry, things will become clear as we keep reading. Let’s for now just forget about this problem.</p><p>Now let’s take a look at the <code>dump</code> field, it is implemented by <code>nft_reject_inet_dump</code> for reject operation. The code is located at <a href="http://elixir.free-electrons.com/linux/v4.13/source/net/netfilter/nft_reject_inet.c#L96">L96</a>:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">nft_reject_inet_dump</span><span class="params">(struct sk_buff *skb,</span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">const</span> struct nft_expr *expr)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">nft_reject</span> *<span class="title">priv</span> =</span> nft_expr_priv(expr);</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> (nla_put_be32(skb, NFTA_REJECT_TYPE, htonl(priv-&gt;type)))</span><br><span class="line"><span class="keyword">goto</span> nla_put_failure;</span><br><span class="line"></span><br><span class="line"><span class="keyword">switch</span> (priv-&gt;type) &#123;</span><br><span class="line"><span class="keyword">case</span> NFT_REJECT_ICMP_UNREACH:</span><br><span class="line"><span class="keyword">case</span> NFT_REJECT_ICMPX_UNREACH:</span><br><span class="line"><span class="keyword">if</span> (nla_put_u8(skb, NFTA_REJECT_ICMP_CODE, priv-&gt;icmp_code))</span><br><span class="line"><span class="keyword">goto</span> nla_put_failure;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">default</span>:</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line"></span><br><span class="line">nla_put_failure:</span><br><span class="line"><span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>We can see that this operation send back the parameters to netlink using functions like <code>nla_put_&lt;type&gt;</code>. In case of success, <code>0</code> should be returned, otherwise it should return a negative number.</p><p>The function that evaluate the evaluation correspond to the field <code>eval</code>. We can think of there are two types of expressions: those that match some conditions, and those that do something, such as drop, reject, accept, dnat, etc., to the packets. For these two types, the <code>eval</code> should be slightly different. Here we use the source code of both compare and reject as example. In reject, it is implemented as <code>nft_reject_inet_eval</code>. The source code is located at <a href="http://elixir.free-electrons.com/linux/v4.13/source/net/netfilter/nft_reject_inet.c#L20">L20</a>:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">nft_reject_inet_eval</span><span class="params">(<span class="keyword">const</span> struct nft_expr *expr,</span></span></span><br><span class="line"><span class="function"><span class="params"> struct nft_regs *regs,</span></span></span><br><span class="line"><span class="function"><span class="params"> <span class="keyword">const</span> struct nft_pktinfo *pkt)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">nft_reject</span> *<span class="title">priv</span> =</span> nft_expr_priv(expr);</span><br><span class="line"></span><br><span class="line"><span class="keyword">switch</span> (nft_pf(pkt)) &#123;</span><br><span class="line"><span class="keyword">case</span> NFPROTO_IPV4:</span><br><span class="line"><span class="keyword">switch</span> (priv-&gt;type) &#123;</span><br><span class="line"><span class="keyword">case</span> NFT_REJECT_ICMP_UNREACH:</span><br><span class="line">nf_send_unreach(pkt-&gt;skb, priv-&gt;icmp_code,</span><br><span class="line">nft_hook(pkt));</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> NFT_REJECT_TCP_RST:</span><br><span class="line">nf_send_reset(nft_net(pkt), pkt-&gt;skb, nft_hook(pkt));</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> NFT_REJECT_ICMPX_UNREACH:</span><br><span class="line">nf_send_unreach(pkt-&gt;skb,</span><br><span class="line">nft_reject_icmp_code(priv-&gt;icmp_code),</span><br><span class="line">nft_hook(pkt));</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> NFPROTO_IPV6:</span><br><span class="line"><span class="keyword">switch</span> (priv-&gt;type) &#123;</span><br><span class="line"><span class="keyword">case</span> NFT_REJECT_ICMP_UNREACH:</span><br><span class="line">nf_send_unreach6(nft_net(pkt), pkt-&gt;skb,</span><br><span class="line"> priv-&gt;icmp_code, nft_hook(pkt));</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> NFT_REJECT_TCP_RST:</span><br><span class="line">nf_send_reset6(nft_net(pkt), pkt-&gt;skb, nft_hook(pkt));</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> NFT_REJECT_ICMPX_UNREACH:</span><br><span class="line">nf_send_unreach6(nft_net(pkt), pkt-&gt;skb,</span><br><span class="line"> nft_reject_icmpv6_code(priv-&gt;icmp_code),</span><br><span class="line"> nft_hook(pkt));</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">regs-&gt;verdict.code = NF_DROP;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>In the compare operation, it is implemented as <code>nft_cmp_eval</code>. The source code is located at <a href="http://elixir.free-electrons.com/linux/v4.13/source/net/netfilter/nft_cmp.c#L27">L27</a>:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">nft_cmp_eval</span><span class="params">(<span class="keyword">const</span> struct nft_expr *expr,</span></span></span><br><span class="line"><span class="function"><span class="params"> struct nft_regs *regs,</span></span></span><br><span class="line"><span class="function"><span class="params"> <span class="keyword">const</span> struct nft_pktinfo *pkt)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">nft_cmp_expr</span> *<span class="title">priv</span> =</span> nft_expr_priv(expr);</span><br><span class="line"><span class="keyword">int</span> d;</span><br><span class="line"></span><br><span class="line">d = <span class="built_in">memcmp</span>(&amp;regs-&gt;data[priv-&gt;sreg], &amp;priv-&gt;data, priv-&gt;len);</span><br><span class="line"><span class="keyword">switch</span> (priv-&gt;op) &#123;</span><br><span class="line"><span class="keyword">case</span> NFT_CMP_EQ:</span><br><span class="line"><span class="keyword">if</span> (d != <span class="number">0</span>)</span><br><span class="line"><span class="keyword">goto</span> mismatch;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> NFT_CMP_NEQ:</span><br><span class="line"><span class="keyword">if</span> (d == <span class="number">0</span>)</span><br><span class="line"><span class="keyword">goto</span> mismatch;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> NFT_CMP_LT:</span><br><span class="line"><span class="keyword">if</span> (d == <span class="number">0</span>)</span><br><span class="line"><span class="keyword">goto</span> mismatch;</span><br><span class="line"><span class="keyword">case</span> NFT_CMP_LTE:</span><br><span class="line"><span class="keyword">if</span> (d &gt; <span class="number">0</span>)</span><br><span class="line"><span class="keyword">goto</span> mismatch;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line"><span class="keyword">case</span> NFT_CMP_GT:</span><br><span class="line"><span class="keyword">if</span> (d == <span class="number">0</span>)</span><br><span class="line"><span class="keyword">goto</span> mismatch;</span><br><span class="line"><span class="keyword">case</span> NFT_CMP_GTE:</span><br><span class="line"><span class="keyword">if</span> (d &lt; <span class="number">0</span>)</span><br><span class="line"><span class="keyword">goto</span> mismatch;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span>;</span><br><span class="line"></span><br><span class="line">mismatch:</span><br><span class="line">regs-&gt;verdict.code = NFT_BREAK;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>From these two functions, we can see that this function tells the kernel to do something by setting <code>regs-&gt;verdict.code</code> or to continue to the next expression by not changing <code>regs-&gt;verdict.code</code>. For actions, the value of <code>regs-&gt;verdict.code</code> should be set to one of the following as shown in <a href="http://elixir.free-electrons.com/linux/v4.13/source/include/uapi/linux/netfilter.h#L9">include/uapi/linux/netfilter.h#L9</a>:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* Responses from hook functions. */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NF_DROP 0</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NF_ACCEPT 1</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NF_STOLEN 2</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NF_QUEUE 3</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NF_REPEAT 4</span></span><br></pre></td></tr></table></figure><p>For matches, it should be a value in <code>enum nft_verdicts</code>, which is listed at <a href="http://elixir.free-electrons.com/linux/v4.13/source/include/uapi/linux/netfilter/nf_tables.h#L49">include/uapi/linux/netfilter/nf_tables.h#L49</a>:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * enum nft_verdicts - nf_tables internal verdicts</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @NFT_CONTINUE: continue evaluation of the current rule</span></span><br><span class="line"><span class="comment"> * @NFT_BREAK: terminate evaluation of the current rule</span></span><br><span class="line"><span class="comment"> * @NFT_JUMP: push the current chain on the jump stack and jump to a chain</span></span><br><span class="line"><span class="comment"> * @NFT_GOTO: jump to a chain without pushing the current chain on the jump stack</span></span><br><span class="line"><span class="comment"> * @NFT_RETURN: return to the topmost chain on the jump stack</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * The nf_tables verdicts share their numeric space with the netfilter verdicts.</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">enum</span> <span class="title">nft_verdicts</span> &#123;</span></span><br><span class="line">NFT_CONTINUE= <span class="number">-1</span>,</span><br><span class="line">NFT_BREAK= <span class="number">-2</span>,</span><br><span class="line">NFT_JUMP= <span class="number">-3</span>,</span><br><span class="line">NFT_GOTO= <span class="number">-4</span>,</span><br><span class="line">NFT_RETURN= <span class="number">-5</span>,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>The field <code>validate</code> is used to check the validation of operation, for example: masquerade is only available at hook point <code>POSTROUTING</code>, reject is only available at hook point <code>LOCAL INPUT</code>, <code>LOCAL_OUTPUT</code> and <code>FORWARD</code>, etc. This can be shown at the source code of at <a href="http://elixir.free-electrons.com/linux/v4.13/source/net/netfilter/nft_reject.c#L29">net/netfilter/nft_reject.c#L29</a>:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">nft_reject_validate</span><span class="params">(<span class="keyword">const</span> struct nft_ctx *ctx,</span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">const</span> struct nft_expr *expr,</span></span></span><br><span class="line"><span class="function"><span class="params"><span class="keyword">const</span> struct nft_data **data)</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line"><span class="keyword">return</span> nft_chain_validate_hooks(ctx-&gt;chain,</span><br><span class="line">(<span class="number">1</span> &lt;&lt; NF_INET_LOCAL_IN) |</span><br><span class="line">(<span class="number">1</span> &lt;&lt; NF_INET_FORWARD) |</span><br><span class="line">(<span class="number">1</span> &lt;&lt; NF_INET_LOCAL_OUT));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>The function <code>nft_chain_validate_hooks</code> is used to validate the hook point. There are other helper functions to validate different things, the list of these functions can be obtained by searching the string “validate” at <a href="http://elixir.free-electrons.com/linux/v4.13/source/include/net/netfilter/nf_tables.h">include/net/netfilter/nf_tables.h</a>.</p><h2 id="struct-nft-expr-type"><a href="#struct-nft-expr-type" class="headerlink" title="struct nft_expr_type"></a>struct nft_expr_type</h2><p>The definition of <code>nft_expr_type</code> is at <a href="http://elixir.free-electrons.com/linux/v4.13/source/include/net/netfilter/nf_tables.h#L681">include/net/netfilter/nf_tables.h#L681</a>:<a name="nft_expr_type"></a><br><a name="nft_expr_type"></a>```C<br>/**</p><ul><li>   struct nft_expr_type - nf_tables expression type</li><li></li><li>   @select_ops: function to select nft_expr_ops</li><li>   @ops: default ops, used when no select_ops functions is present</li><li>   @list: used internally</li><li>   @name: Identifier</li><li>   @owner: module reference</li><li>   @policy: netlink attribute policy</li><li>   @maxattr: highest netlink attribute number</li><li>   @family: address family for AF-specific types</li><li>   @flags: expression type flags</li><li>/<br>struct nft_expr_type {<br>  const struct nft_expr_ops    *(*select_ops)(const struct nft_ctx *,<pre><code>                         const struct nlattr * const tb[]);</code></pre>  const struct nft_expr_ops    *ops;<br>  struct list_head        list;<br>  const char            *name;<br>  struct module            *owner;<br>  const struct nla_policy        *policy;<br>  unsigned int            maxattr;<br>  u8                family;<br>  u8                flags;<br>};<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">The field &#96;ops&#96; and &#96;select_ops&#96; is already discussed; the field &#96;list&#96; is internally, so we should not worry about it here; the field &#96;name&#96; is the name of the expression; the field &#96;owner&#96; should be set to the pointer towards the current module. These are all trivial fields. Now let&#39;s take a look at the &#96;policy&#96; and &#96;maxattr&#96; field. The related code at [the definition of &#96;nft_reject_inet_type&#96;](#nft_expr_ops_and_nft_expr_type_reject) is:</span><br><span class="line">&#96;&#96;&#96;C</span><br><span class="line">.policy &#x3D; nft_reject_policy,</span><br><span class="line">.maxattr &#x3D; NFTA_REJECT_MAX,</span><br></pre></td></tr></table></figure>The array <code>nft_reject_policy</code> is defined at <a href="http://elixir.free-electrons.com/linux/v4.13/source/net/netfilter/nft_reject.c#L23">L23</a>:<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">nla_policy</span> <span class="title">nft_reject_policy</span>[<span class="title">NFTA_REJECT_MAX</span> + 1] =</span> &#123;</span><br><span class="line">[NFTA_REJECT_TYPE]= &#123; .type = NLA_U32 &#125;,</span><br><span class="line">[NFTA_REJECT_ICMP_CODE]= &#123; .type = NLA_U8 &#125;,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>The two array index above, <code>NFTA_REJECT_TYPE</code> and <code>NFTA_REJECT_ICMP_CODE</code>, belongs to an enum named <code>nft_reject_attributes</code>. And the definition of <code>NFTA_REJECT_MAX</code> and <code>nft_reject_attributes</code> is located at <a href="http://elixir.free-electrons.com/linux/v4.13/source/include/uapi/linux/netfilter/nf_tables.h#L1089">include/uapi/linux/netfilter/nf_tables.h#L1089</a>:<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * enum nft_reject_attributes - nf_tables reject expression netlink attributes</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * @NFTA_REJECT_TYPE: packet type to use (NLA_U32: nft_reject_types)</span></span><br><span class="line"><span class="comment"> * @NFTA_REJECT_ICMP_CODE: ICMP code to use (NLA_U8)</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">enum</span> <span class="title">nft_reject_attributes</span> &#123;</span></span><br><span class="line">NFTA_REJECT_UNSPEC,</span><br><span class="line">NFTA_REJECT_TYPE,</span><br><span class="line">NFTA_REJECT_ICMP_CODE,</span><br><span class="line">__NFTA_REJECT_MAX</span><br><span class="line">&#125;;</span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NFTA_REJECT_MAX(__NFTA_REJECT_MAX - 1)</span></span><br></pre></td></tr></table></figure>Recall that we raised a question <a href="#question_netlink">before</a> on how does the kernel knows what are the attributes expected by the expression. The <code>policy</code> field is exactly the answer to this question. Let’s now dig deeper and read the source code of netlink starting at <a href="http://elixir.free-electrons.com/linux/v4.13/source/include/net/netlink.h#L9">include/net/netlink.h#L9</a>:<figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* ========================================================================</span></span><br><span class="line"><span class="comment"> *         Netlink Messages and Attributes Interface (As Seen On TV)</span></span><br><span class="line"><span class="comment"> * ------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"> *                          Messages Interface</span></span><br><span class="line"><span class="comment"> * ------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Message Format:</span></span><br><span class="line"><span class="comment"> *    &lt;--- nlmsg_total_size(payload)  ---&gt;</span></span><br><span class="line"><span class="comment"> *    &lt;-- nlmsg_msg_size(payload) -&gt;</span></span><br><span class="line"><span class="comment"> *   +----------+- - -+-------------+- - -+-------- - -</span></span><br><span class="line"><span class="comment"> *   | nlmsghdr | Pad |   Payload   | Pad | nlmsghdr</span></span><br><span class="line"><span class="comment"> *   +----------+- - -+-------------+- - -+-------- - -</span></span><br><span class="line"><span class="comment"> *   nlmsg_data(nlh)---^                   ^</span></span><br><span class="line"><span class="comment"> *   nlmsg_next(nlh)-----------------------+</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Payload Format:</span></span><br><span class="line"><span class="comment"> *    &lt;---------------------- nlmsg_len(nlh) ---------------------&gt;</span></span><br><span class="line"><span class="comment"> *    &lt;------ hdrlen ------&gt;       &lt;- nlmsg_attrlen(nlh, hdrlen) -&gt;</span></span><br><span class="line"><span class="comment"> *   +----------------------+- - -+--------------------------------+</span></span><br><span class="line"><span class="comment"> *   |     Family Header    | Pad |           Attributes           |</span></span><br><span class="line"><span class="comment"> *   +----------------------+- - -+--------------------------------+</span></span><br><span class="line"><span class="comment"> *   nlmsg_attrdata(nlh, hdrlen)---^</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Data Structures:</span></span><br><span class="line"><span class="comment"> *   struct nlmsghdrnetlink message header</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Message Construction:</span></span><br><span class="line"><span class="comment"> *   nlmsg_new()create a new netlink message</span></span><br><span class="line"><span class="comment"> *   nlmsg_put()add a netlink message to an skb</span></span><br><span class="line"><span class="comment"> *   nlmsg_put_answer()callback based nlmsg_put()</span></span><br><span class="line"><span class="comment"> *   nlmsg_end()finalize netlink message</span></span><br><span class="line"><span class="comment"> *   nlmsg_get_pos()return current position in message</span></span><br><span class="line"><span class="comment"> *   nlmsg_trim()trim part of message</span></span><br><span class="line"><span class="comment"> *   nlmsg_cancel()cancel message construction</span></span><br><span class="line"><span class="comment"> *   nlmsg_free()free a netlink message</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Message Sending:</span></span><br><span class="line"><span class="comment"> *   nlmsg_multicast()multicast message to several groups</span></span><br><span class="line"><span class="comment"> *   nlmsg_unicast()unicast a message to a single socket</span></span><br><span class="line"><span class="comment"> *   nlmsg_notify()send notification message</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Message Length Calculations:</span></span><br><span class="line"><span class="comment"> *   nlmsg_msg_size(payload)length of message w/o padding</span></span><br><span class="line"><span class="comment"> *   nlmsg_total_size(payload)length of message w/ padding</span></span><br><span class="line"><span class="comment"> *   nlmsg_padlen(payload)length of padding at tail</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Message Payload Access:</span></span><br><span class="line"><span class="comment"> *   nlmsg_data(nlh)head of message payload</span></span><br><span class="line"><span class="comment"> *   nlmsg_len(nlh)length of message payload</span></span><br><span class="line"><span class="comment"> *   nlmsg_attrdata(nlh, hdrlen)head of attributes data</span></span><br><span class="line"><span class="comment"> *   nlmsg_attrlen(nlh, hdrlen)length of attributes data</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Message Parsing:</span></span><br><span class="line"><span class="comment"> *   nlmsg_ok(nlh, remaining)does nlh fit into remaining bytes?</span></span><br><span class="line"><span class="comment"> *   nlmsg_next(nlh, remaining)get next netlink message</span></span><br><span class="line"><span class="comment"> *   nlmsg_parse()parse attributes of a message</span></span><br><span class="line"><span class="comment"> *   nlmsg_find_attr()find an attribute in a message</span></span><br><span class="line"><span class="comment"> *   nlmsg_for_each_msg()loop over all messages</span></span><br><span class="line"><span class="comment"> *   nlmsg_validate()validate netlink message incl. attrs</span></span><br><span class="line"><span class="comment"> *   nlmsg_for_each_attr()loop over all attributes</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Misc:</span></span><br><span class="line"><span class="comment"> *   nlmsg_report()report back to application?</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * ------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"> *                          Attributes Interface</span></span><br><span class="line"><span class="comment"> * ------------------------------------------------------------------------</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Attribute Format:</span></span><br><span class="line"><span class="comment"> *    &lt;------- nla_total_size(payload) -------&gt;</span></span><br><span class="line"><span class="comment"> *    &lt;---- nla_attr_size(payload) -----&gt;</span></span><br><span class="line"><span class="comment"> *   +----------+- - -+- - - - - - - - - +- - -+-------- - -</span></span><br><span class="line"><span class="comment"> *   |  Header  | Pad |     Payload      | Pad |  Header</span></span><br><span class="line"><span class="comment"> *   +----------+- - -+- - - - - - - - - +- - -+-------- - -</span></span><br><span class="line"><span class="comment"> *                     &lt;- nla_len(nla) -&gt;      ^</span></span><br><span class="line"><span class="comment"> *   nla_data(nla)----^                        |</span></span><br><span class="line"><span class="comment"> *   nla_next(nla)-----------------------------&#x27;</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Data Structures:</span></span><br><span class="line"><span class="comment"> *   struct nlattrnetlink attribute header</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Attribute Construction:</span></span><br><span class="line"><span class="comment"> *   nla_reserve(skb, type, len)reserve room for an attribute</span></span><br><span class="line"><span class="comment"> *   nla_reserve_nohdr(skb, len)reserve room for an attribute w/o hdr</span></span><br><span class="line"><span class="comment"> *   nla_put(skb, type, len, data)add attribute to skb</span></span><br><span class="line"><span class="comment"> *   nla_put_nohdr(skb, len, data)add attribute w/o hdr</span></span><br><span class="line"><span class="comment"> *   nla_append(skb, len, data)append data to skb</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Attribute Construction for Basic Types:</span></span><br><span class="line"><span class="comment"> *   nla_put_u8(skb, type, value)add u8 attribute to skb</span></span><br><span class="line"><span class="comment"> *   nla_put_u16(skb, type, value)add u16 attribute to skb</span></span><br><span class="line"><span class="comment"> *   nla_put_u32(skb, type, value)add u32 attribute to skb</span></span><br><span class="line"><span class="comment"> *   nla_put_u64_64bit(skb, type,</span></span><br><span class="line"><span class="comment"> *                     value, padattr)add u64 attribute to skb</span></span><br><span class="line"><span class="comment"> *   nla_put_s8(skb, type, value)add s8 attribute to skb</span></span><br><span class="line"><span class="comment"> *   nla_put_s16(skb, type, value)add s16 attribute to skb</span></span><br><span class="line"><span class="comment"> *   nla_put_s32(skb, type, value)add s32 attribute to skb</span></span><br><span class="line"><span class="comment"> *   nla_put_s64(skb, type, value,</span></span><br><span class="line"><span class="comment"> *               padattr)add s64 attribute to skb</span></span><br><span class="line"><span class="comment"> *   nla_put_string(skb, type, str)add string attribute to skb</span></span><br><span class="line"><span class="comment"> *   nla_put_flag(skb, type)add flag attribute to skb</span></span><br><span class="line"><span class="comment"> *   nla_put_msecs(skb, type, jiffies,</span></span><br><span class="line"><span class="comment"> *                 padattr)add msecs attribute to skb</span></span><br><span class="line"><span class="comment"> *   nla_put_in_addr(skb, type, addr)add IPv4 address attribute to skb</span></span><br><span class="line"><span class="comment"> *   nla_put_in6_addr(skb, type, addr)add IPv6 address attribute to skb</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Nested Attributes Construction:</span></span><br><span class="line"><span class="comment"> *   nla_nest_start(skb, type)start a nested attribute</span></span><br><span class="line"><span class="comment"> *   nla_nest_end(skb, nla)finalize a nested attribute</span></span><br><span class="line"><span class="comment"> *   nla_nest_cancel(skb, nla)cancel nested attribute construction</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Attribute Length Calculations:</span></span><br><span class="line"><span class="comment"> *   nla_attr_size(payload)length of attribute w/o padding</span></span><br><span class="line"><span class="comment"> *   nla_total_size(payload)length of attribute w/ padding</span></span><br><span class="line"><span class="comment"> *   nla_padlen(payload)length of padding</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Attribute Payload Access:</span></span><br><span class="line"><span class="comment"> *   nla_data(nla)head of attribute payload</span></span><br><span class="line"><span class="comment"> *   nla_len(nla)length of attribute payload</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Attribute Payload Access for Basic Types:</span></span><br><span class="line"><span class="comment"> *   nla_get_u8(nla)get payload for a u8 attribute</span></span><br><span class="line"><span class="comment"> *   nla_get_u16(nla)get payload for a u16 attribute</span></span><br><span class="line"><span class="comment"> *   nla_get_u32(nla)get payload for a u32 attribute</span></span><br><span class="line"><span class="comment"> *   nla_get_u64(nla)get payload for a u64 attribute</span></span><br><span class="line"><span class="comment"> *   nla_get_s8(nla)get payload for a s8 attribute</span></span><br><span class="line"><span class="comment"> *   nla_get_s16(nla)get payload for a s16 attribute</span></span><br><span class="line"><span class="comment"> *   nla_get_s32(nla)get payload for a s32 attribute</span></span><br><span class="line"><span class="comment"> *   nla_get_s64(nla)get payload for a s64 attribute</span></span><br><span class="line"><span class="comment"> *   nla_get_flag(nla)return 1 if flag is true</span></span><br><span class="line"><span class="comment"> *   nla_get_msecs(nla)get payload for a msecs attribute</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Attribute Misc:</span></span><br><span class="line"><span class="comment"> *   nla_memcpy(dest, nla, count)copy attribute into memory</span></span><br><span class="line"><span class="comment"> *   nla_memcmp(nla, data, size)compare attribute with memory area</span></span><br><span class="line"><span class="comment"> *   nla_strlcpy(dst, nla, size)copy attribute to a sized string</span></span><br><span class="line"><span class="comment"> *   nla_strcmp(nla, str)compare attribute with string</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Attribute Parsing:</span></span><br><span class="line"><span class="comment"> *   nla_ok(nla, remaining)does nla fit into remaining bytes?</span></span><br><span class="line"><span class="comment"> *   nla_next(nla, remaining)get next netlink attribute</span></span><br><span class="line"><span class="comment"> *   nla_validate()validate a stream of attributes</span></span><br><span class="line"><span class="comment"> *   nla_validate_nested()validate a stream of nested attributes</span></span><br><span class="line"><span class="comment"> *   nla_find()find attribute in stream of attributes</span></span><br><span class="line"><span class="comment"> *   nla_find_nested()find attribute in nested attributes</span></span><br><span class="line"><span class="comment"> *   nla_parse()parse and validate stream of attrs</span></span><br><span class="line"><span class="comment"> *   nla_parse_nested()parse nested attribuets</span></span><br><span class="line"><span class="comment"> *   nla_for_each_attr()loop over all attributes</span></span><br><span class="line"><span class="comment"> *   nla_for_each_nested()loop over the nested attributes</span></span><br><span class="line"><span class="comment"> *=========================================================================</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"></span><br><span class="line"> <span class="comment">/**</span></span><br><span class="line"><span class="comment">  * Standard attribute types to specify validation policy</span></span><br><span class="line"><span class="comment">  */</span></span><br><span class="line"><span class="class"><span class="keyword">enum</span> &#123;</span></span><br><span class="line">NLA_UNSPEC,</span><br><span class="line">NLA_U8,</span><br><span class="line">NLA_U16,</span><br><span class="line">NLA_U32,</span><br><span class="line">NLA_U64,</span><br><span class="line">NLA_STRING,</span><br><span class="line">NLA_FLAG,</span><br><span class="line">NLA_MSECS,</span><br><span class="line">NLA_NESTED,</span><br><span class="line">NLA_NESTED_COMPAT,</span><br><span class="line">NLA_NUL_STRING,</span><br><span class="line">NLA_BINARY,</span><br><span class="line">NLA_S8,</span><br><span class="line">NLA_S16,</span><br><span class="line">NLA_S32,</span><br><span class="line">NLA_S64,</span><br><span class="line">__NLA_TYPE_MAX,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NLA_TYPE_MAX (__NLA_TYPE_MAX - 1)</span></span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * struct nla_policy - attribute validation policy</span></span><br><span class="line"><span class="comment"> * @type: Type of attribute or NLA_UNSPEC</span></span><br><span class="line"><span class="comment"> * @len: Type specific length of payload</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Policies are defined as arrays of this struct, the array must be</span></span><br><span class="line"><span class="comment"> * accessible by attribute type up to the highest identifier to be expected.</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Meaning of `len&#x27; field:</span></span><br><span class="line"><span class="comment"> *    NLA_STRING           Maximum length of string</span></span><br><span class="line"><span class="comment"> *    NLA_NUL_STRING       Maximum length of string (excluding NUL)</span></span><br><span class="line"><span class="comment"> *    NLA_FLAG             Unused</span></span><br><span class="line"><span class="comment"> *    NLA_BINARY           Maximum length of attribute payload</span></span><br><span class="line"><span class="comment"> *    NLA_NESTED           Don&#x27;t use `len&#x27; field -- length verification is</span></span><br><span class="line"><span class="comment"> *                         done by checking len of nested header (or empty)</span></span><br><span class="line"><span class="comment"> *    NLA_NESTED_COMPAT    Minimum length of structure payload</span></span><br><span class="line"><span class="comment"> *    NLA_U8, NLA_U16,</span></span><br><span class="line"><span class="comment"> *    NLA_U32, NLA_U64,</span></span><br><span class="line"><span class="comment"> *    NLA_S8, NLA_S16,</span></span><br><span class="line"><span class="comment"> *    NLA_S32, NLA_S64,</span></span><br><span class="line"><span class="comment"> *    NLA_MSECS            Leaving the length field zero will verify the</span></span><br><span class="line"><span class="comment"> *                         given type fits, using it verifies minimum length</span></span><br><span class="line"><span class="comment"> *                         just like &quot;All other&quot;</span></span><br><span class="line"><span class="comment"> *    All other            Minimum length of attribute payload</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * Example:</span></span><br><span class="line"><span class="comment"> * static const struct nla_policy my_policy[ATTR_MAX+1] = &#123;</span></span><br><span class="line"><span class="comment"> * [ATTR_FOO] = &#123; .type = NLA_U16 &#125;,</span></span><br><span class="line"><span class="comment"> *[ATTR_BAR] = &#123; .type = NLA_STRING, .len = BARSIZ &#125;,</span></span><br><span class="line"><span class="comment"> *[ATTR_BAZ] = &#123; .len = sizeof(struct mystruct) &#125;,</span></span><br><span class="line"><span class="comment"> * &#125;;</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">nla_policy</span> &#123;</span></span><br><span class="line">u16type;</span><br><span class="line">u16len;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>The comments explains itself very well. The source code of attributes of different expressions are all defined at <a href="http://elixir.free-electrons.com/linux/v4.13/source/include/uapi/linux/netfilter/nf_tables.h">include/uapi/linux/netfilter/nf_tables.h</a>. To get a feeling on how to write an array like this, just search the string “attributes” in this file. All definition of attributes should begin with an <code>UNSPEC</code> to leave space for internal usage.</li></ul><p>The field <code>family</code> is the address family of your expression. Possible values can be found at <a href="http://elixir.free-electrons.com/linux/v4.13/source/include/uapi/linux/netfilter.h#L59">include/uapi/linux/netfilter.h#L59</a>:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">enum</span> &#123;</span></span><br><span class="line">NFPROTO_UNSPEC =  <span class="number">0</span>,</span><br><span class="line">NFPROTO_INET   =  <span class="number">1</span>,</span><br><span class="line">NFPROTO_IPV4   =  <span class="number">2</span>,</span><br><span class="line">NFPROTO_ARP    =  <span class="number">3</span>,</span><br><span class="line">NFPROTO_NETDEV =  <span class="number">5</span>,</span><br><span class="line">NFPROTO_BRIDGE =  <span class="number">7</span>,</span><br><span class="line">NFPROTO_IPV6   = <span class="number">10</span>,</span><br><span class="line">NFPROTO_DECNET = <span class="number">12</span>,</span><br><span class="line">NFPROTO_NUMPROTO,</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>The field <code>flags</code> are used to denote expression types. Currently, only one flag is available, that is if an expression is stateful. See <a href="http://elixir.free-electrons.com/linux/v4.13/source/include/net/netfilter/nf_tables.h#L707">include/net/netfilter/nf_tables.h#L707</a>:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NFT_EXPR_STATEFUL0x1</span></span><br></pre></td></tr></table></figure><h1 id="Summary-on-kernel-codes"><a href="#Summary-on-kernel-codes" class="headerlink" title="Summary on kernel codes"></a><a name="summary"></a>Summary on kernel codes</h1><p>Create an instance of <code>struct nft_expr_ops</code> for each operation of this expression. Implements its fields as in <a href="#nft_expr_ops">its definition</a>. Use <code>init</code>, <code>clone</code>, <code>destroy</code> to initialize, clone and destroy object. In <code>init</code>, read attributes from netlink and setup operation’s struct. Implement the core function of this operation in <code>eval</code>, tell kernel what to do by setting <code>regs-&gt;verdict.code</code>. In <code>dump</code>, send the attributes through netlink. Apply constraints to operations in <code>validate</code>.</p><p>Create an instance of <code>struct nft_expr_type</code> for your expression. Implements its fields as in <a href="#nft_expr_type">its definition</a>. If you have multiple operations that should be selected dynamically, implement <code>select_ops</code> otherwise set <code>ops</code>. Set <code>name</code>, <code>owner</code> according to your expression. If applicable, set address family at <code>family</code>. If applicable, use <code>flags</code> to indicate if your expression is stateful. Create an array of <code>struct nla_policy</code>, setup attribute information in that array, and set this array as <code>policy</code>. Set <code>maxattr</code> as the maximum number of attributes.</p><p>Call <code>nft_register_expr</code> to register your expression. Call <code>nft_unregister_expr</code> to unregister your expression.</p><h1 id="Writing-our-own-kernel-code"><a href="#Writing-our-own-kernel-code" class="headerlink" title="Writing our own kernel code"></a>Writing our own kernel code</h1><p>With the knowledge on how to write kernel codes, we are ready to write our own module to add our expression. Here we call our expression “abcde”</p><p>abcde.h:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">ifndef</span> _ABCDE_H</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> _ABCDE_H</span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">enum</span> <span class="title">nft_abcde_attributes</span> &#123;</span></span><br><span class="line">NFTA_ABCDE_UNSPEC,</span><br><span class="line">NFTA_ABCDE_TEXT,</span><br><span class="line">__NFTA_ABCDE_MAX,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NFTA_ABCDE_MAX (__NFTA_ABCDE_MAX - 1)</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">endif</span> <span class="comment">/* _ABCDE_H */</span></span></span><br></pre></td></tr></table></figure><p>abcde.c:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;net/netfilter/nf_tables.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;linux/tcp.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&quot;abcde.h&quot;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> ABCDE_TEXT_SIZE 128</span></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">nft_abcde</span> &#123;</span></span><br><span class="line"><span class="keyword">char</span> text[ABCDE_TEXT_SIZE];</span><br><span class="line"><span class="keyword">int</span> len;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">inline</span> <span class="keyword">bool</span> <span class="title">match_packet</span><span class="params">(struct nft_abcde *priv, struct sk_buff *skb)</span> </span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">tcphdr</span> *<span class="title">tcph</span> =</span> tcp_hdr(skb);</span><br><span class="line"><span class="keyword">char</span> *user_data = (<span class="keyword">char</span> *)((<span class="keyword">char</span> *)tcph + (tcph-&gt;doff * <span class="number">4</span>));</span><br><span class="line"><span class="keyword">char</span> *tail = skb_tail_pointer(skb);</span><br><span class="line"><span class="keyword">char</span> *p;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> (p = user_data; p &lt; tail - priv-&gt;len; p++) &#123;</span><br><span class="line"><span class="keyword">int</span> i; <span class="keyword">bool</span> found = <span class="literal">true</span>;</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; priv-&gt;len; i++)</span><br><span class="line"><span class="keyword">if</span> (p[i] != priv-&gt;text[i]) &#123;</span><br><span class="line">found = <span class="literal">false</span>;</span><br><span class="line"><span class="keyword">break</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">if</span> (found)</span><br><span class="line"><span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">nla_policy</span> <span class="title">nft_abcde_policy</span>[<span class="title">NFTA_ABCDE_MAX</span> + 1] =</span> &#123;</span><br><span class="line">[NFTA_ABCDE_TEXT]= &#123; .type = NLA_STRING, .len = ABCDE_TEXT_SIZE &#125;,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> <span class="title">nft_abcde_eval</span><span class="params">(<span class="keyword">const</span> struct nft_expr *expr, struct nft_regs *regs, <span class="keyword">const</span> struct nft_pktinfo *pkt)</span> </span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">nft_abcde</span> *<span class="title">priv</span> =</span> nft_expr_priv(expr);</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">sk_buff</span> *<span class="title">skb</span> =</span> pkt-&gt;skb;</span><br><span class="line"><span class="keyword">if</span>(match_packet(priv, skb))</span><br><span class="line">regs-&gt;verdict.code = NFT_CONTINUE;</span><br><span class="line"><span class="keyword">else</span></span><br><span class="line">regs-&gt;verdict.code = NFT_BREAK;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">nft_abcde_init</span><span class="params">(<span class="keyword">const</span> struct nft_ctx *ctx, <span class="keyword">const</span> struct nft_expr *expr, <span class="keyword">const</span> struct nlattr * <span class="keyword">const</span> tb[])</span> </span>&#123;</span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">nft_abcde</span> *<span class="title">priv</span> =</span> nft_expr_priv(expr);</span><br><span class="line"><span class="keyword">if</span> (tb[NFTA_ABCDE_TEXT] == <span class="literal">NULL</span>)</span><br><span class="line"><span class="keyword">return</span> -EINVAL;</span><br><span class="line">nla_strlcpy(priv-&gt;text, tb[NFTA_ABCDE_TEXT], ABCDE_TEXT_SIZE);</span><br><span class="line">priv-&gt;len = <span class="built_in">strlen</span>(priv-&gt;text);</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> <span class="title">nft_abcde_dump</span><span class="params">(struct sk_buff *skb, <span class="keyword">const</span> struct nft_expr *expr)</span> </span>&#123;</span><br><span class="line"><span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">nft_abcde</span> *<span class="title">priv</span> =</span> nft_expr_priv(expr);</span><br><span class="line"><span class="keyword">if</span> (nla_put_string(skb, NFTA_ABCDE_TEXT, priv-&gt;text))</span><br><span class="line"><span class="keyword">return</span> <span class="number">-1</span>;</span><br><span class="line"><span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">nft_expr_type</span> <span class="title">nft_abcde_type</span>;</span></span><br><span class="line"><span class="keyword">static</span> <span class="keyword">const</span> <span class="class"><span class="keyword">struct</span> <span class="title">nft_expr_ops</span> <span class="title">nft_abcde_op</span> =</span> &#123;</span><br><span class="line">.eval = nft_abcde_eval,</span><br><span class="line">.size = <span class="keyword">sizeof</span>(struct nft_abcde),</span><br><span class="line">.init = nft_abcde_init,</span><br><span class="line">.dump = nft_abcde_dump,</span><br><span class="line">.type = &amp;nft_abcde_type,</span><br><span class="line">&#125;;</span><br><span class="line"><span class="keyword">static</span> <span class="class"><span class="keyword">struct</span> <span class="title">nft_expr_type</span> <span class="title">nft_abcde_type</span> __<span class="title">read_mostly</span> =</span>  &#123;</span><br><span class="line">.ops = &amp;nft_abcde_op,</span><br><span class="line">.name = <span class="string">&quot;abcde&quot;</span>,</span><br><span class="line">.owner = THIS_MODULE,</span><br><span class="line">.policy = nft_abcde_policy,</span><br><span class="line">.maxattr = NFTA_ABCDE_MAX,</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">int</span> __init <span class="title">nft_abcde_module_init</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line"><span class="keyword">return</span> nft_register_expr(&amp;nft_abcde_type);</span><br><span class="line">&#125;</span><br><span class="line"><span class="function"><span class="keyword">static</span> <span class="keyword">void</span> __exit <span class="title">nft_abcde_module_exit</span><span class="params">(<span class="keyword">void</span>)</span> </span>&#123;</span><br><span class="line">nft_unregister_expr(&amp;nft_abcde_type);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">module_init(nft_abcde_module_init);</span><br><span class="line">module_exit(nft_abcde_module_exit);</span><br><span class="line"></span><br><span class="line">MODULE_AUTHOR(<span class="string">&quot;Xiang Gao&quot;</span>);</span><br><span class="line">MODULE_LICENSE(<span class="string">&quot;GPL&quot;</span>);</span><br><span class="line">MODULE_DESCRIPTION(<span class="string">&quot;A sample nftables expression.&quot;</span>);</span><br></pre></td></tr></table></figure><p>Makefile:</p><figure class="highlight makefile"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">obj-m = abcde.o</span><br><span class="line">KVERSION = <span class="variable">$(<span class="built_in">shell</span> uname -r)</span></span><br><span class="line"><span class="section">all:</span></span><br><span class="line">make -C /lib/modules/<span class="variable">$(KVERSION)</span>/build M=<span class="variable">$(PWD)</span> modules</span><br><span class="line"><span class="section">clean:</span></span><br><span class="line">make -C /lib/modules/<span class="variable">$(KVERSION)</span>/build M=<span class="variable">$(PWD)</span> clean</span><br></pre></td></tr></table></figure><p>The complete source code for this example can be found at GitHub:<br><a href="https://github.com/zasdfgbnm/nftables-abcde">https://github.com/zasdfgbnm/nftables-abcde</a></p><h1 id="Modify-user-space-tool"><a href="#Modify-user-space-tool" class="headerlink" title="Modify user space tool"></a>Modify user space tool</h1><p>In order to be able to conveniently use our new expression “abcde”,  it would be good to modify the source code of user space tool, i.e. the <code>nft</code> command, to make it aware of our new expression. Extending the user space tool is easier. We first check it out from its git repository and switch to tag v0.7 (the newest release when this article is written):</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> git://git.netfilter.org/nftables</span><br><span class="line"><span class="built_in">cd</span> nftables</span><br><span class="line">git checkout v0.7 -b abcde</span><br></pre></td></tr></table></figure><p>To figure out where to modify, let’s run <code>grep</code> to see how the expression <code>reject</code> is implemented:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">grep -i reject -r src include</span><br></pre></td></tr></table></figure><p>The above command will output something like:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">src&#x2F;datatype.c:         SYMBOL(&quot;reject-route&quot;,          ICMPV6_REJECT_ROUTE),</span><br><span class="line">......</span><br><span class="line">src&#x2F;evaluate.c:static int reject_payload_gen_dependency_tcp(struct eval_ctx *ctx,</span><br><span class="line">......</span><br><span class="line">src&#x2F;netlink_delinearize.c:static void netlink_parse_reject(struct netlink_parse_ctx *ctx,</span><br><span class="line">......</span><br><span class="line">src&#x2F;parser_bison.y:%token _REJECT                       &quot;reject&quot;</span><br><span class="line">......</span><br><span class="line">src&#x2F;scanner.l:&quot;reject&quot;          &#123; return _REJECT; &#125;</span><br><span class="line">src&#x2F;statement.c:static void reject_stmt_print(const struct stmt *stmt)</span><br><span class="line">......</span><br><span class="line">include&#x2F;linux&#x2F;netfilter&#x2F;nf_tables.h: * enum nft_reject_types - nf_tables reject expression reject types</span><br><span class="line">......</span><br><span class="line">include&#x2F;statement.h:struct reject_stmt &#123;</span><br><span class="line">......</span><br></pre></td></tr></table></figure><p>This tells us the files we may want to modify. A good start point is <code>scanner.l</code> and <code>parser_bison.y</code>. We can copy and paste the code for reject, replace it with our own thing.</p><p>After some try and error, we end up with the following patch generated by <code>git diff v0.7</code>:</p><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">diff --git a/include/statement.h b/include/statement.h</span></span><br><span class="line"><span class="comment">index 277ff2f..9043790 100644</span></span><br><span class="line"><span class="comment">--- a/include/statement.h</span></span><br><span class="line"><span class="comment">+++ b/include/statement.h</span></span><br><span class="line"><span class="meta">@@ -76,6 +76,12 @@</span> struct reject_stmt &#123;</span><br><span class="line"></span><br><span class="line"> extern struct stmt *reject_stmt_alloc(const struct location *loc);</span><br><span class="line"></span><br><span class="line"><span class="addition">+struct abcde_stmt &#123;</span></span><br><span class="line"><span class="addition">+const char *text;</span></span><br><span class="line"><span class="addition">+&#125;;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+extern struct stmt *abcde_stmt_alloc(const struct location *loc);</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"> struct nat_stmt &#123;</span><br><span class="line"> enum nft_nat_typestype;</span><br><span class="line"> struct expr*addr;</span><br><span class="line"><span class="meta">@@ -199,6 +205,7 @@</span> extern struct stmt *xt_stmt_alloc(const struct location *loc);</span><br><span class="line">  * @STMT_LIMIT:limit statement</span><br><span class="line">  * @STMT_LOG:log statement</span><br><span class="line">  * @STMT_REJECT:REJECT statement</span><br><span class="line"><span class="addition">+ * @STMT_ABCDE:abcde statement</span></span><br><span class="line">  * @STMT_NAT:NAT statement</span><br><span class="line">  * @STMT_MASQ:masquerade statement</span><br><span class="line">  * @STMT_REDIR:redirect statement</span><br><span class="line"><span class="meta">@@ -222,6 +229,7 @@</span> enum stmt_types &#123;</span><br><span class="line"> STMT_LIMIT,</span><br><span class="line"> STMT_LOG,</span><br><span class="line"> STMT_REJECT,</span><br><span class="line"><span class="addition">+STMT_ABCDE,</span></span><br><span class="line"> STMT_NAT,</span><br><span class="line"> STMT_MASQ,</span><br><span class="line"> STMT_REDIR,</span><br><span class="line"><span class="meta">@@ -280,6 +288,7 @@</span> struct stmt &#123;</span><br><span class="line"> struct log_stmtlog;</span><br><span class="line"> struct limit_stmtlimit;</span><br><span class="line"> struct reject_stmtreject;</span><br><span class="line"><span class="addition">+struct abcde_stmtabcde;</span></span><br><span class="line"> struct nat_stmtnat;</span><br><span class="line"> struct masq_stmtmasq;</span><br><span class="line"> struct redir_stmtredir;</span><br><span class="line"><span class="comment">diff --git a/src/evaluate.c b/src/evaluate.c</span></span><br><span class="line"><span class="comment">index 8a3da54..751d702 100644</span></span><br><span class="line"><span class="comment">--- a/src/evaluate.c</span></span><br><span class="line"><span class="comment">+++ b/src/evaluate.c</span></span><br><span class="line"><span class="meta">@@ -2495,6 +2495,8 @@</span> int stmt_evaluate(struct eval_ctx *ctx, struct stmt *stmt)</span><br><span class="line"> return stmt_evaluate_ct(ctx, stmt);</span><br><span class="line"> case STMT_LOG:</span><br><span class="line"> return stmt_evaluate_log(ctx, stmt);</span><br><span class="line"><span class="addition">+case STMT_ABCDE:</span></span><br><span class="line"><span class="addition">+return 0;</span></span><br><span class="line"> case STMT_REJECT:</span><br><span class="line"> return stmt_evaluate_reject(ctx, stmt);</span><br><span class="line"> case STMT_NAT:</span><br><span class="line"><span class="comment">diff --git a/src/netlink_delinearize.c b/src/netlink_delinearize.c</span></span><br><span class="line"><span class="comment">index cb0f6ac..f8b83a6 100644</span></span><br><span class="line"><span class="comment">--- a/src/netlink_delinearize.c</span></span><br><span class="line"><span class="comment">+++ b/src/netlink_delinearize.c</span></span><br><span class="line"><span class="meta">@@ -799,6 +799,16 @@</span> static void netlink_parse_reject(struct netlink_parse_ctx *ctx,</span><br><span class="line"> ctx-&gt;stmt = stmt;</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"><span class="addition">+static void netlink_parse_abcde(struct netlink_parse_ctx *ctx,</span></span><br><span class="line"><span class="addition">+ const struct location *loc,</span></span><br><span class="line"><span class="addition">+ const struct nftnl_expr *expr)</span></span><br><span class="line"><span class="addition">+&#123;</span></span><br><span class="line"><span class="addition">+struct stmt *stmt;</span></span><br><span class="line"><span class="addition">+stmt = abcde_stmt_alloc(loc);</span></span><br><span class="line"><span class="addition">+stmt-&gt;abcde.text = xstrdup(nftnl_expr_get_str(expr, NFTNL_EXPR_ABCDE_TEXT));</span></span><br><span class="line"><span class="addition">+ctx-&gt;stmt = stmt;</span></span><br><span class="line"><span class="addition">+&#125;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"> static void netlink_parse_nat(struct netlink_parse_ctx *ctx,</span><br><span class="line">       const struct location *loc,</span><br><span class="line">       const struct nftnl_expr *nle)</span><br><span class="line"><span class="meta">@@ -1144,6 +1154,7 @@</span> static const struct &#123;</span><br><span class="line"> &#123; .name = &quot;limit&quot;,.parse = netlink_parse_limit &#125;,</span><br><span class="line"> &#123; .name = &quot;range&quot;,.parse = netlink_parse_range &#125;,</span><br><span class="line"> &#123; .name = &quot;reject&quot;,.parse = netlink_parse_reject &#125;,</span><br><span class="line"><span class="addition">+&#123; .name = &quot;abcde&quot;,.parse = netlink_parse_abcde &#125;,</span></span><br><span class="line"> &#123; .name = &quot;nat&quot;,.parse = netlink_parse_nat &#125;,</span><br><span class="line"> &#123; .name = &quot;notrack&quot;,.parse = netlink_parse_notrack &#125;,</span><br><span class="line"> &#123; .name = &quot;masq&quot;,.parse = netlink_parse_masq &#125;,</span><br><span class="line"><span class="comment">diff --git a/src/netlink_linearize.c b/src/netlink_linearize.c</span></span><br><span class="line"><span class="comment">index 0915038..893ae7e 100644</span></span><br><span class="line"><span class="comment">--- a/src/netlink_linearize.c</span></span><br><span class="line"><span class="comment">+++ b/src/netlink_linearize.c</span></span><br><span class="line"><span class="meta">@@ -874,6 +874,18 @@</span> static void netlink_gen_reject_stmt(struct netlink_linearize_ctx *ctx,</span><br><span class="line"> nftnl_rule_add_expr(ctx-&gt;nlr, nle);</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"><span class="addition">+static void netlink_gen_abcde_stmt(struct netlink_linearize_ctx *ctx,</span></span><br><span class="line"><span class="addition">+    const struct stmt *stmt)</span></span><br><span class="line"><span class="addition">+&#123;</span></span><br><span class="line"><span class="addition">+struct nftnl_expr *nle;</span></span><br><span class="line"><span class="addition">+nle = alloc_nft_expr(&quot;abcde&quot;);</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+if (stmt-&gt;abcde.text != NULL) &#123;</span></span><br><span class="line"><span class="addition">+nftnl_expr_set_str(nle, NFTNL_EXPR_ABCDE_TEXT, stmt-&gt;abcde.text);</span></span><br><span class="line"><span class="addition">+&#125;</span></span><br><span class="line"><span class="addition">+nftnl_rule_add_expr(ctx-&gt;nlr, nle);</span></span><br><span class="line"><span class="addition">+&#125;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"> static void netlink_gen_nat_stmt(struct netlink_linearize_ctx *ctx,</span><br><span class="line">  const struct stmt *stmt)</span><br><span class="line"> &#123;</span><br><span class="line"><span class="meta">@@ -1200,6 +1212,8 @@</span> static void netlink_gen_stmt(struct netlink_linearize_ctx *ctx,</span><br><span class="line"> return netlink_gen_log_stmt(ctx, stmt);</span><br><span class="line"> case STMT_REJECT:</span><br><span class="line"> return netlink_gen_reject_stmt(ctx, stmt);</span><br><span class="line"><span class="addition">+case STMT_ABCDE:</span></span><br><span class="line"><span class="addition">+return netlink_gen_abcde_stmt(ctx, stmt);</span></span><br><span class="line"> case STMT_NAT:</span><br><span class="line"> return netlink_gen_nat_stmt(ctx, stmt);</span><br><span class="line"> case STMT_MASQ:</span><br><span class="line"><span class="comment">diff --git a/src/parser_bison.y b/src/parser_bison.y</span></span><br><span class="line"><span class="comment">index deaaf06..ac16c72 100644</span></span><br><span class="line"><span class="comment">--- a/src/parser_bison.y</span></span><br><span class="line"><span class="comment">+++ b/src/parser_bison.y</span></span><br><span class="line"><span class="meta">@@ -399,6 +399,7 @@</span> static void location_update(struct location *loc, struct location *rhs, int n)</span><br><span class="line"> %token RANDOM&quot;random&quot;</span><br><span class="line"> %token FULLY_RANDOM&quot;fully-random&quot;</span><br><span class="line"> %token PERSISTENT&quot;persistent&quot;</span><br><span class="line"><span class="addition">+%token ABCDE&quot;abcde&quot;</span></span><br><span class="line"></span><br><span class="line"> %token QUEUE&quot;queue&quot;</span><br><span class="line"> %token QUEUENUM&quot;num&quot;</span><br><span class="line"><span class="meta">@@ -499,6 +500,8 @@</span> static void location_update(struct location *loc, struct location *rhs, int n)</span><br><span class="line"> %type &lt;val&gt;set_stmt_op</span><br><span class="line"> %type &lt;stmt&gt;flow_stmt flow_stmt_alloc</span><br><span class="line"> %destructor &#123; stmt_free($$); &#125;flow_stmt flow_stmt_alloc</span><br><span class="line"><span class="addition">+%type &lt;stmt&gt;abcde_stmt abcde_stmt_alloc</span></span><br><span class="line"><span class="addition">+%destructor &#123; stmt_free($$); &#125;abcde_stmt abcde_stmt_alloc</span></span><br><span class="line"></span><br><span class="line"> %type &lt;expr&gt;symbol_expr verdict_expr integer_expr variable_expr</span><br><span class="line"> %destructor &#123; expr_free($$); &#125;symbol_expr verdict_expr integer_expr variable_expr</span><br><span class="line"><span class="meta">@@ -1400,6 +1403,7 @@</span> stmt:verdict_stmt</span><br><span class="line"> |limit_stmt</span><br><span class="line"> |quota_stmt</span><br><span class="line"> |reject_stmt</span><br><span class="line"><span class="addition">+|abcde_stmt</span></span><br><span class="line"> |nat_stmt</span><br><span class="line"> |queue_stmt</span><br><span class="line"> |ct_stmt</span><br><span class="line"><span class="meta">@@ -1736,6 +1740,21 @@</span> reject_opts:       /* empty */</span><br><span class="line"> &#125;</span><br><span class="line"> ;</span><br><span class="line"></span><br><span class="line"><span class="addition">+abcde_stmt:abcde_stmt_allocabcde_opts</span></span><br><span class="line"><span class="addition">+;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+abcde_stmt_alloc:ABCDE</span></span><br><span class="line"><span class="addition">+&#123;</span></span><br><span class="line"><span class="addition">+$$ = abcde_stmt_alloc(&amp;@$);</span></span><br><span class="line"><span class="addition">+&#125;</span></span><br><span class="line"><span class="addition">+;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+abcde_opts:string</span></span><br><span class="line"><span class="addition">+&#123;</span></span><br><span class="line"><span class="addition">+$&lt;stmt&gt;0-&gt;abcde.text = $1;</span></span><br><span class="line"><span class="addition">+&#125;</span></span><br><span class="line"><span class="addition">+;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"> nat_stmt:nat_stmt_allocnat_stmt_args</span><br><span class="line"> ;</span><br><span class="line"></span><br><span class="line"><span class="comment">diff --git a/src/scanner.l b/src/scanner.l</span></span><br><span class="line"><span class="comment">index 625023f..595db76 100644</span></span><br><span class="line"><span class="comment">--- a/src/scanner.l</span></span><br><span class="line"><span class="comment">+++ b/src/scanner.l</span></span><br><span class="line"><span class="meta">@@ -333,6 +333,7 @@</span> addrstring(&#123;macaddr&#125;|&#123;ip4addr&#125;|&#123;ip6addr&#125;)</span><br><span class="line"> &quot;random&quot;&#123; return RANDOM; &#125;</span><br><span class="line"> &quot;fully-random&quot;&#123; return FULLY_RANDOM; &#125;</span><br><span class="line"> &quot;persistent&quot;&#123; return PERSISTENT; &#125;</span><br><span class="line"><span class="addition">+&quot;abcde&quot;             &#123; return ABCDE; &#125;</span></span><br><span class="line"></span><br><span class="line"> &quot;ll&quot;&#123; return LL_HDR; &#125;</span><br><span class="line"> &quot;nh&quot;&#123; return NETWORK_HDR; &#125;</span><br><span class="line"><span class="comment">diff --git a/src/statement.c b/src/statement.c</span></span><br><span class="line"><span class="comment">index e70eb51..29b8015 100644</span></span><br><span class="line"><span class="comment">--- a/src/statement.c</span></span><br><span class="line"><span class="comment">+++ b/src/statement.c</span></span><br><span class="line"><span class="meta">@@ -417,6 +417,28 @@</span> struct stmt *reject_stmt_alloc(const struct location *loc)</span><br><span class="line"> return stmt_alloc(loc, &amp;reject_stmt_ops);</span><br><span class="line"> &#125;</span><br><span class="line"></span><br><span class="line"><span class="addition">+static void abcde_stmt_print(const struct stmt *stmt)</span></span><br><span class="line"><span class="addition">+&#123;</span></span><br><span class="line"><span class="addition">+printf(&quot;abcde \&quot;%s\&quot;&quot;, stmt-&gt;abcde.text);</span></span><br><span class="line"><span class="addition">+&#125;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+static void abcde_stmt_destroy(struct stmt *stmt)</span></span><br><span class="line"><span class="addition">+&#123;</span></span><br><span class="line"><span class="addition">+xfree(stmt-&gt;abcde.text);</span></span><br><span class="line"><span class="addition">+&#125;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+static const struct stmt_ops abcde_stmt_ops = &#123;</span></span><br><span class="line"><span class="addition">+.type= STMT_ABCDE,</span></span><br><span class="line"><span class="addition">+.name= &quot;abcde&quot;,</span></span><br><span class="line"><span class="addition">+.print= abcde_stmt_print,</span></span><br><span class="line"><span class="addition">+.destroy= abcde_stmt_destroy,</span></span><br><span class="line"><span class="addition">+&#125;;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+struct stmt *abcde_stmt_alloc(const struct location *loc)</span></span><br><span class="line"><span class="addition">+&#123;</span></span><br><span class="line"><span class="addition">+return stmt_alloc(loc, &amp;abcde_stmt_ops);</span></span><br><span class="line"><span class="addition">+&#125;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"> static void print_nf_nat_flags(uint32_t flags)</span><br><span class="line"> &#123;</span><br><span class="line"> const char *delim = &quot; &quot;;</span><br></pre></td></tr></table></figure><p>Same thing applies to libnftnl, we clone the repository and checkout the tag libnftnl-1.0.7:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> git://git.netfilter.org/libnftnl</span><br><span class="line"><span class="built_in">cd</span> libnftnl</span><br><span class="line">git checkout libnftnl-1.0.7 -b abcde</span><br></pre></td></tr></table></figure><p>After some try and error, we end up with the following patch using command <code>git diff libnftnl-1.0.7</code>:</p><figure class="highlight diff"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">diff --git a/include/libnftnl/expr.h b/include/libnftnl/expr.h</span></span><br><span class="line"><span class="comment">index 74e986d..26259a7 100644</span></span><br><span class="line"><span class="comment">--- a/include/libnftnl/expr.h</span></span><br><span class="line"><span class="comment">+++ b/include/libnftnl/expr.h</span></span><br><span class="line"><span class="meta">@@ -186,6 +186,10 @@</span> enum &#123;</span><br><span class="line"> NFTNL_EXPR_REJECT_CODE,</span><br><span class="line"> &#125;;</span><br><span class="line"></span><br><span class="line"><span class="addition">+enum &#123;</span></span><br><span class="line"><span class="addition">+NFTNL_EXPR_ABCDE_TEXT= NFTNL_EXPR_BASE,</span></span><br><span class="line"><span class="addition">+&#125;;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"> enum &#123;</span><br><span class="line"> NFTNL_EXPR_QUEUE_NUM= NFTNL_EXPR_BASE,</span><br><span class="line"> NFTNL_EXPR_QUEUE_TOTAL,</span><br><span class="line"><span class="comment">diff --git a/include/linux/netfilter/abcde.h b/include/linux/netfilter/abcde.h</span></span><br><span class="line">new file mode 100644</span><br><span class="line"><span class="comment">index 0000000..eb027a7</span></span><br><span class="line"><span class="comment">--- /dev/null</span></span><br><span class="line"><span class="comment">+++ b/include/linux/netfilter/abcde.h</span></span><br><span class="line"><span class="meta">@@ -0,0 +1,12 @@</span></span><br><span class="line"><span class="addition">+#ifndef _ABCDE_H</span></span><br><span class="line"><span class="addition">+#define _ABCDE_H</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+enum nft_abcde_attributes &#123;</span></span><br><span class="line"><span class="addition">+NFTA_ABCDE_UNSPEC,</span></span><br><span class="line"><span class="addition">+NFTA_ABCDE_TEXT,</span></span><br><span class="line"><span class="addition">+__NFTA_ABCDE_MAX,</span></span><br><span class="line"><span class="addition">+&#125;;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+#define NFTA_ABCDE_MAX (__NFTA_ABCDE_MAX - 1)</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+#endif /* _ABCDE_H */</span></span><br><span class="line"><span class="comment">diff --git a/src/Makefile.am b/src/Makefile.am</span></span><br><span class="line"><span class="comment">index 485a8c4..a9cb87d 100644</span></span><br><span class="line"><span class="comment">--- a/src/Makefile.am</span></span><br><span class="line"><span class="comment">+++ b/src/Makefile.am</span></span><br><span class="line"><span class="meta">@@ -35,6 +35,7 @@</span> libnftnl_la_SOURCES = utils.c\</span><br><span class="line">       expr/fwd.c\</span><br><span class="line">       expr/limit.c\</span><br><span class="line">       expr/log.c\</span><br><span class="line"><span class="addition">+      expr/abcde.c\</span></span><br><span class="line">       expr/lookup.c\</span><br><span class="line">       expr/dynset.c\</span><br><span class="line">       expr/immediate.c\</span><br><span class="line"><span class="comment">diff --git a/src/expr/abcde.c b/src/expr/abcde.c</span></span><br><span class="line">new file mode 100644</span><br><span class="line"><span class="comment">index 0000000..e76abd4</span></span><br><span class="line"><span class="comment">--- /dev/null</span></span><br><span class="line"><span class="comment">+++ b/src/expr/abcde.c</span></span><br><span class="line"><span class="meta">@@ -0,0 +1,183 @@</span></span><br><span class="line"><span class="addition">+#include &lt;stdio.h&gt;</span></span><br><span class="line"><span class="addition">+#include &lt;stdint.h&gt;</span></span><br><span class="line"><span class="addition">+#include &lt;string.h&gt;</span></span><br><span class="line"><span class="addition">+#include &lt;arpa/inet.h&gt;</span></span><br><span class="line"><span class="addition">+#include &lt;errno.h&gt;</span></span><br><span class="line"><span class="addition">+#include &lt;linux/netfilter/nf_tables.h&gt;</span></span><br><span class="line"><span class="addition">+#include &lt;linux/netfilter/abcde.h&gt;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+#include &quot;internal.h&quot;</span></span><br><span class="line"><span class="addition">+#include &lt;libmnl/libmnl.h&gt;</span></span><br><span class="line"><span class="addition">+#include &lt;libnftnl/expr.h&gt;</span></span><br><span class="line"><span class="addition">+#include &lt;libnftnl/rule.h&gt;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+struct nftnl_expr_abcde &#123;</span></span><br><span class="line"><span class="addition">+const char*text;</span></span><br><span class="line"><span class="addition">+&#125;;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+static int nftnl_expr_abcde_set(struct nftnl_expr *e, uint16_t type,</span></span><br><span class="line"><span class="addition">+ const void *data, uint32_t data_len)</span></span><br><span class="line"><span class="addition">+&#123;</span></span><br><span class="line"><span class="addition">+struct nftnl_expr_abcde *abcde = nftnl_expr_data(e);</span></span><br><span class="line"><span class="addition">+switch(type)&#123;</span></span><br><span class="line"><span class="addition">+case NFTNL_EXPR_ABCDE_TEXT:</span></span><br><span class="line"><span class="addition">+abcde-&gt;text = strdup(data);</span></span><br><span class="line"><span class="addition">+if (!abcde-&gt;text)</span></span><br><span class="line"><span class="addition">+return -1;</span></span><br><span class="line"><span class="addition">+break;</span></span><br><span class="line"><span class="addition">+&#125;</span></span><br><span class="line"><span class="addition">+return 0;</span></span><br><span class="line"><span class="addition">+&#125;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+static const void *</span></span><br><span class="line"><span class="addition">+nftnl_expr_abcde_get(const struct nftnl_expr *e, uint16_t type,</span></span><br><span class="line"><span class="addition">+      uint32_t *data_len)</span></span><br><span class="line"><span class="addition">+&#123;</span></span><br><span class="line"><span class="addition">+struct nftnl_expr_abcde *abcde = nftnl_expr_data(e);</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+switch(type) &#123;</span></span><br><span class="line"><span class="addition">+case NFTNL_EXPR_ABCDE_TEXT:</span></span><br><span class="line"><span class="addition">+*data_len = strlen(abcde-&gt;text)+1;</span></span><br><span class="line"><span class="addition">+return abcde-&gt;text;</span></span><br><span class="line"><span class="addition">+&#125;</span></span><br><span class="line"><span class="addition">+return NULL;</span></span><br><span class="line"><span class="addition">+&#125;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+static int nftnl_expr_abcde_cb(const struct nlattr *attr, void *data)</span></span><br><span class="line"><span class="addition">+&#123;</span></span><br><span class="line"><span class="addition">+const struct nlattr **tb = data;</span></span><br><span class="line"><span class="addition">+int type = mnl_attr_get_type(attr);</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+if (mnl_attr_type_valid(attr, NFTA_ABCDE_MAX) &lt; 0)</span></span><br><span class="line"><span class="addition">+return MNL_CB_OK;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+switch(type) &#123;</span></span><br><span class="line"><span class="addition">+case NFTNL_EXPR_ABCDE_TEXT:</span></span><br><span class="line"><span class="addition">+if (mnl_attr_validate(attr, MNL_TYPE_STRING) &lt; 0)</span></span><br><span class="line"><span class="addition">+abi_breakage();</span></span><br><span class="line"><span class="addition">+break;</span></span><br><span class="line"><span class="addition">+&#125;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+tb[type] = attr;</span></span><br><span class="line"><span class="addition">+return MNL_CB_OK;</span></span><br><span class="line"><span class="addition">+&#125;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+static void</span></span><br><span class="line"><span class="addition">+nftnl_expr_abcde_build(struct nlmsghdr *nlh, const struct nftnl_expr *e)</span></span><br><span class="line"><span class="addition">+&#123;</span></span><br><span class="line"><span class="addition">+struct nftnl_expr_abcde *abcde = nftnl_expr_data(e);</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+if (e-&gt;flags &amp; (1 &lt;&lt; NFTNL_EXPR_ABCDE_TEXT))</span></span><br><span class="line"><span class="addition">+mnl_attr_put_strz(nlh, NFTNL_EXPR_ABCDE_TEXT, abcde-&gt;text);</span></span><br><span class="line"><span class="addition">+&#125;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+static int</span></span><br><span class="line"><span class="addition">+nftnl_expr_abcde_parse(struct nftnl_expr *e, struct nlattr *attr)</span></span><br><span class="line"><span class="addition">+&#123;</span></span><br><span class="line"><span class="addition">+struct nftnl_expr_abcde *abcde = nftnl_expr_data(e);</span></span><br><span class="line"><span class="addition">+struct nlattr *tb[NFTA_ABCDE_MAX+1] = &#123;&#125;;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+if (mnl_attr_parse_nested(attr, nftnl_expr_abcde_cb, tb) &lt; 0)</span></span><br><span class="line"><span class="addition">+return -1;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+if (tb[NFTNL_EXPR_ABCDE_TEXT]) &#123;</span></span><br><span class="line"><span class="addition">+if (abcde-&gt;text)</span></span><br><span class="line"><span class="addition">+xfree(abcde-&gt;text);</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+abcde-&gt;text = strdup(mnl_attr_get_str(tb[NFTNL_EXPR_ABCDE_TEXT]));</span></span><br><span class="line"><span class="addition">+if (!abcde-&gt;text)</span></span><br><span class="line"><span class="addition">+return -1;</span></span><br><span class="line"><span class="addition">+e-&gt;flags |= (1 &lt;&lt; NFTNL_EXPR_ABCDE_TEXT);</span></span><br><span class="line"><span class="addition">+&#125;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+return 0;</span></span><br><span class="line"><span class="addition">+&#125;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+static int nftnl_expr_abcde_json_parse(struct nftnl_expr *e, json_t *root,</span></span><br><span class="line"><span class="addition">+struct nftnl_parse_err *err)</span></span><br><span class="line"><span class="addition">+&#123;</span></span><br><span class="line"><span class="addition">+#ifdef JSON_PARSING</span></span><br><span class="line"><span class="addition">+const char *text;</span></span><br><span class="line"><span class="addition">+uint16_t group, qthreshold;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+text = nftnl_jansson_parse_str(root, &quot;text&quot;, err);</span></span><br><span class="line"><span class="addition">+if (text != NULL)</span></span><br><span class="line"><span class="addition">+nftnl_expr_set_str(e, NFTNL_EXPR_ABCDE_TEXT, text);</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+return 0;</span></span><br><span class="line"><span class="addition">+#else</span></span><br><span class="line"><span class="addition">+errno = EOPNOTSUPP;</span></span><br><span class="line"><span class="addition">+return -1;</span></span><br><span class="line"><span class="addition">+#endif</span></span><br><span class="line"><span class="addition">+&#125;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+static int nftnl_expr_abcde_snprintf_default(char *buf, size_t size,</span></span><br><span class="line"><span class="addition">+   const struct nftnl_expr *e)</span></span><br><span class="line"><span class="addition">+&#123;</span></span><br><span class="line"><span class="addition">+struct nftnl_expr_abcde *abcde = nftnl_expr_data(e);</span></span><br><span class="line"><span class="addition">+int ret, offset = 0, len = size;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+if (e-&gt;flags &amp; (1 &lt;&lt; NFTNL_EXPR_ABCDE_TEXT)) &#123;</span></span><br><span class="line"><span class="addition">+ret = snprintf(buf, len, &quot;text %s &quot;, abcde-&gt;text);</span></span><br><span class="line"><span class="addition">+SNPRINTF_BUFFER_SIZE(ret, size, len, offset);</span></span><br><span class="line"><span class="addition">+&#125;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+return offset;</span></span><br><span class="line"><span class="addition">+&#125;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+static int nftnl_expr_abcde_export(char *buf, size_t size,</span></span><br><span class="line"><span class="addition">+ const struct nftnl_expr *e, int type)</span></span><br><span class="line"><span class="addition">+&#123;</span></span><br><span class="line"><span class="addition">+struct nftnl_expr_abcde *abcde = nftnl_expr_data(e);</span></span><br><span class="line"><span class="addition">+NFTNL_BUF_INIT(b, buf, size);</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+if (e-&gt;flags &amp; (1 &lt;&lt; NFTNL_EXPR_ABCDE_TEXT))</span></span><br><span class="line"><span class="addition">+nftnl_buf_str(&amp;b, type, abcde-&gt;text, &quot;text&quot;);</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+return nftnl_buf_done(&amp;b);</span></span><br><span class="line"><span class="addition">+&#125;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+static int</span></span><br><span class="line"><span class="addition">+nftnl_expr_abcde_snprintf(char *buf, size_t len, uint32_t type,</span></span><br><span class="line"><span class="addition">+uint32_t flags, const struct nftnl_expr *e)</span></span><br><span class="line"><span class="addition">+&#123;</span></span><br><span class="line"><span class="addition">+switch(type) &#123;</span></span><br><span class="line"><span class="addition">+case NFTNL_OUTPUT_DEFAULT:</span></span><br><span class="line"><span class="addition">+return nftnl_expr_abcde_snprintf_default(buf, len, e);</span></span><br><span class="line"><span class="addition">+case NFTNL_OUTPUT_XML:</span></span><br><span class="line"><span class="addition">+case NFTNL_OUTPUT_JSON:</span></span><br><span class="line"><span class="addition">+return nftnl_expr_abcde_export(buf, len, e, type);</span></span><br><span class="line"><span class="addition">+default:</span></span><br><span class="line"><span class="addition">+break;</span></span><br><span class="line"><span class="addition">+&#125;</span></span><br><span class="line"><span class="addition">+return -1;</span></span><br><span class="line"><span class="addition">+&#125;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+static void nftnl_expr_abcde_free(const struct nftnl_expr *e)</span></span><br><span class="line"><span class="addition">+&#123;</span></span><br><span class="line"><span class="addition">+struct nftnl_expr_abcde *abcde = nftnl_expr_data(e);</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+xfree(abcde-&gt;text);</span></span><br><span class="line"><span class="addition">+&#125;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+static bool nftnl_expr_abcde_cmp(const struct nftnl_expr *e1,</span></span><br><span class="line"><span class="addition">+     const struct nftnl_expr *e2)</span></span><br><span class="line"><span class="addition">+&#123;</span></span><br><span class="line"><span class="addition">+struct nftnl_expr_abcde *l1 = nftnl_expr_data(e1);</span></span><br><span class="line"><span class="addition">+struct nftnl_expr_abcde *l2 = nftnl_expr_data(e2);</span></span><br><span class="line"><span class="addition">+return !strcmp(l1-&gt;text, l2-&gt;text);</span></span><br><span class="line"><span class="addition">+&#125;</span></span><br><span class="line"><span class="addition">+</span></span><br><span class="line"><span class="addition">+struct expr_ops expr_ops_abcde = &#123;</span></span><br><span class="line"><span class="addition">+.name= &quot;abcde&quot;,</span></span><br><span class="line"><span class="addition">+.alloc_len= sizeof(struct nftnl_expr_abcde),</span></span><br><span class="line"><span class="addition">+.max_attr= NFTA_ABCDE_MAX,</span></span><br><span class="line"><span class="addition">+.free= nftnl_expr_abcde_free,</span></span><br><span class="line"><span class="addition">+.cmp= nftnl_expr_abcde_cmp,</span></span><br><span class="line"><span class="addition">+.set= nftnl_expr_abcde_set,</span></span><br><span class="line"><span class="addition">+.get= nftnl_expr_abcde_get,</span></span><br><span class="line"><span class="addition">+.parse= nftnl_expr_abcde_parse,</span></span><br><span class="line"><span class="addition">+.build= nftnl_expr_abcde_build,</span></span><br><span class="line"><span class="addition">+.snprintf= nftnl_expr_abcde_snprintf,</span></span><br><span class="line"><span class="addition">+.json_parse= nftnl_expr_abcde_json_parse,</span></span><br><span class="line"><span class="addition">+&#125;;</span></span><br><span class="line"><span class="comment">diff --git a/src/expr_ops.c b/src/expr_ops.c</span></span><br><span class="line"><span class="comment">index 7a0e1e3..a02878c 100644</span></span><br><span class="line"><span class="comment">--- a/src/expr_ops.c</span></span><br><span class="line"><span class="comment">+++ b/src/expr_ops.c</span></span><br><span class="line"><span class="meta">@@ -33,6 +33,7 @@</span> extern struct expr_ops expr_ops_target;</span><br><span class="line"> extern struct expr_ops expr_ops_dynset;</span><br><span class="line"> extern struct expr_ops expr_ops_hash;</span><br><span class="line"> extern struct expr_ops expr_ops_fib;</span><br><span class="line"><span class="addition">+extern struct expr_ops expr_ops_abcde;</span></span><br><span class="line"></span><br><span class="line"> static struct expr_ops expr_ops_notrack = &#123;</span><br><span class="line"> .name= &quot;notrack&quot;,</span><br><span class="line"><span class="meta">@@ -69,6 +70,7 @@</span> static struct expr_ops *expr_ops[] = &#123;</span><br><span class="line"> &amp;expr_ops_hash,</span><br><span class="line"> &amp;expr_ops_fib,</span><br><span class="line"> &amp;expr_ops_objref,</span><br><span class="line"><span class="addition">+&amp;expr_ops_abcde,</span></span><br><span class="line"> NULL,</span><br><span class="line"> &#125;;</span><br></pre></td></tr></table></figure><p>The abcde branch of nftables and libnftnl can be found at GitHub:<br><a href="https://github.com/zasdfgbnm/nftables/tree/abcde">https://github.com/zasdfgbnm/nftables/tree/abcde</a><br><a href="https://github.com/zasdfgbnm/libnftnl/tree/abcde">https://github.com/zasdfgbnm/libnftnl/tree/abcde</a></p><h1 id="Test"><a href="#Test" class="headerlink" title="Test"></a>Test</h1><p>Our new module can be tested by inserting our module, and then using our self-compiled nft tool to add a rule that looks like:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">PREFIX=/home/gaoxiang/tmp/test_nftables</span><br><span class="line"><span class="built_in">export</span> LD_LIBRARY_PATH=<span class="variable">$PREFIX</span>/lib</span><br><span class="line"><span class="variable">$PREFIX</span>/sbin/nft add table ip <span class="built_in">test</span></span><br><span class="line"><span class="variable">$PREFIX</span>/sbin/nft add chain <span class="built_in">test</span> <span class="built_in">test</span> \&#123; <span class="built_in">type</span> filter hook postrouting priority 0\; \&#125;</span><br><span class="line"><span class="variable">$PREFIX</span>/sbin/nft add rule ip <span class="built_in">test</span> <span class="built_in">test</span> tcp sport 4000 abcde darkhttpd <span class="built_in">log</span> prefix <span class="string">&quot;darkhttpd___&quot;</span></span><br></pre></td></tr></table></figure><p>Open a darkhttpd server, access to it, and the output of <code>dmesg</code> will looks like:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[ 2427.056229] darkhttpd___IN&#x3D; OUT&#x3D;lo SRC&#x3D;127.0.0.1 DST&#x3D;127.0.0.1 LEN&#x3D;60 TOS&#x3D;0x00 PREC&#x3D;0x00 TTL&#x3D;64 ID&#x3D;0 DF PROTO&#x3D;TCP SPT&#x3D;4000 DPT&#x3D;36840 WINDOW&#x3D;43690 RES&#x3D;0x00 ACK SYN URGP&#x3D;0</span><br><span class="line">[ 2427.094038] darkhttpd___IN&#x3D; OUT&#x3D;lo SRC&#x3D;127.0.0.1 DST&#x3D;127.0.0.1 LEN&#x3D;52 TOS&#x3D;0x00 PREC&#x3D;0x00 TTL&#x3D;64 ID&#x3D;9012 DF PROTO&#x3D;TCP SPT&#x3D;4000 DPT&#x3D;36840 WINDOW&#x3D;357 RES&#x3D;0x00 ACK URGP&#x3D;0</span><br><span class="line">[ 2427.094162] darkhttpd___IN&#x3D; OUT&#x3D;lo SRC&#x3D;127.0.0.1 DST&#x3D;127.0.0.1 LEN&#x3D;269 TOS&#x3D;0x00 PREC&#x3D;0x00 TTL&#x3D;64 ID&#x3D;9013 DF PROTO&#x3D;TCP SPT&#x3D;4000 DPT&#x3D;36840 WINDOW&#x3D;357 RES&#x3D;0x00 ACK PSH URGP&#x3D;0</span><br><span class="line">[ 2427.094216] darkhttpd___IN&#x3D; OUT&#x3D;lo SRC&#x3D;127.0.0.1 DST&#x3D;127.0.0.1 LEN&#x3D;97 TOS&#x3D;0x00 PREC&#x3D;0x00 TTL&#x3D;64 ID&#x3D;9014 DF PROTO&#x3D;TCP SPT&#x3D;4000 DPT&#x3D;36840 WINDOW&#x3D;357 RES&#x3D;0x00 ACK PSH URGP&#x3D;0</span><br><span class="line">[ 2427.361198] darkhttpd___IN&#x3D; OUT&#x3D;lo SRC&#x3D;127.0.0.1 DST&#x3D;127.0.0.1 LEN&#x3D;246 TOS&#x3D;0x00 PREC&#x3D;0x00 TTL&#x3D;64 ID&#x3D;9015 DF PROTO&#x3D;TCP SPT&#x3D;4000 DPT&#x3D;36840 WINDOW&#x3D;372 RES&#x3D;0x00 ACK PSH URGP&#x3D;0</span><br><span class="line">[ 2427.361215] darkhttpd___IN&#x3D; OUT&#x3D;lo SRC&#x3D;127.0.0.1 DST&#x3D;127.0.0.1 LEN&#x3D;258 TOS&#x3D;0x00 PREC&#x3D;0x00 TTL&#x3D;64 ID&#x3D;9016 DF PROTO&#x3D;TCP SPT&#x3D;4000 DPT&#x3D;36840 WINDOW&#x3D;372 RES&#x3D;0x00 ACK PSH URGP&#x3D;0</span><br><span class="line">[ 2475.658088] darkhttpd___IN&#x3D; OUT&#x3D;lo SRC&#x3D;127.0.0.1 DST&#x3D;127.0.0.1 LEN&#x3D;52 TOS&#x3D;0x00 PREC&#x3D;0x00 TTL&#x3D;64 ID&#x3D;9017 DF PROTO&#x3D;TCP SPT&#x3D;4000 DPT&#x3D;36840 WINDOW&#x3D;372 RES&#x3D;0x00 ACK URGP&#x3D;0</span><br><span class="line">[ 2521.747363] darkhttpd___IN&#x3D; OUT&#x3D;lo SRC&#x3D;127.0.0.1 DST&#x3D;127.0.0.1 LEN&#x3D;52 TOS&#x3D;0x00 PREC&#x3D;0x00 TTL&#x3D;64 ID&#x3D;9018 DF PROTO&#x3D;TCP SPT&#x3D;4000 DPT&#x3D;36840 WINDOW&#x3D;372 RES&#x3D;0x00 ACK URGP&#x3D;0</span><br><span class="line">[ 2567.826378] darkhttpd___IN&#x3D; OUT&#x3D;lo SRC&#x3D;127.0.0.1 DST&#x3D;127.0.0.1 LEN&#x3D;52 TOS&#x3D;0x00 PREC&#x3D;0x00 TTL&#x3D;64 ID&#x3D;9019 DF PROTO&#x3D;TCP SPT&#x3D;4000 DPT&#x3D;36840 WINDOW&#x3D;372 RES&#x3D;0x00 ACK URGP&#x3D;0</span><br></pre></td></tr></table></figure>]]></content>
    
    
    <summary type="html">&lt;h1 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h1&gt;&lt;p&gt;I’m recently writing something that uses Linux’s firewall framework to do some non-standard operations packets. Extending the kernel is required for my task but unfortunately documentations about this topic I find online are quite dated. These old documents are mainly for kernel version 2.4 and earlier 2.6.x, in which new matches or targets are registered by calling &lt;code&gt;ipt_register_match&lt;/code&gt; and &lt;code&gt;ipt_register_target&lt;/code&gt;. The related subsystem of kernel has changed a lot since then, and iptables has been replaced by nftables. Although we can use &lt;code&gt;xt_register_match&lt;/code&gt; and &lt;code&gt;xt_register_target&lt;/code&gt; instead, I prefer to move to the new nftables framework. Due to the lack of documentation, I have to dig into the source code of Linux kernel to figure out how things works, and this post is the note for that. As Linus Torvalds says in 2008, “Linux is evolution, not intelligent design”, the design and API of nftables might be changing very fast. So I’m not only trying to make a brief review on the design or API of nftables. But also, this post will serve as a guide on how to find the correct way of doing things by reading the kernel source code. The eager reader can go directly to &lt;a href=&quot;#summary&quot;&gt;the summary section&lt;/a&gt;. This post is based on kernel version 4.13, the most recent version when this post is started writing.&lt;/p&gt;
&lt;p&gt;Here in this post, we will solve a toy problem: monitor all outgoing TCP traffic from port 80, if it contains the string given by the user, log it. I don’t assume any knowledge in the design or kernel API of nftables, but I do assume the reader has read and understand well &lt;a href=&quot;https://wiki.nftables.org/&quot;&gt;the official documents on how to use nftables&lt;/a&gt;.&lt;/p&gt;</summary>
    
    
    
    <category term="Linux" scheme="https://zasdfgbnm.github.io/categories/Linux/"/>
    
    
    <category term="Linux" scheme="https://zasdfgbnm.github.io/tags/Linux/"/>
    
    <category term="Kernel" scheme="https://zasdfgbnm.github.io/tags/Kernel/"/>
    
    <category term="nftables" scheme="https://zasdfgbnm.github.io/tags/nftables/"/>
    
    <category term="network" scheme="https://zasdfgbnm.github.io/tags/network/"/>
    
    <category term="netfilter" scheme="https://zasdfgbnm.github.io/tags/netfilter/"/>
    
  </entry>
  
  <entry>
    <title>Rademacher复杂度学习笔记</title>
    <link href="https://zasdfgbnm.github.io/2017/07/06/Rademacher%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    <id>https://zasdfgbnm.github.io/2017/07/06/Rademacher%E5%A4%8D%E6%9D%82%E5%BA%A6%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/</id>
    <published>2017-07-07T02:40:59.000Z</published>
    <updated>2021-04-04T05:17:59.765Z</updated>
    
    <content type="html"><![CDATA[<p>计算学习理论中的一类很重要的问题是研究训练集训练出来的模型在训练集以外的表现，即泛化误差（generalization error）。我们来考虑这样一个问题，我们想要拟合目标函数$f:\mathcal{X}\to\mathbb{R}$，为此，我们选取假设空间（hypothesis space） $\mathcal{H}$，然后通过某种方法获得一个训练集$S=\left\{(x_1,f(x_1)),(x_2,f(x_2)),\ldots(x_m,f(x_m))\right\}$。这个训练集被认为是从$\mathcal{X}$上的概率分布$\mathcal{P}$进行独立同分布的抽样而来。获得训练集以后，我们把训练集作为输入输送给某个优化算法$\mathscr{A}$。这个算法本身可能是带有随机性的，比如SGD，但是如果把算法使用的随机数发生器生成的随机数也看成算法的输入的话，那么这个优化算法就没有任何随机可言，给定一个训练集$S$以及随机数$\theta$，算法输出唯一的$h=\mathscr{A}(S,\theta)\in\mathcal{H}$。如果我们使用$\mathfrak{l}:\mathbb{R}\times\mathbb{R}\to\mathbb{R}_{\ge0}$作为损失函数来衡量$f$与$g$的差异的话，我们关心的是，当我们的训练误差为$\hat{\mathrm{E}}_{x\in S}[\mathfrak{l}(h(x),f(x))]:=\frac{1}{m}\sum_{i=1}^m\mathfrak{l}(h(x_i),f(x_i))$时，我们有多大的置信度来保证这个算法的输出的$h$的泛化误差$\mathrm{E}_{x\sim\mathcal{P}}[\mathfrak{l}(h(x),f(x))]$比训练误差不会高出超过$\epsilon$，即<br>$$\mathrm{E}_{x\sim\mathcal{P}}[\mathfrak{l}(h(x),f(x))]-\hat{\mathrm{E}}_{x\in S}[\mathfrak{l}(h(x),f(x))]\leq\epsilon$$</p><span id="more"></span><p>作为算法的输出，$h$依赖于具体选取的优化算法，以及提供给算法的随机数，这些都不是什么方便研究的东西，于是通常情况下将这层信息抹去。要将这层信息抹去，我们将上式的要求收紧：我们不仅仅要求算法输出的$h$满足上式，而是要求$\mathcal{H}$中的所有元素都满足上式要求。写成式子就是：<br>$$\sup_{h\in\mathcal{H}}\left\{\mathrm{E}_{x\sim\mathcal{P}}[\mathfrak{l}(h(x),f(x))]-\hat{\mathrm{E}}_{x\in S}[\mathfrak{l}(h(x),f(x))]\right\}\leq\epsilon$$</p><p>我们将上式左边的部分记为$\varphi(S)$。由于要求更苛刻了，所以我们估算出来的置信度是更悲观的。实际上的置信度要比估算出来的大一些，即：<br>$$\mathrm{Pr}\left(\mathrm{E}_{x\sim\mathcal{P}}[\mathfrak{l}(h(x),f(x))]-\hat{\mathrm{E}}_{x\in S}[\mathfrak{l}(h(x),f(x))]\leq\epsilon\right)\geq\mathrm{Pr}\left(\varphi(S)\leq\epsilon\right)$$也就是说，通过估算$\mathcal{P}\left(\varphi(S)\leq\epsilon\right)$，我们可以找到我们最终想要的置信度的一个下界。</p><p>下面就来考察$\varphi(S)\leq\epsilon$这个条件。首先来思考一个问题：在保证大的置信度的前提下，$\epsilon$的值我们能往下压到多小呢？我们可以通过加大样本的数量来把$\epsilon$压到任意接近于$0$吗？如果我们对$\mathcal{H}$不加任何限定的话，答案是否定的。为了说明这一点，我们来考虑$\mathcal{H}$是所有$\mathcal{X}\to\mathbb{R}$的函数的集合的情况：通常情况下，我们遇到的问题中的$\mathcal{X}$都是某个$\mathbb{R}^n$，而$\mathcal{P}$则是一个相对于$\mathcal{X}$上的Lebesgue测度绝对连续的概率测度。而$S$呢？一个Lebesgue零测集而已，存在感为零。来看泛化误差吧，根据其定义：$$\mathrm{E}_{x\sim\mathcal{P}}[\mathfrak{l}(h(x),f(x))]=\int\mathfrak{l}(h(x),f(x))d\mathcal{P}(x)$$我们非常容易就能找到一个与$f$相去甚远的$h$，这样上述Lebesgue积分的值可以任意大，然后我们把$S$上$h$的值替换为$f$在$S$上的值，上述Lebesgue积分的值仍然保持不变，然而训练误差却变成了$0$。</p><p>上面的思考告诉我们，$\epsilon$的值能往下压到多小是取决于$\mathcal{H}$的性质的。为了能把$\epsilon$的值能往下压，我们必须要对$\mathcal{H}$进行一些限制。而本文所讨论的Rademacher复杂度就是这样一个限制。为了推导出Rademacher复杂度的相关定理，我们将$\varphi(S)$拆成两部分：<br>$$\varphi(S)=\mathrm{E}_S[\varphi(S)]+\left(\varphi(S)-\mathrm{E}_S[\varphi(S)]\right)$$其中$\mathrm{E}_S[\cdot]$表示针对$S$根据其概率（$m$个分布为$\mathcal{P}$的独立同分布的联合概率）求取期望。这两部分的含义我们可以这样直观地理解：设想我们在打靶，砰砰砰若干枪射出去了以后，我们在靶上打下了若干弹孔。这些弹孔的中心（平均位置）代表我们打靶的准确度。如果我们的弹孔中心不在靶心，而是有个整体偏移，这就说明我们的瞄准方法不当，导致没有瞄准到靶心。而这些弹孔的散布，则说明我们的稳定性，如果我们的弹孔散布很大四处都有，这就说明我们打枪的时候手抖得厉害。上面公式中的第一部分$\mathrm{E}_S[\varphi(S)]$相当于打枪弹孔的中心位置，而第二部分$\varphi(S)-\mathrm{E}_S[\varphi(S)]$则相当于每个弹孔相对于中心位置的相对位置。那么，中心位置跟相对位置又分别代表了什么呢？我们来思考一下为什么泛化误差通常会比训练误差大吧：</p><p>一方面，我们的假设空间$\mathcal{H}$并不是只有少数几个元素，而是有非常多的元素的。多到即使把$m$个点的值固定下来，不管这$m$个点具体是什么点，也都远远不足以唯一确定一个$h$。相反，不管取哪$m$个点，总会有很多个$h\in\mathcal{H}$与$f$在这$m$个点处吻合很好并且在这$m$个点之外的地方仍然保持一定的任意性。不要忘了，我们研究的$\varphi(S)$可是要从所有这些吻合的$h$中挑选一个泛化误差最不好的，而$h$在这$m$个点外的这种任意性就给了泛化误差上升的空间。这种独立于这$m$个点的具体的选取方式的效应，造成的泛化误差的上升对于$\varphi(S)$的贡献就是$\mathrm{E}_S[\varphi(S)]$。由于与这$m$个点的选取无关，这种效应是不具有随机性的，它仅与$\mathcal{H}$的性质有关。</p><p>另一方面，具体选取的这$m$个点不一样，自然也会给$h$带来不同大小的任意性。因此，泛化误差比训练误差多出来的那部分$\varphi(S)$不会是一成不变的$\mathrm{E}_S[\varphi(S)]$，而是会根据具体的$S$的值在$\mathrm{E}_S[\varphi(S)]$附近上下波动。这部分对$\varphi(S)$的贡献则是$\varphi(S)-\mathrm{E}_S[\varphi(S)]$。由于$S$是随机选取的，这部分是个随机问题。</p><p>我们既然想要以比较大的置信度断定$\varphi(S)$比较小，这就相当于要求射击选手能够稳定发挥，保证子弹在靶心附近不远，不会出差错。要达到这点要求，射击选手既要保证自己打靶的准确度高，也要保证自己打靶子弹的散布是比较小，二者缺一不可。</p><p>先来看第二部分$\varphi(S)-\mathrm{E}_S[\varphi(S)]$。我们想要这部分比较小，而概率论中刚好有个不等式是这种形式，那就是McDiarmid不等式：</p><blockquote><p><strong>定理（McDiarmid不等式）：</strong> 若$x_1,\ldots,x_m$是$m$个独立随机变量，关于$x_1,\ldots,x_m$的函数$\varphi$满足<br>$$\sup_{x_1,\ldots,x_i,\ldots,x_m,x_i’}\left|\varphi(x_1,\ldots,x_i,\ldots,x_m)-\varphi(x_1,\ldots,x_i’,\ldots,x_m)\right|\leq c_i$$则<br>$$\mathrm{Pr}\left(\varphi(x_1,\ldots,x_m)-\mathrm{E}\left[\varphi(x_1,\ldots,x_m)\right]\geq\epsilon\right)\leq e^{-2\epsilon^2/\sum_{i=1}^m c_i^2}$$</p></blockquote><p>要想套用McDiarmid不等式，我们先来看一下不等式要求中的$\left|\varphi(S)-\varphi(S’)\right|$，其中$S’$是将$S$中第$i$个元素由$x_i$替换为$x_i’$得来：<br>$$\begin{eqnarray}<br>\left|\varphi(S)-\varphi(S’)\right|=\left|\sup_{h\in\mathcal{H}}\left\{\mathrm{E}_{x\sim\mathcal{P}}[\mathfrak{l}(h(x),f(x))]-\hat{\mathrm{E}}_{x\in S}[\mathfrak{l}(h(x),f(x))]\right\}-\sup_{h\in\mathcal{H}}\left\{\mathrm{E}_{x\sim\mathcal{P}}[\mathfrak{l}(h(x),f(x))]-\hat{\mathrm{E}}_{x\in S’}[\mathfrak{l}(h(x),f(x))]\right\}\right| \\<br>\leq\sup_{h\in\mathcal{H}}\left|\hat{\mathrm{E}}_{x\in S’}[\mathfrak{l}(h(x),f(x))]-\hat{\mathrm{E}}_{x\in S}[\mathfrak{l}(h(x),f(x))]\right|=\frac{1}{m}\sup_{h\in\mathcal{H}}\left|\mathfrak{l}(h(x_i’),f(x_i’))-\mathfrak{l}(h(x_i),f(x_i))\right|\leq\frac{M}{m}<br>\end{eqnarray}$$其中<br>$$M=\sup_{h\in\mathcal{H}}\left\{\sup_{x\in\mathcal{X}}\mathfrak{l}(h(x),f(x))-\inf_{x\in\mathcal{X}}\mathfrak{l}(h(x),f(x))\right\}$$这里我们确实有假定$h$与$f$之间的最大误差是有界的。有了上面的关系，我们就得到<br>$$\mathrm{Pr}\left(\varphi(S)-\mathrm{E}_S\left[\varphi(S)\right]\geq\epsilon\right)\leq e^{-2m\epsilon^2/M^2}$$如果我们令上述概率为$\delta$，则可解出<br>$$\epsilon=M\sqrt{\frac{\log\frac{1}{\delta}}{2m}}$$于是，我们可以以$1-\delta$的置信概率来相信$\varphi(S)-\mathrm{E}_S[\varphi(S)]$的值不会超过$M\sqrt{\frac{\log\frac{1}{\delta}}{2m}}$。第二部分算是研究完了。</p><p>再来看一下第一部分$\mathrm{E}_S[\varphi(S)]$。我们希望通过对这一部分的研究来导出一个对$\mathcal{H}$的合理的约束。引入一个同样包含$m$个元素的幽灵样本$\tilde{S}$，则$\mathrm{E}_{x\sim\mathcal{P}}[\mathfrak{l}(h(x),f(x))]$可以写成<br>$$\mathrm{E}_{x\sim\mathcal{P}}[\mathfrak{l}(h(x),f(x))]=\mathrm{E}_{\tilde{S}}\left[\hat{\mathrm{E}}_{\tilde{x}\in\tilde{S}}[\mathfrak{l}(h(\tilde{x}),f(\tilde{x}))]\right]$$由于$\hat{\mathrm{E}}_{x\in S}[\mathfrak{l}(h(x),f(x))]$相对于$\tilde{S}$来讲只是个常数而已，因此有<br>$$\hat{\mathrm{E}}_{x\in S}[\mathfrak{l}(h(x),f(x))]=\mathrm{E}_{\tilde{S}}\left[\hat{\mathrm{E}}_{x\in S}[\mathfrak{l}(h(x),f(x))]\right]$$于是$\varphi(S)$可以写成<br>$$\begin{eqnarray}<br>\varphi(S)=\sup_{h\in\mathcal{H}}\left\{\mathrm{E}_{\tilde{S}}\left[\hat{\mathrm{E}}_{\tilde{x}\in\tilde{S}}[\mathfrak{l}(h(\tilde{x}),f(\tilde{x}))]-\hat{\mathrm{E}}_{x\in S}[\mathfrak{l}(h(x),f(x))]\right]\right\} \\<br>\leq\mathrm{E}_{\tilde{S}}\left[\sup_{h\in\mathcal{H}}\left\{\hat{\mathrm{E}}_{\tilde{x}\in\tilde{S}}[\mathfrak{l}(h(\tilde{x}),f(\tilde{x}))]-\hat{\mathrm{E}}_{x\in S}[\mathfrak{l}(h(x),f(x))]\right\}\right]<br>\end{eqnarray}$$于是有<br>$$\begin{eqnarray}<br>\mathrm{E}_S[\varphi(S)]\leq\mathrm{E}_{S,\tilde{S}}\left[\sup_{h\in\mathcal{H}}\left\{\hat{\mathrm{E}}_{\tilde{x}\in\tilde{S}}[\mathfrak{l}(h(\tilde{x}),f(\tilde{x}))]-\hat{\mathrm{E}}_{x\in S}[\mathfrak{l}(h(x),f(x))]\right\}\right] \\<br>=\mathrm{E}_{S,\tilde{S}}\left[\sup_{h\in\mathcal{H}}\left\{\frac{1}{m}\sum_{i=1}^{m}\left[\mathfrak{l}(h(\tilde{x}_{i}),f(\tilde{x}_{i}))-\mathfrak{l}(h(x_{i}),f(x_{i}))\right] \right\}\right]<br>\end{eqnarray}$$注意到上式中的$S$跟$\tilde{S}$相互独立且服从相同的分布，并且他们中的每个元素也是独立同分布的。于是对于任意的$i$，我们总是可以把$\tilde{x}_i$与$x_i$对调让$\tilde{x}_i$到$S$中去而让$x_i$到$\tilde{S}$中去，这种对调并不影响总的结果。于是可以引入一个新的在$\{-1,1\}$中取值的随机变量$\sigma$用来控制是否进行上述对调。只要$\sigma$与$S$跟$\tilde{S}$相互独立，这个新引入的随机变量并不会对结果有任何改变。写成式子就是：<br>$$\mathrm{E}_{S,\tilde{S}}\left[\sup_{h\in\mathcal{H}}\left\{\frac{1}{m}\sum_{i=1}^{m}\left[\mathfrak{l}(h(\tilde{x}_{i}),f(\tilde{x}_{i}))-\mathfrak{l}(h(x_{i}),f(x_{i}))\right] \right\}\right]=\mathrm{E}_{\sigma,S,\tilde{S}}\left[\sup_{h\in\mathcal{H}}\left\{\frac{1}{m}\sum_{i=1}^{m}\sigma_i\left[\mathfrak{l}(h(\tilde{x}_{i}),f(\tilde{x}_{i}))-\mathfrak{l}(h(x_{i}),f(x_{i}))\right] \right\}\right]$$<br>注意到<br>$$\begin{eqnarray}<br>\mathrm{E}_{\sigma,S,\tilde{S}}\left[\sup_{h\in\mathcal{H}}\left\{\frac{1}{m}\sum_{i=1}^{m}\sigma_i\left[\mathfrak{l}(h(\tilde{x}_{i}),f(\tilde{x}_{i}))-\mathfrak{l}(h(x_{i}),f(x_{i}))\right] \right\}\right] \leq \mathrm{E}_{\sigma,S,\tilde{S}}\left[\sup_{h\in\mathcal{H}}\left\{\frac{1}{m}\sum_{i=1}^{m}\sigma_i\mathfrak{l}(h(\tilde{x}_{i}),f(\tilde{x}_{i}))\right\} + \sup_{h\in\mathcal{H}}\left\{\frac{1}{m}\sum_{i=1}^{m}-\sigma_i\mathfrak{l}(h(x_{i}),f(x_{i}))\right\} \right]    \\<br>= \mathrm{E}_{\sigma,\tilde{S}}\left[\sup_{h\in\mathcal{H}}\left\{\frac{1}{m}\sum_{i=1}^{m}\sigma_i\mathfrak{l}(h(\tilde{x}_{i}),f(\tilde{x}_{i}))\right\}\right] + \mathrm{E}_{\sigma,S}\left[\sup_{h\in\mathcal{H}}\left\{\frac{1}{m}\sum_{i=1}^{m}-\sigma_i\mathfrak{l}(h(x_{i}),f(x_{i}))\right\} \right]    \\<br>= \mathrm{E}_{\sigma,\tilde{S}}\left[\sup_{h\in\mathcal{H}}\left\{\frac{1}{m}\sum_{i=1}^{m}\sigma_i\mathfrak{l}(h(\tilde{x}_{i}),f(\tilde{x}_{i}))\right\}\right] + \mathrm{E}_{\sigma,S}\left[\sup_{h\in\mathcal{H}}\left\{\frac{1}{m}\sum_{i=1}^{m}\sigma_i\mathfrak{l}(h(x_{i}),f(x_{i}))\right\} \right]    \\<br>= 2 \mathrm{E}_{\sigma,S}\left[\sup_{h\in\mathcal{H}}\left\{\frac{1}{m}\sum_{i=1}^{m}\sigma_i\mathfrak{l}(h(x_{i}),f(x_{i}))\right\} \right]<br>\end{eqnarray}<br>$$<br>记<br>$$\mathrm{R}_m(\mathfrak{l}(\mathcal{H},f))=\mathrm{E}_{\sigma,S}\left[\sup_{h\in\mathcal{H}}\left\{\frac{1}{m}\sum_{i=1}^{m}\sigma_i\mathfrak{l}(h(x_{i}),f(x_{i}))\right\} \right]$$并称其为函数$\mathfrak{l}(h(x),f(x))$的Rademacher复杂度。我们有关系式：<br>$$\mathrm{E}_S[\varphi(S)]\leq 2\mathrm{R}_m(\mathfrak{l}(\mathcal{H},f))$$</p><p>综上，我们可以说：我们可以以$1-\delta$的置信概率来相信$\varphi(S)$的值不会超过<br>$$2\mathrm{R}_m(\mathfrak{l}(\mathcal{H},f))+M\sqrt{\frac{\log\frac{1}{\delta}}{2m}}$$<br>这就是我们想要的最终结果。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;计算学习理论中的一类很重要的问题是研究训练集训练出来的模型在训练集以外的表现，即泛化误差（generalization error）。我们来考虑这样一个问题，我们想要拟合目标函数$f:\mathcal{X}\to\mathbb{R}$，为此，我们选取假设空间（hypothesis space） $\mathcal{H}$，然后通过某种方法获得一个训练集$S=\left\{(x_1,f(x_1)),(x_2,f(x_2)),\ldots(x_m,f(x_m))\right\}$。这个训练集被认为是从$\mathcal{X}$上的概率分布$\mathcal{P}$进行独立同分布的抽样而来。获得训练集以后，我们把训练集作为输入输送给某个优化算法$\mathscr{A}$。这个算法本身可能是带有随机性的，比如SGD，但是如果把算法使用的随机数发生器生成的随机数也看成算法的输入的话，那么这个优化算法就没有任何随机可言，给定一个训练集$S$以及随机数$\theta$，算法输出唯一的$h=\mathscr{A}(S,\theta)\in\mathcal{H}$。如果我们使用$\mathfrak{l}:\mathbb{R}\times\mathbb{R}\to\mathbb{R}_{\ge0}$作为损失函数来衡量$f$与$g$的差异的话，我们关心的是，当我们的训练误差为$\hat{\mathrm{E}}_{x\in S}[\mathfrak{l}(h(x),f(x))]:=\frac{1}{m}\sum_{i=1}^m\mathfrak{l}(h(x_i),f(x_i))$时，我们有多大的置信度来保证这个算法的输出的$h$的泛化误差$\mathrm{E}_{x\sim\mathcal{P}}[\mathfrak{l}(h(x),f(x))]$比训练误差不会高出超过$\epsilon$，即&lt;br&gt;$$\mathrm{E}_{x\sim\mathcal{P}}[\mathfrak{l}(h(x),f(x))]-\hat{\mathrm{E}}_{x\in S}[\mathfrak{l}(h(x),f(x))]\leq\epsilon$$&lt;/p&gt;</summary>
    
    
    
    <category term="机器学习" scheme="https://zasdfgbnm.github.io/categories/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
    
    <category term="Rademacher复杂度" scheme="https://zasdfgbnm.github.io/tags/Rademacher%E5%A4%8D%E6%9D%82%E5%BA%A6/"/>
    
    <category term="计算学习理论" scheme="https://zasdfgbnm.github.io/tags/%E8%AE%A1%E7%AE%97%E5%AD%A6%E4%B9%A0%E7%90%86%E8%AE%BA/"/>
    
    <category term="机器学习" scheme="https://zasdfgbnm.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>我与学校SafeConnect软件斗智斗勇的经历</title>
    <link href="https://zasdfgbnm.github.io/2017/07/01/%E6%88%91%E4%B8%8E%E5%AD%A6%E6%A0%A1SafeConnect%E8%BD%AF%E4%BB%B6%E6%96%97%E6%99%BA%E6%96%97%E5%8B%87%E7%9A%84%E7%BB%8F%E5%8E%86/"/>
    <id>https://zasdfgbnm.github.io/2017/07/01/%E6%88%91%E4%B8%8E%E5%AD%A6%E6%A0%A1SafeConnect%E8%BD%AF%E4%BB%B6%E6%96%97%E6%99%BA%E6%96%97%E5%8B%87%E7%9A%84%E7%BB%8F%E5%8E%86/</id>
    <published>2017-07-01T16:53:10.000Z</published>
    <updated>2021-04-04T05:17:59.766Z</updated>
    
    <content type="html"><![CDATA[<p><strong>版权信息：博主就是本文原创作者，但是本文最早发布于<a href="http://www.freebuf.com/news/topnews/125994.html">FreeBuf</a>，并属FreeBuf原创奖励计划，如需转载请联系FreeBuf。</strong></p><p>故事是这样的，本文作者读书的学校，IT部门要求我们如果使用Windows或者Mac OS要连接学校网络的话，必须安装SafeConnect客户端。这个客户端干的事情就是监视你的系统，确保你安装、启用并及时更新杀毒软件，确保你及时更新电脑上的Flash跟Java，确保你不使用P2P软件。然而我一直很不喜欢这种被监视的感觉，感觉这是侵犯了我的人权，况且我很少用P2P来下载盗版内容，偶尔用P2P一直都是用来下载Linux的安装镜像的，这种宁可错杀一千也不放过一个的做法实在是让人难以忍受。再加上学校的IT部门的人非常官僚，自己还没啥技术，曾经有同学找他们备份数据结果数据没备份成他们反而把分区表给搞坏了，这就让我坚定了跟他们斗争到底的想法，刚好也可以打发业余时光。由于SafeConnect客户端不支持Linux系统，同时学校中Linux用户的数量相当多，所以Linux系统不需要安装任何客户端，直接就能访问网络，这是一个关键性的切入点。</p><span id="more"></span><p>要同SafeConnect斗争，有两个切入点，一个是从SafeConnect客户端做手脚，想办法让SafeConnect客户端丧失相应的监测功能，只是傻傻地给他们的服务器汇报一切符合要求，另一个则是从SafeConnect网关的操作系统检测入手，只要能让网关认为我们用的是Linux系统，我们就可以上网了，这样连SafeConnect客户端都不用装了。</p><p>第一个切入点需要对SafeConnect进行逆向工程，搞清楚SafeConnect这些项目的检测机制。逆向工程向来都是费时费力，成本巨大，而且不可以跨平台。不过幸运的是，SafeConnect检测P2P软件的方式经过简单测试作者就发现了端倪：</p><img src="/2017/07/01/%E6%88%91%E4%B8%8E%E5%AD%A6%E6%A0%A1SafeConnect%E8%BD%AF%E4%BB%B6%E6%96%97%E6%99%BA%E6%96%97%E5%8B%87%E7%9A%84%E7%BB%8F%E5%8E%86/p2p-blocked.png" class="" title="打开P2P软件，网络被断，遭到警告"><img src="/2017/07/01/%E6%88%91%E4%B8%8E%E5%AD%A6%E6%A0%A1SafeConnect%E8%BD%AF%E4%BB%B6%E6%96%97%E6%99%BA%E6%96%97%E5%8B%87%E7%9A%84%E7%BB%8F%E5%8E%86/p2p-changeprocname.png" class="" title="把P2P软件的进程名改掉，正常使用未被发现"><img src="/2017/07/01/%E6%88%91%E4%B8%8E%E5%AD%A6%E6%A0%A1SafeConnect%E8%BD%AF%E4%BB%B6%E6%96%97%E6%99%BA%E6%96%97%E5%8B%87%E7%9A%84%E7%BB%8F%E5%8E%86/helloworld-blockedasp2p.png" class="" title="自己写一个Hello World程序并命名为为BitTorrent.exe并打开，网络被断，遭到警告"><p>从上面的测试不难看出，SafeConnect通过列举系统的进程，如果发现黑名单中的进程名，就给你断开网络链接，然后弹出网页警告你说我们检测到你在使用P2P软件，这违反了学校的规定。明白了原理，就可以开干了。既然SafeConnect列举系统进程，那我们就使用进程隐藏技术把P2P软件的进程隐藏起来。</p><p>Windows系统有很多API可以访问系统的进程信息，但是所有这些API在底层最终都会调用<code>NtQuerySystemInformation</code>来获取系统进程信息。这个系统调用总共有四个参数，其中第一个参数<code>SystemInformationClass</code>表示的是你要查询的系统信息的类型，对于列举系统进程而言，这个参数的值应为<code>SystemProcessInformation</code>。第二个参数<code>SystemInformation</code>存储着获得的系统信息，对于列举进程而言，这个参数存储着一个链表，链表的每一项都是一个进程，而要隐藏进程，我们只需要从链表中删除相应的项即可。要篡改系统调用的结果，需要用到DLL注入技术将DLL注入到目标进程的地址空间，然后篡改地址空间中<code>NtQuerySystemInformation</code>函数的的代码加入跳转语句跳转到我们伪造的<code>NtQuerySystemInformation</code>去，这就是DLL注入的整个运行过程。整个DLL注入的过程不需要亲自动手，有现成的<a href="http://easyhook.github.io/">EasyHook库</a>可以实现。</p><p>不多说，贴代码：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;easyhook.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;tchar.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;windows.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;shlwapi.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;winternl.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;ntstatus.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> comment(lib, <span class="meta-string">&quot;EasyHook32.lib&quot;</span>)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> comment(lib, <span class="meta-string">&quot;ntdll.lib&quot;</span> )</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> HIDE_PROCESS_NAME TEXT(<span class="meta-string">&quot;BitTorrent.exe&quot;</span>)</span></span><br><span class="line"></span><br><span class="line"><span class="function">BOOL APIENTRY <span class="title">DllMain</span><span class="params">(HMODULE hModule, DWORD  ul_reason_for_call, LPVOID lpReserved)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">return</span> TRUE;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>我们要Hook的函数位于ntdll.dll，所以在代码中要引用一下ntdll.lib。我们要写的dll的entry不需要做任何事情。接下来就是我们的自定义<code>NtQuerySystemInformation</code>了，在这里我把它命名为<code>myNtQuerySystemInformation</code>：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">NTSTATUS WINAPI <span class="title">myNtQuerySystemInformation</span><span class="params">(SYSTEM_INFORMATION_CLASS SystemInformationClass,</span></span></span><br><span class="line"><span class="function"><span class="params">                                           PVOID SystemInformation, ULONG SystemInformationLength,</span></span></span><br><span class="line"><span class="function"><span class="params">                                           PULONG ReturnLength)</span> </span>&#123;</span><br><span class="line">    NTSTATUS status = <span class="built_in">NtQuerySystemInformation</span>(SystemInformationClass, SystemInformation,</span><br><span class="line">                                               SystemInformationLength, ReturnLength);</span><br><span class="line">    <span class="keyword">if</span> (status != STATUS_SUCCESS)</span><br><span class="line">        <span class="keyword">return</span> status;</span><br><span class="line">    <span class="keyword">if</span> (SystemInformationClass == SystemProcessInformation) &#123;</span><br><span class="line">        PSYSTEM_PROCESS_INFORMATION pcur = <span class="literal">NULL</span>, pprev = <span class="literal">NULL</span>;</span><br><span class="line">        pcur = (PSYSTEM_PROCESS_INFORMATION)SystemInformation;</span><br><span class="line">        <span class="keyword">while</span> (<span class="number">1</span>) &#123;</span><br><span class="line">            <span class="keyword">if</span> (pcur-&gt;Reserved2[<span class="number">1</span>] != <span class="literal">NULL</span>) &#123;</span><br><span class="line">                <span class="keyword">if</span> (_tcscmp((LPTSTR)(pcur-&gt;Reserved2[<span class="number">1</span>]), HIDE_PROCESS_NAME) == <span class="number">0</span>) &#123;</span><br><span class="line">                    <span class="comment">// delete element from linked list</span></span><br><span class="line">                    <span class="keyword">if</span> (pcur-&gt;NextEntryOffset == <span class="number">0</span> &amp;&amp; pprev != <span class="literal">NULL</span>)</span><br><span class="line">                        pprev-&gt;NextEntryOffset = <span class="number">0</span>;</span><br><span class="line">                    <span class="keyword">else</span> <span class="keyword">if</span> (pprev != <span class="literal">NULL</span>)</span><br><span class="line">                        pprev-&gt;NextEntryOffset += pcur-&gt;NextEntryOffset;</span><br><span class="line">                &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                    pprev = pcur;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (pcur-&gt;NextEntryOffset == <span class="number">0</span>)</span><br><span class="line">                <span class="keyword">break</span>;</span><br><span class="line">            pcur = (PSYSTEM_PROCESS_INFORMATION)((ULONG)pcur + pcur-&gt;NextEntryOffset);</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> status;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>正如刚刚介绍的那样，这个函数做的事情就是把要隐藏的进程从链表删掉。同时，EasyHook还要求我们在dll中定义安装函数，这个不复杂，直接从官方教程粘贴代码简单改改就好：</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">extern</span> <span class="string">&quot;C&quot;</span> <span class="keyword">void</span> __declspec(dllexport) <span class="function">__stdcall <span class="title">NativeInjectionEntryPoint</span><span class="params">(REMOTE_ENTRY_INFO* inRemoteInfo)</span></span>;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">void</span> __stdcall <span class="title">NativeInjectionEntryPoint</span><span class="params">(REMOTE_ENTRY_INFO* inRemoteInfo)</span> </span>&#123;</span><br><span class="line">    HOOK_TRACE_INFO hHook = &#123; <span class="literal">NULL</span> &#125;;</span><br><span class="line">    HMODULE ntdll = <span class="built_in">GetModuleHandle</span>(<span class="built_in">TEXT</span>(<span class="string">&quot;ntdll&quot;</span>));</span><br><span class="line">    NTSTATUS result = <span class="built_in">LhInstallHook</span>(<span class="built_in">GetProcAddress</span>(ntdll, <span class="string">&quot;NtQuerySystemInformation&quot;</span>),</span><br><span class="line">                                    myNtQuerySystemInformation,<span class="literal">NULL</span>,&amp;hHook);</span><br><span class="line"></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">FAILED</span>(result))</span><br><span class="line">        std::wcout &lt;&lt; <span class="built_in">RtlGetLastErrorString</span>() &lt;&lt; std::endl;</span><br><span class="line">    <span class="keyword">else</span></span><br><span class="line">        std::wcout &lt;&lt; <span class="string">&quot;NtQuerySystemInformation hook success!&quot;</span> &lt;&lt; std::endl;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// If the threadId in the ACL is set to 0,</span></span><br><span class="line">    <span class="comment">// then internally EasyHook uses GetCurrentThreadId()</span></span><br><span class="line">    ULONG ACLEntries[<span class="number">1</span>] = &#123; <span class="number">0</span> &#125;;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Disable the hook for the provided threadIds, enable for all others</span></span><br><span class="line">    <span class="built_in">LhSetExclusiveACL</span>(ACLEntries, <span class="number">1</span>, &amp;hHook);</span><br><span class="line">    <span class="keyword">return</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>写好了DLL，下一步就是找到目标进程注入进去了。仔细研究一下那个SafeConnect，可以发现他总共有两部分：一个scManager.sys系统服务，以及一个SafeConnectClient.exe进程，实测发现把DLL注入到SafeConnectClient.exe不管用，于是断定负责检索系统进程列表的是scManager.sys。</p><p>下图是用来将我们写的DLL注入到scManager.sys的代码，这里代码做的事情是查找名为scManager.sys的进程，读取进程的PID，然后调用EasyHook的API将我们写的DLL注入到对应的进程中。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;string&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;tchar.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;cstring&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;easyhook.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;psapi.h&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> comment(lib, <span class="meta-string">&quot;EasyHook32.lib&quot;</span>)</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">pragma</span> comment(lib, <span class="meta-string">&quot;psapi.lib&quot;</span> )</span></span><br><span class="line"><span class="keyword">using</span> <span class="keyword">namespace</span> std;</span><br><span class="line"></span><br><span class="line"><span class="meta">#<span class="meta-keyword">define</span> NUM_PROC 1</span></span><br><span class="line">TCHAR * targets[NUM_PROC] = &#123;</span><br><span class="line">    <span class="built_in">TEXT</span>(<span class="string">&quot;scManager.sys&quot;</span>)</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function">DWORD <span class="title">getTargetProcessID</span><span class="params">(TCHAR *target)</span> </span>&#123;</span><br><span class="line">    DWORD aProcesses[<span class="number">1024</span>], cbNeeded, cProcesses;</span><br><span class="line">    <span class="keyword">if</span>(!<span class="built_in">EnumProcesses</span>(aProcesses, <span class="built_in"><span class="keyword">sizeof</span></span>(aProcesses), &amp;cbNeeded))</span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">    cProcesses = cbNeeded / <span class="built_in"><span class="keyword">sizeof</span></span>(DWORD);</span><br><span class="line">    <span class="keyword">for</span> (DWORD i = <span class="number">0</span>; i &lt; cProcesses; i++) &#123;</span><br><span class="line">        <span class="keyword">if</span> (aProcesses[i] != <span class="number">0</span>)&#123;</span><br><span class="line">            TCHAR szProcessName[MAX_PATH] = <span class="built_in">TEXT</span>(<span class="string">&quot;&lt;unknown&gt;&quot;</span>);</span><br><span class="line">            HANDLE hProcess = <span class="built_in">OpenProcess</span>(PROCESS_QUERY_INFORMATION|PROCESS_VM_READ,</span><br><span class="line">                                          FALSE, aProcesses[i]);</span><br><span class="line">            <span class="keyword">if</span> (<span class="literal">NULL</span> != hProcess) &#123;</span><br><span class="line">                HMODULE hMod;</span><br><span class="line">                DWORD cbNeeded;</span><br><span class="line">                <span class="keyword">if</span> (<span class="built_in">EnumProcessModules</span>(hProcess, &amp;hMod, <span class="built_in"><span class="keyword">sizeof</span></span>(hMod),&amp;cbNeeded))</span><br><span class="line">                    <span class="built_in">GetModuleBaseName</span>(hProcess, hMod, szProcessName,<span class="built_in"><span class="keyword">sizeof</span></span>(szProcessName)/<span class="built_in"><span class="keyword">sizeof</span></span>(TCHAR));</span><br><span class="line">                <span class="built_in">CloseHandle</span>(hProcess);</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="keyword">if</span> (_tcscmp(target, szProcessName) == <span class="number">0</span>)</span><br><span class="line">                <span class="keyword">return</span> aProcesses[i];</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span> </span>&#123;</span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; NUM_PROC; i++) &#123;</span><br><span class="line">        DWORD processId = <span class="built_in">getTargetProcessID</span>(targets[i]);</span><br><span class="line">        HMODULE ntdll = <span class="built_in">GetModuleHandle</span>(<span class="built_in">TEXT</span>(<span class="string">&quot;ntdll&quot;</span>));</span><br><span class="line">        std::wcout &lt;&lt; <span class="string">&quot;target func in injector has address &quot;</span></span><br><span class="line">                   &lt;&lt; <span class="built_in">GetProcAddress</span>(ntdll, <span class="string">&quot;NtQuerySystemInformation&quot;</span>) &lt;&lt; std::endl;</span><br><span class="line">        <span class="keyword">if</span> (processId == <span class="number">0</span>) &#123;</span><br><span class="line">            std::wcout &lt;&lt; <span class="string">&quot;Unable to find the process ID for &quot;</span></span><br><span class="line">                       &lt;&lt; targets[i] &lt;&lt; <span class="string">&quot;, please manually input: &quot;</span>;</span><br><span class="line">            std::cin &gt;&gt; processId;</span><br><span class="line">            std::wstring input;</span><br><span class="line">            std::<span class="built_in">getline</span>(std::wcin, input);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">if</span> (processId!=<span class="number">0</span>) &#123;</span><br><span class="line">            NTSTATUS nt = <span class="built_in">RhInjectLibrary</span>(processId, <span class="number">0</span>, EASYHOOK_INJECT_DEFAULT,</span><br><span class="line">                                          <span class="string">L&quot;fuck_safeconnect.dll&quot;</span>, <span class="literal">NULL</span>, <span class="literal">NULL</span>, <span class="number">0</span>);</span><br><span class="line">            <span class="keyword">if</span> (nt != <span class="number">0</span>) &#123;</span><br><span class="line">                <span class="built_in">printf</span>(<span class="string">&quot;RhInjectLibrary failed with error code = %d\n&quot;</span>, nt);</span><br><span class="line">                PWCHAR err = <span class="built_in">RtlGetLastErrorString</span>();</span><br><span class="line">                std::wcout &lt;&lt; err &lt;&lt; <span class="string">&quot;\n&quot;</span>;</span><br><span class="line">            &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">                std::wcout &lt;&lt; <span class="string">&quot;inject success!\n&quot;</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    std::wcout &lt;&lt; <span class="string">&quot;Press Enter to exit&quot;</span>;</span><br><span class="line">    std::wstring input;</span><br><span class="line">    std::<span class="built_in">getline</span>(std::wcin, input);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>由于scManager.sys是个系统服务，单纯的“以管理员身份运行”是无法成功注入的，这时候就需要把注入器提权到SYSTEM用户来进行注入。提权到SYSTEM的操作可以用微软提供的<a href="https://technet.microsoft.com/en-us/sysinternals/pxexec.aspx">PsExec</a>工具来进行。PsExec是个命令行工具，使用PsExec非常简单，只需要<code>psexec –i –s 程序名</code>即可。</p><img src="/2017/07/01/%E6%88%91%E4%B8%8E%E5%AD%A6%E6%A0%A1SafeConnect%E8%BD%AF%E4%BB%B6%E6%96%97%E6%99%BA%E6%96%97%E5%8B%87%E7%9A%84%E7%BB%8F%E5%8E%86/inject-success.png" class="" title="注入成功，这时候再打开BitTorrent就不被断网了"><p>由于逆向工程太过费时费力，笔者并没有在SafeConnect客户端上多费心思，而是转向了第二种方法：欺骗SafeConnect的服务器端的操作系统检测功能。要检测连进来的设备的操作系统，一种常用的方法是TCP Fingerprinting，此外，还可以运用深度包检测技术读取设备发送的数据包的内容，推测设备的类型。只需要针对这几项进行伪装，然后观察SafeConnect的行为就可以推测SafeConnect检测用户操作系统的方式。</p><p>经过一番实验，推测SafeConnect服务器的工作原理如下：客户端新设备连进网络的时候，他们是直接不给你互联网接入的。但是他们会监测你的的外出http流量，从http流量中读取User-Agent中的操作系统信息。</p><p>如果发现是他们SafeConnect客户端不支持的系统，比如Linux，iOS，android之类，就把你这个IP地址限制放开。如果是客户端支持的系统，比如Windows，Mac OS，并且你的SafeConnect已经安装了，那么SafeConnect会跟他们服务器通讯把你放开，如果你还没安装SafeConnect，那么就把你跳转到相关页面让你装SafeConnect。</p><p>明白了这一点，解决方法自然就来了：给浏览器安装可以更改User-Agent的插件，把User-Agent里面的操作系统信息改成Linux即可，这样在访问网络的时候，SafeConnect的服务器就会误以为你是Linux系统了。通过给浏览器更改User-Agent，几乎可以完美躲过SafeConnect的法眼，然而美中不足的是如果用多个浏览器，还需要挨个安装插件更改User-Agent，同时有的网站会检测浏览器的版本，如果发现浏览器版本过就会提示不支持需要更新，这样就需要不断地根据浏览器更新手工更改插件里的User-Agent的值。还有一点麻烦的地方是，新设备接入的时候还需要设置新的设备。对我来说有没有设置一个新设备自然很简单，但是经常有时候有客人来，用Windows设备没装SafeConnect就上网导致我家整个路由器被封。有没有简单快捷的方法自动让所有连接到路由器的设备都不受SafeConnect的影响呢？这时候就想到了bettercap。</p><p>Bettercap是一个模块化的开源的中间人攻击框架。使用bettercap只需要几行代码就可以实现劫持整个局域网的流量并把其中的HTTP流量的User-Agent改掉。这样的话，只要家里有客人来，我们就可以打开bettercap，自动把客人的User-Agent改掉，防止客人上网导致家里整个路由器都被断。在局域网中实现中间人攻击的一种常见方法是ARP欺骗。ARP欺骗攻击发起方通过不断向受害者发送伪造的ARP数据包，让受害者误以为自己是网关，这样受害者本来想送到网关的数据包就会错误地送给攻击方，攻击方进而可以篡改数据然后送给真正的网关。要使用bettercap实现User-Agent的伪造，首先需要写一个bettercap的代理模块。Bettercap的代理模块写起来非常简单， <a href="https://github.com/evilsocket/bettercap-proxy-modules">这里有很多示例模块</a>，文档在<a href="https://www.bettercap.org/docs/proxying/http.html">这里</a>。我写的模块代码如下:</p><figure class="highlight ruby"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Osfuscate</span> &lt; BetterCap::Proxy::<span class="title">HTTP::Module</span></span></span><br><span class="line">    meta(</span><br><span class="line">        <span class="string">&#x27;Name&#x27;</span>        =&gt; <span class="string">&#x27;Osfuscate&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Description&#x27;</span> =&gt; <span class="string">&#x27;Change the operating system in User-Agent string to Linux.&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Version&#x27;</span>     =&gt; <span class="string">&#x27;1.0.0&#x27;</span>,</span><br><span class="line">        <span class="string">&#x27;Author&#x27;</span>      =&gt; <span class="string">&quot;zasdfgbnm&quot;</span>,</span><br><span class="line">        <span class="string">&#x27;License&#x27;</span>     =&gt; <span class="string">&#x27;GPL3&#x27;</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">on_pre_request</span><span class="params">( request )</span></span></span><br><span class="line">        request[<span class="string">&#x27;User-Agent&#x27;</span>].gsub!( <span class="regexp">/\(Windows.*?\)/</span>, <span class="string">&#x27;(X11; Linux x86_64)&#x27;</span> )</span><br><span class="line">        request[<span class="string">&#x27;User-Agent&#x27;</span>].gsub!( <span class="regexp">/\(Macintosh.*?\)/</span>, <span class="string">&#x27;(X11; Linux x86_64)&#x27;</span> )</span><br><span class="line">        <span class="comment"># return nil to tell the streamer that this module didn&#x27;t do the request</span></span><br><span class="line">        <span class="comment"># and therefore the request should be done by the streamer.</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">nil</span></span><br><span class="line">    <span class="keyword">end</span></span><br><span class="line"><span class="keyword">end</span></span><br></pre></td></tr></table></figure><p>其中<code>on_pre_request</code>函数在请求发生前会被调用，我们只需要在这里把请求中User-Agent的信息中的操作系统给替换成Linux就行了。这里需要注意的是，在函数的结尾需要返回<code>nil</code>，用来告诉bettercap请求还没有被执行，这样bettercap才会去执行请求。</p><p>有了这个代理模块，要想部署，只需要执行<code>bettercap–proxy-module 模块文件名</code>命令就可以了，不需要手动配置iptables这些东西, 非常简单快捷。上图：</p><img src="/2017/07/01/%E6%88%91%E4%B8%8E%E5%AD%A6%E6%A0%A1SafeConnect%E8%BD%AF%E4%BB%B6%E6%96%97%E6%99%BA%E6%96%97%E5%8B%87%E7%9A%84%E7%BB%8F%E5%8E%86/ua-windows.png" class="" title="这是局域网内的一台Windows机器User-Agent中的操作系统信息"><img src="/2017/07/01/%E6%88%91%E4%B8%8E%E5%AD%A6%E6%A0%A1SafeConnect%E8%BD%AF%E4%BB%B6%E6%96%97%E6%99%BA%E6%96%97%E5%8B%87%E7%9A%84%E7%BB%8F%E5%8E%86/bettercap.png" class="" title="这是bettercap软件的运行界面"><img src="/2017/07/01/%E6%88%91%E4%B8%8E%E5%AD%A6%E6%A0%A1SafeConnect%E8%BD%AF%E4%BB%B6%E6%96%97%E6%99%BA%E6%96%97%E5%8B%87%E7%9A%84%E7%BB%8F%E5%8E%86/ua-changed.png" class="" title="这是bettercap运行时局域网内这台Windows机器的User-Agent中的操作系统信息"><p>从图中可见User-Agent信息已经被成功修改掉了，大功告成。</p><p>最后说再来一句，这个工作其实稳定的解决方法是直接在路由器跟网口中间加一个电脑用来做网关来负责User-Agent的修改，这样网络会比ARP欺骗的解决方案要稳定好多。这里之所以选择ARP欺骗的方案主要是因为简单快速不需要拔网线不需要设置网关。另外，如果你已经有一台已经设置好了的网关服务器，bettercap同样可以用来完成我们想要的任务，只需要在网关服务器上执行如下命令</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bettercap --no-spoofing --no-discovery --proxy-module 模块名</span><br></pre></td></tr></table></figure><p>程序执行的界面类似，这里就不截图了。</p>]]></content>
    
    
    <summary type="html">&lt;p&gt;&lt;strong&gt;版权信息：博主就是本文原创作者，但是本文最早发布于&lt;a href=&quot;http://www.freebuf.com/news/topnews/125994.html&quot;&gt;FreeBuf&lt;/a&gt;，并属FreeBuf原创奖励计划，如需转载请联系FreeBuf。&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;故事是这样的，本文作者读书的学校，IT部门要求我们如果使用Windows或者Mac OS要连接学校网络的话，必须安装SafeConnect客户端。这个客户端干的事情就是监视你的系统，确保你安装、启用并及时更新杀毒软件，确保你及时更新电脑上的Flash跟Java，确保你不使用P2P软件。然而我一直很不喜欢这种被监视的感觉，感觉这是侵犯了我的人权，况且我很少用P2P来下载盗版内容，偶尔用P2P一直都是用来下载Linux的安装镜像的，这种宁可错杀一千也不放过一个的做法实在是让人难以忍受。再加上学校的IT部门的人非常官僚，自己还没啥技术，曾经有同学找他们备份数据结果数据没备份成他们反而把分区表给搞坏了，这就让我坚定了跟他们斗争到底的想法，刚好也可以打发业余时光。由于SafeConnect客户端不支持Linux系统，同时学校中Linux用户的数量相当多，所以Linux系统不需要安装任何客户端，直接就能访问网络，这是一个关键性的切入点。&lt;/p&gt;</summary>
    
    
    
    <category term="信息安全" scheme="https://zasdfgbnm.github.io/categories/%E4%BF%A1%E6%81%AF%E5%AE%89%E5%85%A8/"/>
    
    
    <category term="SafeConnect" scheme="https://zasdfgbnm.github.io/tags/SafeConnect/"/>
    
    <category term="P2P" scheme="https://zasdfgbnm.github.io/tags/P2P/"/>
    
    <category term="DLL注入" scheme="https://zasdfgbnm.github.io/tags/DLL%E6%B3%A8%E5%85%A5/"/>
    
    <category term="中间人攻击" scheme="https://zasdfgbnm.github.io/tags/%E4%B8%AD%E9%97%B4%E4%BA%BA%E6%94%BB%E5%87%BB/"/>
    
    <category term="ARP欺骗" scheme="https://zasdfgbnm.github.io/tags/ARP%E6%AC%BA%E9%AA%97/"/>
    
    <category term="逆向工程" scheme="https://zasdfgbnm.github.io/tags/%E9%80%86%E5%90%91%E5%B7%A5%E7%A8%8B/"/>
    
    <category term="Hook" scheme="https://zasdfgbnm.github.io/tags/Hook/"/>
    
    <category term="User-Agent" scheme="https://zasdfgbnm.github.io/tags/User-Agent/"/>
    
    <category term="bettercap" scheme="https://zasdfgbnm.github.io/tags/bettercap/"/>
    
  </entry>
  
  <entry>
    <title>能当主力，能入虚拟机，还能随时打包带走，Linux就是这么强大</title>
    <link href="https://zasdfgbnm.github.io/2017/06/29/%E8%83%BD%E5%BD%93%E4%B8%BB%E5%8A%9B%EF%BC%8C%E8%83%BD%E5%85%A5%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%8C%E8%BF%98%E8%83%BD%E9%9A%8F%E6%97%B6%E6%89%93%E5%8C%85%E5%B8%A6%E8%B5%B0%EF%BC%8CLinux%E5%B0%B1%E6%98%AF%E8%BF%99%E4%B9%88%E5%BC%BA%E5%A4%A7/"/>
    <id>https://zasdfgbnm.github.io/2017/06/29/%E8%83%BD%E5%BD%93%E4%B8%BB%E5%8A%9B%EF%BC%8C%E8%83%BD%E5%85%A5%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%8C%E8%BF%98%E8%83%BD%E9%9A%8F%E6%97%B6%E6%89%93%E5%8C%85%E5%B8%A6%E8%B5%B0%EF%BC%8CLinux%E5%B0%B1%E6%98%AF%E8%BF%99%E4%B9%88%E5%BC%BA%E5%A4%A7/</id>
    <published>2017-06-29T14:52:54.000Z</published>
    <updated>2021-04-04T05:17:59.799Z</updated>
    
    <content type="html"><![CDATA[<p>__更新日志__：<br>2017-07-18 增加了新的一章：无盘系统，将多处不当使用的术语“rootfs”替换为更贴切的“root”</p><p>===================</p><p>这里介绍一下自己管理自己的Linux桌面的一点经验吧，我觉得还是有不少可取之处的。先来说一下大多数人管理Linux桌面的方法有哪些不方便的地方吧：</p><ul><li>买新电脑了，又得在新电脑上安装Linux，安装各种软件，各种库，各种开发环境，配置各种服务，真麻烦。</li><li>最近一直在用电脑A，干了好多事情安装了好多软件，也配置了不少开发环境跟各种服务，然而处于某种原因，我又要开始使用好久没用过的电脑B了，难道我要把在A上的做的各种配置在B上再重新做一遍？</li><li>在Windows下做着PPT呢，发现需要调出自己之前的程序，然后根据若干组输入跑几个结果画张图好插到PPT里，然而这个程序是在Linux下写的，编译等的过程也严重依赖自己用的Linux环境，重启进Linux拿到结果再回Windows太不方便，想在Windows下配置好环境把自己的程序跑通更不容易。</li><li>要对系统安装某个软件，或者进行一些比较危险的更新操作（要知道Archlinux滚动更新滚挂了太正常了），担心把系统搞挂了，系统备份又实在太麻烦，要真挂了，系统恢复起来更麻烦。</li><li>我一直用Archlinux做主力，然而最近做的某件事情要用某个软件，这个软件官方只给了Ubuntu上的安装方式，Archlinux里面没有相应的包，在Archlinux上手动安装也太不方便。装个Ubuntu，然后暂时用几天Ubuntu吧，也是够折腾的。更何况有时候只是想用一小下而已，怎样才能最小化自己在折腾上浪费的时间呢？</li><li>有的软件官方软件仓库里面没有，而<code>make install</code>的话则会在系统中安装上不被包管理器所管理的文件，将来卸载也不方便，我还是更希望所有的文件都在一个包管理器中管理的。</li><li>听说新版本内核引入了某个牛逼的东西？我就想快速测试一下玩玩，我电脑还有计算在跑着呢，我可不想重启，那就只能用虚拟机尝试了。而且，一定要快速，我可不想为此特地装一个虚拟机。</li></ul><p>上述的这些不方便之处是可以通过自己管理系统时的一些技巧来克服的，本文目的就是来介绍一下这些技巧。通过这些技巧，我们实现的功能是：一台机器上，可以同时安装Windows跟若干Linux系统，Windows下可以通过虚拟机来运行位于本地磁盘的这些Linux系统，而这些Linux系统下也可以通过容器或者虚拟机的方式互相运行。并且这些系统可以非常方便地备份跟删除，也可以随时创建以及运行快照。并且这些Linux系统可以随时打包带走，只需要经过很少的修改，就能直接在U盘或者其他机器上运行。如果要换电脑，或者新装一台电脑，也不需要重新安装系统，只需要把已有的系统同步到新电脑就行。这也正是这篇文章标题的意思。</p><span id="more"></span><p>为了行文的方便，我们假定读者有一台全新的机器，硬盘还没分区，也还没装任何系统。如果已经什么都装好了，而只是想迁移到我这种管理方式的话，我相信读者能够判断这个安装教程中哪些步骤是需要做的哪些步骤是不需要做的。 另外需要注意的是这不是一个手把手的一步一步的教程，中间有一些显然的步骤我就略去不写了，所以希望读者不要照着文章里的的命令不加思考地一条一条粘贴运行，而是要搞明白这些命令的目的是什么，然后根据你自己的情况来做相应的修改。</p><h1 id="分区与子卷"><a href="#分区与子卷" class="headerlink" title="分区与子卷"></a>分区与子卷</h1><p>具体怎么分区我就不说了，随便找个livecd启动进去，然后找到你自己最喜欢的分区程序，按照你的喜好把区分了就好。注意别忘了EFI分区。我这里需要说的是，分区的时候，不论有多少个发行版要安装，总共只给Linux划分两个分区：一个是swap，另一个则是一个大的btrfs分区。那个btrfs分区里面装着所有的文件，包括用户的个人数据，以及所有发行版的rootfs。这两个分区在格式化的时候，一定要给他们取Label，这么做的好处接下来我们很快就会看到。我的习惯是，swap分区的Label我就叫他“swap”，而那个btrfs分区我则叫他“linux”。创建好分区以后，如果格式化工作是在图形的分区管理程序下完成的，那么指定Label是个非常简单的工作，右键属性里面就有。如果是使用命令行工具格式化分区的，则可以使用<code>-L label</code>选项来指定label，比如：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">mkswap -L swap /dev/sdb4</span><br><span class="line">mkfs.btrfs -L linux /dev/nvme0n1p4</span><br></pre></td></tr></table></figure><p>那个大的btrfs分区上的不同内容是通过btrfs的子卷来管理的，具体来讲就是为自己想安装的每个不同的Linux系统来创建一个单独的子卷。 比如说我电脑上同时安装了Archlinux、Ubuntu、Kali、Debian四个系统，那么的btrfs分区里面就有四个子卷：archlinux、ubuntu、kali、debian。 子卷的创建可以通过<code>btrfs subvolume create &lt;name&gt;</code>命令完成，比如说要创建我这五个子卷，需要做的事情就是：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">mount /dev/disk/by-label/linux /mnt</span><br><span class="line"><span class="built_in">cd</span> /mnt</span><br><span class="line">btrfs subvolume create archlinux</span><br><span class="line">btrfs subvolume create ubuntu</span><br><span class="line">btrfs subvolume create kali</span><br><span class="line">btrfs subvolume create debian</span><br></pre></td></tr></table></figure><p>如果你只想装一个发行版，比如archlinux，那么只需要archlinux子卷就够了。另外，如果你想把用户数据单独放在一个子卷里，也是完全可以的，不过这里不推荐多个Linux系统共享同一个家目录，因为不同系统上安装的软件不同，同样的软件版本也不相同，即使版本相同，不同发行版也可能应用了不同的patch，这就导致在一个系统上用户家目录里面产生的配置文件，在另一个系统里无法兼容，产生奇怪的行为。</p><h1 id="系统安装"><a href="#系统安装" class="headerlink" title="系统安装"></a>系统安装</h1><p>创建好分区与子卷，下一步就是安装操作系统了。这里分两种情况来讲：第一种情况是你想要全新安装一个Linux操作系统；第二种情况则是你已经有了某个可用的操作系统了，而只是想把这个操作系统迁移到文章所说的管理方式上。</p><h2 id="全新安装"><a href="#全新安装" class="headerlink" title="全新安装"></a>全新安装</h2><p>如果想要全新安装一个操作系统，安装方式上，作者只推荐纯手工安装，而不是用官方给的安装光盘不断点着“下一步”来进行安装。这么做是为了防止官方安装程序做一些我们不想让他做的事情，比如说自动安装grub。对于Archlinux跟Gentoo来讲，唯一的安装方法就是纯手工安装，所以只要按照官方的教程来就好了。对于deb系的系统，可以使用debootstrap程序。对于其他的发行版，可能会找不到手工安装的教程，这时候可以新建一个虚拟机，在虚拟机中使用官方的安装程序不断点击“下一步”来完成安装，然后按照下一节即将介绍的现有系统迁移教程把系统从虚拟机中迁移到现实机器上；除此之外，读者还可以找到发行版官方提供的安装程序的源代码阅读一下，看明白这些安装程序都在干啥，就知道怎么手工安装了，安装程序的代码还是相对简单的，有时间的读者不妨尝试一下。下面来具体说一下安装过程，这里只介绍Archlinux跟deb系。如果有多个Linux系统需要安装，建议先安装并完全配置好其中一个，让这个系统处于可用并且方便使用的状态，然后再在这个可用的系统中安装其他系统。这里我们假设读者已经完成了分区，创建了对应的子卷，并且把那个btrfs分区挂载在了<code>/mnt</code>上。</p><h3 id="Archlinux的手动安装"><a href="#Archlinux的手动安装" class="headerlink" title="Archlinux的手动安装"></a>Archlinux的手动安装</h3><p>Archlinux的手动安装主要还是看<a href="https://wiki.archlinux.org/index.php/Installation_guide">官方教程</a>。分区的时候注意按照上文介绍的方法。非常关键的<code>pacstrap</code>那一步注意使用如下命令安装到子卷里，而不是整个btrfs分区中:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pacstrap -d /mnt/archlinux base</span><br></pre></td></tr></table></figure><p>至于fstab，就不要使用教程中的方法来生成了，我们的管理方式比较非常规，还是自己写fstab比较好。bootloader也要按照本文下文说的方式来安装跟配置。至于其他的设置键盘、设置网络、设置时区等操作，照着教程来就行。</p><h3 id="deb系的手动安装"><a href="#deb系的手动安装" class="headerlink" title="deb系的手动安装"></a>deb系的手动安装</h3><p>deb系的系统网上找到的教程都是使用发行版自带的安装程序的教程，并没有像Archlinux那么详细的手动安装教程。因为我们想要手动安装，所以我们就不参照网上的deb系的安装教程了。但是我们还是有教程可以参照的，那就是Archlinux的wiki里面<a href="https://wiki.archlinux.org/index.php/Systemd-nspawn#Create_a_Debian_or_Ubuntu_environment">关于systemd-nspawn的教程</a>，这个教程里面有一节介绍如何使用debootstrap安装Debian或者Ubuntu。具体安装过程请参照上述教程，其中关键命令如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">debootstrap --arch amd64 zesty /mnt/ubuntu http://archive.ubuntu.com/ubuntu/</span><br></pre></td></tr></table></figure><p>值得一提的是，我们安装deb系的发行版并不一定要使用deb系的livecd，任何能够安装debootstrap程序的livecd都是可以的。比如说我们完全可以使用Archlinux的livecd来启动，然后安装debootstrap并通过debootstrap来安装Ubuntu。</p><p>注意的是，debootstrap并不会像官方安装程序那样安装一个完整齐全开袋即食的操作系统，而只是安装最基本的软件包，读者需要根据自己的情况单独安装桌面环境等的软件包。同时fstab跟bootloader也要根据本文的方法自己配置。</p><h2 id="现有系统迁移"><a href="#现有系统迁移" class="headerlink" title="现有系统迁移"></a>现有系统迁移</h2><p>Linux系统的迁移其实非常简单，无非就是把根目录（下文称作root）的文件全都拷贝到目的地即可。不过这个过程虽然看似简单，但是还是有一些需要注意的东西的。比如说对于符号链接，如果处理不当，则会不小心把符号链接搞成实体文件，这就不好了。再比如说，文件的权限等元数据的问题，如果处理不当，可能会导致拷贝过程中元数据的丢失。这两种问题，都有可能会导致系统不能正常运行。还有一个需要注意的地方就是，正常运行的操作系统里，会有/proc、/dev等目录，这些目录都是单独的虚拟文件系统，是不需要拷贝的，也是无法拷贝的。</p><p>我们现在假设用户想要把位于A的Ubuntu系统迁移到目标子卷<code>/mnt/ubuntu</code>去。其中，A可能位于虚拟机中，可能位于另一台电脑上，也可能位于本地磁盘。对系统进行迁移，大方向上来讲，需要做的有两步：</p><ol><li>挂载相应分区，设置ssh，保证我们能够访问到A。</li><li>使用<code>rsync</code>或者<code>btrfs send</code>命令来把数据从A发送到目标子卷中去。</li></ol><p>第一步具体怎么做就不说了，分三种情况简单几句话概括一下怎么做：</p><ul><li>如果只是一个分区的话，mount就可以了</li><li>如果是另一台机器，把那台机器配置好ssh，保证root用户可以用ssh访问</li><li>如果是虚拟机，有两种选择，一种是想办法挂载虚拟机的磁盘镜像，然后像情况1那样处理；另一种则是配置好网络跟ssh，像情况2那样处理。具体采取哪种措施请读者根据自己的情况来自行决定。</li></ul><p>第二步我们来分别介绍<code>rsync</code>跟<code>btrfs send</code>两种方法。</p><p><code>rsync</code>的方法<a href="https://wiki.archlinux.org/index.php/full_system_backup_with_rsync">这里有教程</a>可以参照。我们现在假设A的ip地址为<code>192.168.88.3</code>。则只需执行如下命令即可：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">rsync -aAXv --exclude=&#123;<span class="string">&quot;/dev/*&quot;</span>,<span class="string">&quot;/proc/*&quot;</span>,<span class="string">&quot;/sys/*&quot;</span>,<span class="string">&quot;/tmp/*&quot;</span>,<span class="string">&quot;/run/*&quot;</span>,<span class="string">&quot;/mnt/*&quot;</span>,<span class="string">&quot;/media/*&quot;</span>,<span class="string">&quot;/lost+found&quot;</span>&#125; root@192.168.88.3:/ /mnt/ubuntu</span><br></pre></td></tr></table></figure><p>这里提醒读者注意自己系统上是否还有其他不想要同步的文件，记得一并排除掉。</p><p><code>btrfs send</code>只在A的root也是btrfs的情况下才能使用。<a href="https://btrfs.wiki.kernel.org/index.php/Incremental_Backup">这个方法的教程参见这里</a>。首先需要做的是在A机器上给root创建一个只读快照（注意下面命令是在A机器上执行的）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">btrfs subvolume snapshot -r / /ubuntu</span><br></pre></td></tr></table></figure><p>注意上面命令中快照的名字要和目标子卷的名字相同，这样可以省去将来改名的麻烦。然后就可以使用<code>btrfs send</code>命令来把快照/ubuntu中的内容发送到目的地了，在这之前我们需要暂时删除我们分区的时候创建的ubuntu子卷，这个子卷会在接收过程中自动重新创建：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">btrfs subvolume delete /mnt/ubuntu</span><br><span class="line">ssh root@192.168.88.3 btrfs send /ubuntu | btrfs receive /mnt</span><br></pre></td></tr></table></figure><p>最后在A机器上把刚刚创建的快照删除就可以了</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">btrfs subvolume delete /ubuntu</span><br></pre></td></tr></table></figure><h1 id="bootloader与fstab"><a href="#bootloader与fstab" class="headerlink" title="bootloader与fstab"></a>bootloader与fstab</h1><p>系统装好了，我们的fstab还没设置，启动管理器也还没安装配置。下面来讲讲怎么配置这两样东西。我们之前说过一定要给分区取一个Label，玄机在这里。如何在虚拟机中直接运行本地磁盘上安装的Linux，以及如何能把一个系统直接进行打包带走而不需要更改太多配置，关键也在这里。</p><h2 id="fstab"><a href="#fstab" class="headerlink" title="fstab"></a>fstab</h2><p>先来说说fstab，fstab总共有五列，分别为fs、mountpoint、type、opts跟dump/pass。这五列分别为什么意思、以及fstab该怎么填，网上一查便知，在此不再赘述。这里只说我们需要做的跟常规不一样的地方。</p><p>第一个要注意的事情是，大家在填写fstab的时候，通常喜欢在fs那一列填写类似<code>/dev/sda4</code>或者<code>UUID=d5acc217-d524-4a2d-a937-bad945a047b2</code>，而在这里这样是不行的，这里我们填写的是形如<code>/dev/disk/by-label/linux</code>这样的东西。也就是说，我们的fstab里面是通过分区的Label来找分区的。这么做的原因是，我们希望我们的root不光能在这台机器上启动，还希望它能在虚拟机的环境中，或者当我们把root打包带走同步到别的机器上的时候，也能正常启动。在这台机器上root所在的分区叫做<code>/dev/sda4</code>，在别的机器上或者虚拟机里就不一定还叫<code>/dev/sda4</code>了。但是我们只要遵守自己的命名规则，所有机器上的这些分区我们都取相同的Label，那么我们的fstab就是放之四海而皆准的，不需要为不同的环境而更改。</p><p>第二个需要注意的问题是，不要填写root的条目。这种做法跟通常发行版或者其他用户的默认做法是非常不相同的。为了理解这一点，先来说说Linux系统的启动过程。通常情况下，Linux启动的时候，首先由bootloader把内核装载到内存，并向内核传递参数告诉内核root的位置。接下来内核就会根据传递的参数，以只读方式挂载root，并执行root中的init程序。init程序会调用相应的初始化程序执行各种初始化操作。其中一项初始化操作就是根据fstab的配置，来重新以读写方式挂载root，并且挂载fstab里面配置的其他各个分区到指定位置。明白了Linux启动的过程，我们就知道，fstab里面的root那一行其实不是必须的。删掉了root那一行，我们只需要通过修改bootloader传递给内核的参数，就可以告诉内核直接以读写而不是只读的方式挂载root。</p><p>那么，我们在写fstab的时候不写root那一项有啥好处呢？好处就是，我们不仅希望我们的系统能在裸机上用，还希望我们的系统能在虚拟机上用。在下文设置qemu虚拟机的时候，我们会以virtfs的方式把我们的子卷传递给虚拟机，这个时候root就已经不再是<code>/dev/disk/by-label/linux</code>了，如果我们把root的挂载方式硬编码到fstab里面，那么会导致init程序的失败，进而无法启动。</p><p>另外有一点值得一提的小技巧是，很多时候我们还有别的一些个分区想要自动挂载。问题在于，这些分区在虚拟机环境中，并不一定是存在的，这就会导致启动的时候由于无法挂载而启动失败。其实系统的设计者早就考虑到这个问题了。如果你不希望fstab中的某些条目自动挂载，在选项里面增加<code>noauto</code>即可。如果你希望一些条目自动挂载，但是这些条目不是那么重要，即使挂载失败也不希望这些条目导致启动失败，可以在选项中增加<code>nofail</code>。这两个选项真的是给我们的系统管理工作提供了非常大的方便。比如说我们可能会在fstab中增加<code>/dev/disk/by-label/swap</code>的条目，以便开机自动将这个分区设置为交换分区供系统使用。然而后面我们会看到，我们设置虚拟机的时候，这个分区在虚拟机环境下，并不一定是可用的。这种情况下，我们希望系统在找不到这个分区的时候直接忽略错误不用swap便是，而不是报错拒绝启动。</p><p>说了这么多，直接贴一个fstab的例子好了：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tmpfs                  &#x2F;tmptmpfsdefaults0 0</span><br><span class="line">&#x2F;dev&#x2F;disk&#x2F;by-label&#x2F;swapnoneswapdefaults,nofail0 0</span><br></pre></td></tr></table></figure><h2 id="bootloader"><a href="#bootloader" class="headerlink" title="bootloader"></a>bootloader</h2><p>再来说说启动管理器，这里作者推荐的启动管理器是refind，<a href="http://www.rodsbooks.com/refind/installing.html">安装教程官网有</a>，在此不赘述。这里只讲一下启动项怎么写。先贴示例代码：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">menuentry archlinux &#123;</span><br><span class="line">icon EFI&#x2F;refind&#x2F;icons&#x2F;os_arch.png</span><br><span class="line">volume linux</span><br><span class="line">loader archlinux&#x2F;boot&#x2F;vmlinuz-linux</span><br><span class="line">options &quot;root&#x3D;&#x2F;dev&#x2F;disk&#x2F;by-label&#x2F;linux rootflags&#x3D;subvol&#x3D;archlinux rw&quot;</span><br><span class="line">initrd archlinux&#x2F;boot&#x2F;initramfs-linux.img</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>其中第三行的volume用来指定内核存放的分区，此分区可以通过多种方式来指定，比如通过分区的GUID，但是对我们来说最重要的是可以通过文件系统的Label来指定。我们的root分区Label是”linux”，所以这一行写作<code>volume linux</code>。</p><p>接下来就是指定内核位置、内核参数跟initramfs的位置了。其中loader用来指定内核位置，options用来指定内核参数，initrd则用来指定initramfs的位置。示例中的是Archlinux系统，内核是archlinux子卷中的<code>boot/vmlinuz-linux</code>文件，所以写作<code>loader archlinux/boot/vmlinuz-linux</code>。类似，initrd那一行则写作<code>initrd archlinux/boot/initramfs-linux.img</code>。至于内核参数，<code>root=/dev/disk/by-label/linux</code>告诉内核我们的root所在的分区，<code>rootflags=subvol=archlinux</code>告诉内核挂载名为archlinux的子卷，<code>rw</code>则告诉内核以读写方式挂载。对于Ubuntu系统，这三行应该写作：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">loader ubuntu&#x2F;vmlinuz</span><br><span class="line">options &quot;root&#x3D;&#x2F;dev&#x2F;disk&#x2F;by-label&#x2F;linux rootflags&#x3D;subvol&#x3D;ubuntu rw&quot;</span><br><span class="line">initrd ubuntu&#x2F;initrd.img</span><br></pre></td></tr></table></figure><p>细心的读者可能已经发现，我们的refind的配置文件中在指定分区的时候用的全是他们的Label，这就保证了这个配置文件的普适性，换台电脑，只要你用同样的管理方式，同样的命名习惯，配置文件里面的东西动都不用动，直接拷贝过去就行。</p><h1 id="系统的备份与恢复以及快照的应用"><a href="#系统的备份与恢复以及快照的应用" class="headerlink" title="系统的备份与恢复以及快照的应用"></a>系统的备份与恢复以及快照的应用</h1><p>由于使用了btrfs的动态卷，所以备份恢复工作做起来非常简单。备份系统只需要创建快照即可：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /mnt</span><br><span class="line">btrfs subvolume snapshot archlinux backup</span><br></pre></td></tr></table></figure><p>至于恢复，其实我们根本不需要恢复，直接把快照作为root用就行。我们只需要去refind的配置文件里面，把相应的启动项改改即可。比如说对于Archlinux而言，只需要改成：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">menuentry archlinux &#123;</span><br><span class="line">icon EFI&#x2F;refind&#x2F;icons&#x2F;os_arch.png</span><br><span class="line">volume linux</span><br><span class="line">loader backup&#x2F;boot&#x2F;vmlinuz-linux</span><br><span class="line">options &quot;root&#x3D;&#x2F;dev&#x2F;disk&#x2F;by-label&#x2F;linux rootflags&#x3D;subvol&#x3D;backup rw&quot;</span><br><span class="line">initrd backup&#x2F;boot&#x2F;initramfs-linux.img</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>如果有强迫症，觉得root名字不叫archlinux很不爽，那其实改名也很简单:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /mnt</span><br><span class="line">btrfs subvolume delete archlinux</span><br><span class="line">btrfs subvolume snapshot backup archlinux</span><br></pre></td></tr></table></figure><p>其实，btrfs的快照功能不仅可以用来备份与恢复系统，还有很多非常灵活的运用的。比如说我想在系统里面安装一个巨大而又混乱的软件，这个软件我只想用几天干一件事情，干完这件事情我就不想用了。问题是，这个软件在官方的软件仓库并没有，要安装，我只能使用软件提供的安装程序来安装，然而软件并没有提供卸载程序，或者卸载程序卸载的很不彻底，会在系统残留垃圾。我想用这软件，然而又不想脏了我的系统，这该怎么办？很简单：创建一个快照，新增加一条以快照为root的启动项，要用软件了就启动到快照中去，用完这个软件以后把快照删除即可。再比如说，我想要搞个虚拟机跟实体机一起来测试某个东西（比如说测试某些网络协议、测试某些集群管理软件等），这个时候我根本没必要重新用安装光盘去装一个虚拟机，只需要创建一个快照，然后把快照作为虚拟机的root启动即可，具体方法下文会介绍，在此不多说。当然，快照的应用还远远不止我说的这些，更多好玩的应用还待读者自己探索。</p><h1 id="Windows下访问Linux"><a href="#Windows下访问Linux" class="headerlink" title="Windows下访问Linux"></a>Windows下访问Linux</h1><p>从文章的刚开头我们就说，有时候我们是有在Windows下运行本地安装的Linux的需求的。这个需求可以通过VirtualBox来满足，只需要在VirtualBox中使用本地磁盘来作虚拟磁盘即可。说起来简单，但是实现起来还是需要折腾一下子的。</p><p>首先我们需要新建一个虚拟机，具体过程不多说，一路“下一步”就行了，唯一需要注意的是，在创建虚拟磁盘的那一步，选择“不添加虚拟硬盘”：</p><img src="/2017/06/29/%E8%83%BD%E5%BD%93%E4%B8%BB%E5%8A%9B%EF%BC%8C%E8%83%BD%E5%85%A5%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%8C%E8%BF%98%E8%83%BD%E9%9A%8F%E6%97%B6%E6%89%93%E5%8C%85%E5%B8%A6%E8%B5%B0%EF%BC%8CLinux%E5%B0%B1%E6%98%AF%E8%BF%99%E4%B9%88%E5%BC%BA%E5%A4%A7/virt_hdd.png" class=""><p>这里我的虚拟机取名为“Linux”。创建完虚拟机了以后，就需要把本地磁盘设置为虚拟磁盘了。VirtualBox只能通过命令来做这件事情，<a href="http://www.serverwatch.com/server-tutorials/using-a-physical-hard-drive-with-a-virtualbox-vm.html">教程可以在这里找到</a>。首先要做的是寻找我们安装Linux的磁盘的编号，这个可以在系统自带的磁盘管理程序中找到，在我的机器上这个磁盘编号为2：</p><img src="/2017/06/29/%E8%83%BD%E5%BD%93%E4%B8%BB%E5%8A%9B%EF%BC%8C%E8%83%BD%E5%85%A5%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%8C%E8%BF%98%E8%83%BD%E9%9A%8F%E6%97%B6%E6%89%93%E5%8C%85%E5%B8%A6%E8%B5%B0%EF%BC%8CLinux%E5%B0%B1%E6%98%AF%E8%BF%99%E4%B9%88%E5%BC%BA%E5%A4%A7/dskmgr.png" class=""><p>知道了磁盘的编号，就可以创建虚拟盘了。这里我们使用的命令如下，注意使用管理员身份运行：</p><figure class="highlight powershell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">VBoxManage internalcommands createrawvmdk <span class="literal">-filename</span> <span class="string">&quot;C:\Users\gaoxiang\VirtualBox VMs\Linux\localdisk.vmdk&quot;</span> <span class="literal">-rawdisk</span> \\.\PhysicalDrive2</span><br></pre></td></tr></table></figure><p>有了虚拟磁盘了，就可以将虚拟磁盘添加到虚拟机中去了：</p><img src="/2017/06/29/%E8%83%BD%E5%BD%93%E4%B8%BB%E5%8A%9B%EF%BC%8C%E8%83%BD%E5%85%A5%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%8C%E8%BF%98%E8%83%BD%E9%9A%8F%E6%97%B6%E6%89%93%E5%8C%85%E5%B8%A6%E8%B5%B0%EF%BC%8CLinux%E5%B0%B1%E6%98%AF%E8%BF%99%E4%B9%88%E5%BC%BA%E5%A4%A7/newdisk.png" class=""><p>虚拟磁盘设置好了，最后一步就是设置EFI了。由于我们之前在分区的时候给文件系统都赋予了Label，并且在refind设置的时候也是用的Label来指定分区，所以同一套refind的配置在虚拟机上也能用。因此我们不需要单独给虚拟机安装bootloader，而是直接用我们之前安装在物理磁盘上的EFI分区中的refind就行。VitualBox默认是不开启EFI的，我们需要在虚拟机的系统设置里面手动勾选EFI：</p><img src="/2017/06/29/%E8%83%BD%E5%BD%93%E4%B8%BB%E5%8A%9B%EF%BC%8C%E8%83%BD%E5%85%A5%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%8C%E8%BF%98%E8%83%BD%E9%9A%8F%E6%97%B6%E6%89%93%E5%8C%85%E5%B8%A6%E8%B5%B0%EF%BC%8CLinux%E5%B0%B1%E6%98%AF%E8%BF%99%E4%B9%88%E5%BC%BA%E5%A4%A7/efi.png" class=""><p>为了要让VirtualBox自动启动refind，还要对EFI的分区做一些简单的设置，<a href="https://wiki.archlinux.org/index.php/VirtualBox#Installation_in_EFI_mode">设置的教程参考这里</a>。设置的时候一定要注意，这些设置一定要是通用的，即同一份文件既能在物理机上正常工作也能在虚拟机上正常工作，不要改完了设置以后虚拟机上能跑了物理机却挂了，这就不好玩了。VirtualBox的EFI在启动的时候会优先选择<code>/EFI/BOOT/BOOTX64.EFI</code>，如果找不到的话，才会启动EFI分区根目录下的<code>startup.nsh</code>中指定的bootloader。知道了这一点，为了实现自动启动refind，首先需要检查一下<code>/EFI/BOOT/BOOTX64.EFI</code>这个文件是否存在，若存在，备份并删除之：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> EFI/BOOT</span><br><span class="line">mv bootx64.efi bootx64-backup.efi</span><br></pre></td></tr></table></figure><p>然后就是在EFI分区根目录下新建一个<code>startup.nsh</code>了，这个文件只需要一行，内容如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">\EFI\refind\refind_x64.efi</span><br></pre></td></tr></table></figure><p>一切设置完毕，运行虚拟机，就能看到我们熟悉的refind界面了：</p><img src="/2017/06/29/%E8%83%BD%E5%BD%93%E4%B8%BB%E5%8A%9B%EF%BC%8C%E8%83%BD%E5%85%A5%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%8C%E8%BF%98%E8%83%BD%E9%9A%8F%E6%97%B6%E6%89%93%E5%8C%85%E5%B8%A6%E8%B5%B0%EF%BC%8CLinux%E5%B0%B1%E6%98%AF%E8%BF%99%E4%B9%88%E5%BC%BA%E5%A4%A7/refind.png" class=""><p>打开其中的Ubuntu系统，测试一切正常就大功告成了：</p><img src="/2017/06/29/%E8%83%BD%E5%BD%93%E4%B8%BB%E5%8A%9B%EF%BC%8C%E8%83%BD%E5%85%A5%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%8C%E8%BF%98%E8%83%BD%E9%9A%8F%E6%97%B6%E6%89%93%E5%8C%85%E5%B8%A6%E8%B5%B0%EF%BC%8CLinux%E5%B0%B1%E6%98%AF%E8%BF%99%E4%B9%88%E5%BC%BA%E5%A4%A7/ubuntu.png" class=""><p>当然，要在虚拟机中使用，还有一些细节性的工作要处理，比如安装VirtualBox的guest需要的相应的内核模块等等，这些在此不谈，读者使用过程中如果发现少啥了，自己装上便是。</p><h1 id="Linux下不同发行版的互相访问"><a href="#Linux下不同发行版的互相访问" class="headerlink" title="Linux下不同发行版的互相访问"></a>Linux下不同发行版的互相访问</h1><p>我们已经成功地在Windows下运行Linux了，下一步就是想办法在一个Linux系统下访问其他Linux了。由于这些系统都是Linux，而且都在同一个文件系统里面，所以如果只是想要访问一下里面的文件的话，挂载了用就行了。但是很多时候我们还是有需要来运行其他系统里面安装的程序，或者对那个系统进行管理的。应对这种需求有两种解决方案：容器跟虚拟机。</p><p>可能很多读者并不了解这两者的区别，这里简单介绍一下。粗略来讲，虚拟机是通过软件的方式虚拟出一套硬件环境来，并在这套硬件环境中启动内核，然后内核会进行一个完整的开机过程，包括进行相应的初始化，加载init程序等。相比之下，容器则要轻量很多。容器并不会虚拟出自己的硬件环境，也不会额外加载一个内核。容器所做的，就是在现有内核上，运用namespace来创建出一套独立的进程PID、挂载点、网络接口、用户ID等等，由于不同namespace中的这些个ID之类的标识符都是独立的，所以不同namespace中的进程是互相之间看不到对方的，虚拟出来的环境乍看上去就跟在单独运行的一个系统一样，同样有PID为1的init进程，有自己一套独立的root，等等。虚拟机的优点是更不容易被突破，安全性更好，可以使用自己的内核，但是效率也更低。容器的优点是轻便效率高，但是安全性就要稍差一些，也没法使用定制内核。</p><h2 id="容器"><a href="#容器" class="headerlink" title="容器"></a>容器</h2><p>Linux下大家最熟悉的容器就是chroot了，但是作者并不喜欢chroot，主要原因有两点：</p><ul><li>/proc、 /dev等东西不会自动挂载，每次手动挂载挂的心好累</li><li>没有一个相对完整的开机过程，好多我希望自动启动的服务并不会运行起来</li></ul><p>基于上面的原因，作者在这里推荐的容器是systemd-nspawn。关于systemd-nspawn的介绍跟使用教程，<a href="https://wiki.archlinux.org/index.php/Systemd-nspawn">推荐看这里</a>。systemd-nspawn的使用非常简单，假设你的linux分区已经mount到了/mnt上去了，那么你只需要下面步骤就能启动一个systemd-nspawn容器（以Debian为例）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /mnt/debian</span><br><span class="line">systemd-nspawn -b</span><br></pre></td></tr></table></figure><p>然后就能看到刷刷刷的开机界面了，真的是非常的方便快捷。这里还有一点小技巧是，如果嫌每次开容器都要把linux分区挂载到/mnt上太麻烦，可以在<code>/var/lib/machines</code>里面为每个系统新建一个目录，然后在fstab里面设置一下自动把相应的子卷挂载进去：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">&#x2F;dev&#x2F;disk&#x2F;by-label&#x2F;linux        &#x2F;var&#x2F;lib&#x2F;machines&#x2F;kali          btrfs           defaults,nofail,noatime,discard,subvol&#x3D;kali            0 0</span><br><span class="line">&#x2F;dev&#x2F;disk&#x2F;by-label&#x2F;linux        &#x2F;var&#x2F;lib&#x2F;machines&#x2F;debian        btrfs           defaults,nofail,noatime,discard,subvol&#x3D;debian          0 0</span><br><span class="line">&#x2F;dev&#x2F;disk&#x2F;by-label&#x2F;linux        &#x2F;var&#x2F;lib&#x2F;machines&#x2F;ubuntu        btrfs           defaults,nofail,noatime,discard,subvol&#x3D;ubuntu          0 0</span><br></pre></td></tr></table></figure><p>这么做的好处是，根目录位于<code>/var/lib/machines</code>的系统，在启动systemd-nspawn的时候可以直接使用<code>-M</code>选项来指定系统，而不需要进入相应目录。比如如果想启动Ubuntu系统：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">systemd-nspawn -b -M ubuntu</span><br></pre></td></tr></table></figure><h2 id="虚拟机"><a href="#虚拟机" class="headerlink" title="虚拟机"></a>虚拟机</h2><p>如果只是想运行一下其他系统里面的程序，那么容器完全就够用了，但是有的时候我们还是需要玩玩不同的内核的，这就必须得用虚拟机了。通常情况下，大家用虚拟机，都是新建一个磁盘镜像，然后插入安装光盘，然后把光盘安装到镜像上。这么做的坏处，一个是访问镜像中的文件不方便，另一个是，我们在本地已经有安装过若干系统了，不去充分利用一下这些而去再重新往镜像里面安装那实在是舍近求远。那我们就来找一个把子卷当成虚拟机root的方法。困难在于，虚拟机是个很独立的东西，是无法直接访问宿主机的文件系统的。然而幸运的是，Linux的内核虚拟化方案KVM提供了一个把本地文件系统传递给虚拟机的解决方案，用到的东西叫做VirtFS，<a href="http://wiki.qemu.org/Documentation/9psetup">相关的文档见这里</a>。</p><p>好消息是，VirtFS是可以作为root的。但是要能正常挂载VirtFS，内核必须要有相应的驱动才行。这里有两种方法可以做到这一点。如果你是自己编译内核的话，那么建议直接将相应的驱动编译进内核而不是模块。根据官网的指示，涉及到的内核配置如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">CONFIG_NET_9P&#x3D;y</span><br><span class="line">CONFIG_NET_9P_VIRTIO&#x3D;y</span><br><span class="line">CONFIG_9P_FS&#x3D;y</span><br><span class="line">CONFIG_9P_FS_POSIX_ACL&#x3D;y</span><br></pre></td></tr></table></figure><p>如果使用的是发行版提供的内核的话，那么可以修改initramfs的相关设置保证9p、9pnet、9pnet_virtio三个modules能被安装到initramfs里面去。这里以Ubuntu做guest为例，具体做法是修改Ubuntu系统中的<code>/etc/initramfs-tools/modules</code>文件，增加下面三行：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">9p</span><br><span class="line">9pnet</span><br><span class="line">9pnet_virtio</span><br></pre></td></tr></table></figure><p>然后重新生成initramfs即可：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">update-initramfs -u</span><br></pre></td></tr></table></figure><p>内核驱动设置好了，就可以启动qemu虚拟机了，这里假定Ubuntu的root已经被mount到了<code>/var/lib/machines/ubuntu</code>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">qemu-system-x86_64 -enable-kvm -m 16G -kernel /var/lib/machines/ubuntu/vmlinuz -initrd /var/lib/machines/ubuntu/initrd.img -virtfs <span class="built_in">local</span>,id=root9p,path=/var/lib/machines/ubuntu,security_model=passthrough,mount_tag=root9p -nographic -append <span class="string">&#x27;root=root9p rw rootfstype=9p rootflags=trans=virtio console=ttyS0 init=/lib/systemd/systemd&#x27;</span></span><br></pre></td></tr></table></figure><p>最后放一张成功的截图：</p><img src="/2017/06/29/%E8%83%BD%E5%BD%93%E4%B8%BB%E5%8A%9B%EF%BC%8C%E8%83%BD%E5%85%A5%E8%99%9A%E6%8B%9F%E6%9C%BA%EF%BC%8C%E8%BF%98%E8%83%BD%E9%9A%8F%E6%97%B6%E6%89%93%E5%8C%85%E5%B8%A6%E8%B5%B0%EF%BC%8CLinux%E5%B0%B1%E6%98%AF%E8%BF%99%E4%B9%88%E5%BC%BA%E5%A4%A7/qemu-ubuntu.png" class=""><h1 id="无盘系统"><a href="#无盘系统" class="headerlink" title="无盘系统"></a>无盘系统</h1><p>在某些特定的应用场景中，无盘系统用起来还是有不少方便之处的。尤其对于计算机集群而言，使用无盘系统不光能节省购买硬盘的成本，还能大大简化集群的管理。虽然我们并没有集群要管理，但是做一个无盘系统放在硬盘上用来代替livecd，在需要的时候进行一些系统恢复类的操作还是不错的。对同时安装有多个Linux的同学来说，其实用到livecd的时候并不多，偶尔一个系统出故障了，进其他系统把故障系统修复了就好。但是有些操作还是不得不用livecd的，比如要调整Linux分区的大小跟位置，这个分区就不能处于挂载状态，这就不得不用到livecd了。相比于livecd，自己做的无盘系统的好处主要是可定制性。举个不少人遇到过的实际例子来说：系统出故障了，进livecd修复系统，当试图使用vim更改某配置文件的时候，系统提示说vim并没有安装，想要安装，系统又提示说文件系统是只读的，无法安装。其实没有vim还只是小事，用vi或者nano将就一下也就过去了。但是如果自己千辛万苦下载并刻录livecd，却发现自己修复系统必备的软件没有且不能安装，那估计砸电脑的心都有了吧。既然livecd这么不好用，那为什么不搞一个跟自己平时使用的桌面一模一样的无盘系统呢？</p><p>要做无盘系统，一种做法是在另一台机器上搞个nfs，然后在本机启动的时候用nfs当做root来启动（需要在内核配置中开启<code>ROOT_NFS</code>选项），这种做法优点是内存占用相对较小（跟作者接下来要介绍的方法相比简直是小多了），但是配置起来比较麻烦，而且网络延迟跟带宽也严重制约系统的性能。由于作者的电脑内存有128G之多，可以随便挥霍不需要节约内存，并且作者只想简单粗暴地把自己平时使用的桌面做成无盘系统来启动，并不想多折腾。所以，作者最终采用的方案是基于initramfs的。要想理解制作过程，需要先了解几个术语：</p><h2 id="ramfs、tmpfs、rootfs以及initramfs"><a href="#ramfs、tmpfs、rootfs以及initramfs" class="headerlink" title="ramfs、tmpfs、rootfs以及initramfs"></a>ramfs、tmpfs、rootfs以及initramfs</h2><p>要想理解这个方案的工作原理，需要先了解一下本小节标题中的这几个术语。<a href="https://www.kernel.org/doc/Documentation/filesystems/ramfs-rootfs-initramfs.txt">这几个术语在内核的官方文档中有很好的解释</a>，在这里我们只做一个简单的概括。</p><p>首先要从Linux的磁盘缓存机制说起。程序访问文件的时候，Linux会把文件读到内存中缓存起来。磁盘缓存中的文件，如果没被修改过，或者被修改过但是改动已经从缓存同步到磁盘中去了，这种情况下内核会把对应的磁盘缓存标记为干净（clean）的。对于被修改过，但是还没来得及同步到磁盘的文件，内核会将其标记为脏（dirty）的。当Linux内存不足，需要释放内存的时候，Linux会将磁盘缓存中的一些干净的部分释放掉，从而将内存挪作他用。ramfs是一个虚拟的文件系统，直观上来讲，它相当于直接把磁盘缓存给挂载到相应的节点上去了：它其中的文件只存活在磁盘缓存中。并且由于没有物理磁盘可以将数据同步出去，所以这些文件的缓存始终是脏的，这也保证了这些文件不会被内核释放掉。而tmpfs则是对ramfs的一个扩展，相比于ramfs，它允许限制文件系统的大小，也允许数据被搬运到swap中去。</p><p>rootfs也是一个虚拟的文件系统，它是专门在启动的时候使用的一个特殊的ramfs。要想理解rootfs，需要了解Linux内核的启动过程。这个过程位于内核源码<code>init/main.c</code>文件中的<code>kernel_init</code>函数中，有兴趣的读者可以读一下以便深入了解。简单概括就是：Linux启动的时候，会创建一个rootfs，并把根目录“/”挂载为rootfs。这个rootfs将会伴随Linux终生：跟init进程无法被终止道理类似，rootfs是无法被卸载的。rootfs创建好以后，Linux内核会把bootloader提供的initramfs文件中的内容解压到rootfs中去，如果解压好的文件中能找到<code>/init</code>或者用户通过<code>rdinit=</code>内核参数指定的其他init程序，那么内核会执行这个init程序，并将接下来的初始化工作（比如挂载真正的root、删除旧的rootfs中的内容以节约内存、执行真正的root中的init程序）交由这个init程序负责。如果此时rootfs中无法找到相应的init程序，Linux就会尝试挂载真正的root，并执行root中的init程序。</p><h2 id="基于initramfs的无盘系统制作"><a href="#基于initramfs的无盘系统制作" class="headerlink" title="基于initramfs的无盘系统制作"></a>基于initramfs的无盘系统制作</h2><p>了解了上述的原理，我们的无盘系统制作思路也就清晰了：我们直接把自己的桌面打包成一个cpio，然后作为initramfs提供给内核，然后通过<code>rdinit</code>参数告诉内核启动<code>systemd</code>即可。具体做法，这里就以Ubuntu为例，并假定Linux分区被挂载在<code>/mnt</code>中。首先需要把我们的桌面制作成一个cpio包：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">cd</span> /mnt/ubuntu</span><br><span class="line">find -mindepth 1 -<span class="built_in">printf</span> <span class="string">&#x27;%P\0&#x27;</span> | LANG=C bsdcpio -0 -o -H newc | xz -T 21 -9e --check=crc32 &gt; ../ubuntu.cpio.xz</span><br></pre></td></tr></table></figure><p>其中xz命令中的线程数跟压缩比请根据自己的实际情况设置合适的值。另外注意如果内存太小装不下整个桌面，那么这种方法是不可能成功的。有了cpio文件，要想启动无盘系统，只需要在refind中增加相应的菜单条目即可：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">menuentry Ubuntu-diskless &#123;</span><br><span class="line">icon EFI&#x2F;refind&#x2F;icons&#x2F;os_ubuntu.png</span><br><span class="line">volume linux</span><br><span class="line">loader ubuntu&#x2F;vmlinuz</span><br><span class="line">options &quot;rdinit&#x3D;&#x2F;lib&#x2F;systemd&#x2F;systemd&quot;</span><br><span class="line">initrd ubuntu.cpio.xz</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p><em>全剧终</em></p>]]></content>
    
    
    <summary type="html">&lt;p&gt;__更新日志__：&lt;br&gt;2017-07-18 增加了新的一章：无盘系统，将多处不当使用的术语“rootfs”替换为更贴切的“root”&lt;/p&gt;
&lt;p&gt;===================&lt;/p&gt;
&lt;p&gt;这里介绍一下自己管理自己的Linux桌面的一点经验吧，我觉得还是有不少可取之处的。先来说一下大多数人管理Linux桌面的方法有哪些不方便的地方吧：&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;买新电脑了，又得在新电脑上安装Linux，安装各种软件，各种库，各种开发环境，配置各种服务，真麻烦。&lt;/li&gt;
&lt;li&gt;最近一直在用电脑A，干了好多事情安装了好多软件，也配置了不少开发环境跟各种服务，然而处于某种原因，我又要开始使用好久没用过的电脑B了，难道我要把在A上的做的各种配置在B上再重新做一遍？&lt;/li&gt;
&lt;li&gt;在Windows下做着PPT呢，发现需要调出自己之前的程序，然后根据若干组输入跑几个结果画张图好插到PPT里，然而这个程序是在Linux下写的，编译等的过程也严重依赖自己用的Linux环境，重启进Linux拿到结果再回Windows太不方便，想在Windows下配置好环境把自己的程序跑通更不容易。&lt;/li&gt;
&lt;li&gt;要对系统安装某个软件，或者进行一些比较危险的更新操作（要知道Archlinux滚动更新滚挂了太正常了），担心把系统搞挂了，系统备份又实在太麻烦，要真挂了，系统恢复起来更麻烦。&lt;/li&gt;
&lt;li&gt;我一直用Archlinux做主力，然而最近做的某件事情要用某个软件，这个软件官方只给了Ubuntu上的安装方式，Archlinux里面没有相应的包，在Archlinux上手动安装也太不方便。装个Ubuntu，然后暂时用几天Ubuntu吧，也是够折腾的。更何况有时候只是想用一小下而已，怎样才能最小化自己在折腾上浪费的时间呢？&lt;/li&gt;
&lt;li&gt;有的软件官方软件仓库里面没有，而&lt;code&gt;make install&lt;/code&gt;的话则会在系统中安装上不被包管理器所管理的文件，将来卸载也不方便，我还是更希望所有的文件都在一个包管理器中管理的。&lt;/li&gt;
&lt;li&gt;听说新版本内核引入了某个牛逼的东西？我就想快速测试一下玩玩，我电脑还有计算在跑着呢，我可不想重启，那就只能用虚拟机尝试了。而且，一定要快速，我可不想为此特地装一个虚拟机。&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;上述的这些不方便之处是可以通过自己管理系统时的一些技巧来克服的，本文目的就是来介绍一下这些技巧。通过这些技巧，我们实现的功能是：一台机器上，可以同时安装Windows跟若干Linux系统，Windows下可以通过虚拟机来运行位于本地磁盘的这些Linux系统，而这些Linux系统下也可以通过容器或者虚拟机的方式互相运行。并且这些系统可以非常方便地备份跟删除，也可以随时创建以及运行快照。并且这些Linux系统可以随时打包带走，只需要经过很少的修改，就能直接在U盘或者其他机器上运行。如果要换电脑，或者新装一台电脑，也不需要重新安装系统，只需要把已有的系统同步到新电脑就行。这也正是这篇文章标题的意思。&lt;/p&gt;</summary>
    
    
    
    <category term="Linux" scheme="https://zasdfgbnm.github.io/categories/Linux/"/>
    
    
    <category term="Linux" scheme="https://zasdfgbnm.github.io/tags/Linux/"/>
    
    <category term="系统管理" scheme="https://zasdfgbnm.github.io/tags/%E7%B3%BB%E7%BB%9F%E7%AE%A1%E7%90%86/"/>
    
    <category term="btrfs" scheme="https://zasdfgbnm.github.io/tags/btrfs/"/>
    
    <category term="refind" scheme="https://zasdfgbnm.github.io/tags/refind/"/>
    
    <category term="fstab" scheme="https://zasdfgbnm.github.io/tags/fstab/"/>
    
    <category term="root" scheme="https://zasdfgbnm.github.io/tags/root/"/>
    
    <category term="rootfs" scheme="https://zasdfgbnm.github.io/tags/rootfs/"/>
    
    <category term="ramfs" scheme="https://zasdfgbnm.github.io/tags/ramfs/"/>
    
    <category term="虚拟机" scheme="https://zasdfgbnm.github.io/tags/%E8%99%9A%E6%8B%9F%E6%9C%BA/"/>
    
    <category term="容器" scheme="https://zasdfgbnm.github.io/tags/%E5%AE%B9%E5%99%A8/"/>
    
    <category term="virtfs" scheme="https://zasdfgbnm.github.io/tags/virtfs/"/>
    
    <category term="KVM" scheme="https://zasdfgbnm.github.io/tags/KVM/"/>
    
    <category term="qemu" scheme="https://zasdfgbnm.github.io/tags/qemu/"/>
    
    <category term="VitualBox" scheme="https://zasdfgbnm.github.io/tags/VitualBox/"/>
    
    <category term="Plan 9" scheme="https://zasdfgbnm.github.io/tags/Plan-9/"/>
    
  </entry>
  
</feed>
