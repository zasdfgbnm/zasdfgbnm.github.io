<!doctype html>



  


<html class="theme-next mist use-motion" lang="zh-Hans">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />



  <meta name="google-site-verification" content="d44tDfSSWxm1_XP1dAq65hkgyD6zw70Ua9JdCaJqWGg" />













  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="PyTorch,深度学习,机器学习," />





  <link rel="alternate" href="/atom.xml" title="zasdfgbnm" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="This is my note for reading PyTorch’s JIT source. We begin by looking at torch.jit.script and torch.jit.script_method to find the frontend that compiles the Python code into PyTorch’s tree views, and">
<meta name="keywords" content="PyTorch,深度学习,机器学习">
<meta property="og:type" content="article">
<meta property="og:title" content="PyTorch JIT Source Code Read Note">
<meta property="og:url" content="https://zasdfgbnm.github.io/2018/09/20/PyTorch-JIT-Source-Code-Read-Note/index.html">
<meta property="og:site_name" content="zasdfgbnm">
<meta property="og:description" content="This is my note for reading PyTorch’s JIT source. We begin by looking at torch.jit.script and torch.jit.script_method to find the frontend that compiles the Python code into PyTorch’s tree views, and">
<meta property="og:locale" content="zh-Hans">
<meta property="og:updated_time" content="2018-09-26T22:04:32.016Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="PyTorch JIT Source Code Read Note">
<meta name="twitter:description" content="This is my note for reading PyTorch’s JIT source. We begin by looking at torch.jit.script and torch.jit.script_method to find the frontend that compiles the Python code into PyTorch’s tree views, and">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://zasdfgbnm.github.io/2018/09/20/PyTorch-JIT-Source-Code-Read-Note/"/>





  <title>PyTorch JIT Source Code Read Note | zasdfgbnm</title>
  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-7583294-5', 'auto');
  ga('send', 'pageview');
</script>


  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?a56abdeb557a286a6b7a104348fdfbcd";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>










</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">zasdfgbnm</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            归档
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-sitemap">
          <a href="/sitemap.xml" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-sitemap"></i> <br />
            
            站点地图
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">

    <div>
      
      
      <ul class="post-copyright">
        <li class="post-copyright-author">
            <strong>本文作者：</strong>zasdfgbnm
        </li>
        <li class="post-copyright-link">
          <strong>本文链接：</strong>
          <a href="/2018/09/20/PyTorch-JIT-Source-Code-Read-Note/" title="PyTorch JIT Source Code Read Note">2018/09/20/PyTorch-JIT-Source-Code-Read-Note/</a>
        </li>
        <li class="post-copyright-license">
          <strong>版权声明： </strong>
          本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0 CN</a> 许可协议。转载请注明出处！
        </li>
      </ul>
      
    </div>

    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://zasdfgbnm.github.io/2018/09/20/PyTorch-JIT-Source-Code-Read-Note/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="zasdfgbnm">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="zasdfgbnm">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">PyTorch JIT Source Code Read Note</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              
              <time title="创建于" itemprop="dateCreated datePublished" datetime="2018-09-20T20:12:21-04:00">
                2018-09-20
              </time>
            

            

            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/机器学习/" itemprop="url" rel="index">
                    <span itemprop="name">机器学习</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2018/09/20/PyTorch-JIT-Source-Code-Read-Note/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2018/09/20/PyTorch-JIT-Source-Code-Read-Note/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <p>This is my note for reading PyTorch’s JIT source. We begin by looking at <code>torch.jit.script</code> and <code>torch.jit.script_method</code> to find the frontend that compiles the Python code into PyTorch’s tree views, and the backend that compiles tree views to graph. We also read the structure of the internal representation of PyTorch’s graph. Finally we go to graph executor to look at how the computation graph is further compiled into instructions and how the action of these instructions are defined and executed.</p>
<a id="more"></a>
<p>PyTorch is under very active development. So the PyTorch’s source code at the time the reader reading this article won’t be the same as when I wrote this article. To get the same source code as in this article, the readers could run the following command:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">git checkout 76ab26cc3eff1d7ba822d8db93723f5c9598eead</div></pre></td></tr></table></figure>
<h1 id="Starting-point-script-and-script-method"><a href="#Starting-point-script-and-script-method" class="headerlink" title="Starting point: script and script_method"></a>Starting point: script and script_method</h1><p>In PyTorch, a Python function can be just-in-time compiled by doing something like:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="meta">@torch.jit.script</span></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(x)</span>:</span></div><div class="line">    <span class="keyword">return</span> x + x</div></pre></td></tr></table></figure>
<p>the <code>torch.jit.script</code> is a decorator of your function <code>f</code>. If you are unfamiliar with Python’s decorator, please refer to <a href="https://realpython.com/primer-on-python-decorators/" target="_blank" rel="noopener">this article</a>.</p>
<p>It is also possible to create a module with its method JIT compiled by doing something like:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModule</span><span class="params">(torch.jit.ScriptModule)</span>:</span></div><div class="line"></div><div class="line"><span class="meta">    @torch.jit.script_method</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(self.x)</span>:</span></div><div class="line">        <span class="keyword">return</span> x * x</div><div class="line"></div><div class="line"><span class="meta">    @torch.jit.script_method</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div><div class="line">        <span class="keyword">return</span> x + self.f(x)</div></pre></td></tr></table></figure>
<h2 id="Scripting-a-function"><a href="#Scripting-a-function" class="headerlink" title="Scripting a function"></a>Scripting a function</h2><p>We will start by looking at <code>torch.jit.script</code>. To read <code>torch.jit.script</code>, we begin by looking at <code>torch/jit/__init__.py</code>. To quickly locate <code>script</code>, search <code>def script</code> in your editor, and you will immediately find it:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">script</span><span class="params">(fn, optimize=True, _frames_up=<span class="number">0</span>)</span>:</span></div><div class="line">    <span class="keyword">if</span> <span class="keyword">not</span> _enabled:</div><div class="line">        <span class="keyword">return</span> fn</div><div class="line">    rcb = createResolutionCallback(_frames_up + <span class="number">1</span>)</div><div class="line">    ast = get_jit_ast(fn, is_method=<span class="keyword">False</span>)</div><div class="line">    graph = _jit_script_compile(ast, rcb)</div><div class="line">    mod = ScriptModule()</div><div class="line">    mod._create_method_from_graph(<span class="string">'forward'</span>, graph)</div><div class="line">    <span class="comment"># <span class="doctag">TODO:</span> refactor everything so we're not 1) creating a ScriptModule</span></div><div class="line">    <span class="comment"># 2) Throwing everything away except for the graph 3) Creating a new</span></div><div class="line">    <span class="comment"># ScriptModule and dumping that graph in 4) Re-populating the schema</span></div><div class="line">    <span class="comment"># because it was lost doing the previous</span></div><div class="line">    mod.__getattr__(<span class="string">'forward'</span>).forward_schema(ast, <span class="keyword">False</span>)</div><div class="line">    <span class="comment"># Forward docstrings</span></div><div class="line">    mod.__doc__ = fn.__doc__</div><div class="line">    <span class="keyword">return</span> mod</div></pre></td></tr></table></figure>
<p>In the beginning, <code>createResolutionCallback</code> is called. This function is defined in the same file. The source code tells us that it just returns a function that maps names to its values in the scope of the caller of <code>script</code>, this would be used later in C++ to read values from Python.</p>
<p>The <code>get_jit_ast</code> in next line is imported from <code>torch.jit.frontend</code>. From the name of this function and its owning module, we can tell that this is the frontend of PyTorch’s JIT compiler that compiles the source code of the scripted function into abstract syntax tree(AST).</p>
<p>The next line uses <code>_jit_script_compile</code> to compiles the AST obtained in the previous step into computation graph. By searching <code>_jit_script_compile</code>, we find something that reads: <code>torch._C._jit_script_compile</code>, which tells us that <code>_jit_script_compile</code> is implemented in C++.</p>
<p>The next couple lines basically create a <code>ScriptModule</code> whose <code>forward</code> method is the compiled graph.</p>
<h2 id="Scripting-a-module"><a href="#Scripting-a-module" class="headerlink" title="Scripting a module"></a>Scripting a module</h2><p>We start by looking at <code>torch.jit.script_method</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line">ScriptMethodStub = namedtuple(<span class="string">'ScriptMethodStub'</span>, (<span class="string">'resolution_callback'</span>, <span class="string">'def_'</span>, <span class="string">'original_method'</span>))</div><div class="line"></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">script_method</span><span class="params">(fn)</span>:</span></div><div class="line">    <span class="keyword">if</span> <span class="keyword">not</span> _enabled:</div><div class="line">        <span class="keyword">return</span> fn</div><div class="line">    <span class="comment"># ...</span></div><div class="line">    rcb = createResolutionCallback(frames_up=<span class="number">2</span>)</div><div class="line">    ast = get_jit_ast(fn, is_method=<span class="keyword">True</span>)</div><div class="line">    <span class="keyword">return</span> ScriptMethodStub(rcb, ast, fn)</div></pre></td></tr></table></figure>
<p>This is similar to <code>script</code>, but instead of creating and returning a module and put the compiled function into its <code>forward</code> method, it simply use a named tuple to store the resolution callback, AST and the original function.</p>
<p>This can not be the end of the story because a named tuple can never be called to do the computation. So there must be some magic somewhere that replace the named tuples with something that actually do the job. For readers familiar with Python’s class meta-programming, it’s not hard to imagine how the magic happens. For those not familiar with class meta-programming, I would refer to the book <a href="http://shop.oreilly.com/product/0636920032519.do" target="_blank" rel="noopener">Fluent Python</a>. I will explain a bit of detail on that:</p>
<p>In Python, everything is an object, and a class itself is not an exception. Classes in Python are objects of a special type of classes called meta-class. During import time, when Python see the following code:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyModule</span><span class="params">(torch.jit.ScriptModule)</span>:</span></div><div class="line"></div><div class="line"><span class="meta">    @torch.jit.script_method</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">f</span><span class="params">(self.x)</span>:</span></div><div class="line">        <span class="keyword">return</span> x * x</div><div class="line"></div><div class="line"><span class="meta">    @torch.jit.script_method</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">forward</span><span class="params">(self, x)</span>:</span></div><div class="line">        <span class="keyword">return</span> x + self.f(x)</div></pre></td></tr></table></figure>
<p>It will execute the body of the class definition, that is: compile the <code>return x * x</code>, create an function object with that compiled code, pass this function object to <code>torch.jit.script_method</code>, and set the returned named tuple as <code>f</code>. Then do the same thing for <code>forward</code>. After that, Python will have a map of attribute names and values of the class to be constructed. This map will then be passed to the meta-class of <code>MyModule</code> to actually construct <code>MyModule</code> as an instance of that meta-class.</p>
<p>To know in detail how this is achieved in PyTorch, we should take a look at <code>ScriptMeta</code> and <code>ScriptModule</code>. These two classes are lengthy, so I will not copy their full code here, but to use pseudocode to show what is done:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ScriptMeta</span><span class="params">(type<span class="params">(torch._C.ScriptModule)</span>)</span>:</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(cls, name, bases, attrs)</span>:</span></div><div class="line">        <span class="comment"># delete all ScriptMethodStub</span></div><div class="line"></div><div class="line"><span class="meta">        @functools.wraps(original_init)</span></div><div class="line">        <span class="function"><span class="keyword">def</span> <span class="title">init_then_register</span><span class="params">(self, *args, **kwargs)</span>:</span></div><div class="line">            <span class="comment"># invoke the original __init__</span></div><div class="line">            self._create_methods(defs, rcbs)</div><div class="line"></div><div class="line">        cls.__init__ = init_then_register</div><div class="line">        <span class="keyword">return</span> super(ScriptMeta, cls).__init__(name, bases, attrs)</div><div class="line"></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">ScriptModule</span><span class="params">(with_metaclass<span class="params">(ScriptMeta, torch._C.ScriptModule, Module)</span>)</span>:</span></div><div class="line">    <span class="comment"># ......</span></div><div class="line"></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__getattr__</span><span class="params">(self, attr)</span>:</span></div><div class="line">        <span class="keyword">if</span> self._has_method(attr):</div><div class="line">            <span class="comment"># ......</span></div><div class="line">            <span class="keyword">return</span> self._get_method(attr)</div><div class="line">        <span class="comment"># .....</span></div><div class="line">        <span class="keyword">return</span> Module.__getattr__(self, attr)</div></pre></td></tr></table></figure>
<p>In the above pseudocode, <code>_create_methods</code>, <code>_has_method</code>, and <code>_get_method</code> are inherited from <code>torch._C.ScriptModule</code>. So a natural question to ask is then: what does <code>torch._C.ScriptModule</code> do? Before answering this question, let’s first take a look at the frontend.</p>
<h1 id="The-frontend"><a href="#The-frontend" class="headerlink" title="The frontend"></a>The frontend</h1><p>A good starting point of the frontend is the <code>get_jit_ast</code> we just saw. This function is defined at <code>torch/jit/frontend.py</code>. The code is:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_jit_ast</span><span class="params">(fn, is_method)</span>:</span></div><div class="line">    source = dedent(inspect.getsource(fn))</div><div class="line">    py_ast = ast.parse(source)</div><div class="line">    <span class="keyword">if</span> len(py_ast.body) != <span class="number">1</span> <span class="keyword">or</span> <span class="keyword">not</span> isinstance(py_ast.body[<span class="number">0</span>], ast.FunctionDef):</div><div class="line">        <span class="keyword">raise</span> RuntimeError(<span class="string">"expected a single top-level function"</span>)</div><div class="line">    type_line = torch.jit.annotations.get_type_line(source)</div><div class="line">    ctx = SourceContext(source, _uses_true_division(fn))</div><div class="line">    <span class="keyword">return</span> build_def(ctx, py_ast.body[<span class="number">0</span>], type_line, is_method)</div></pre></td></tr></table></figure>
<p>The first 4 lines of function body just use the standard tools provided by Python, <code>dedent</code>, <code>inspect</code>, and <code>ast</code>, to construct the Python AST, and do some check to make sure the thing being compiled is “a single top-level function”.</p>
<p>The following line <code>type_line = torch.jit.annotations.get_type_line(source)</code> is interesting. After looking at <code>torch/jit/annotations.py</code>, we can see that PyTorch’s JIT allows the user to specify the type of arguments and return value by writing something like <code># type: (Tensor, torch.Tensor) -&gt; Tuple[Tensor, Tensor]</code>.</p>
<p>In the next line <code>ctx = SourceContext(source, _uses_true_division(fn))</code>, the <code>_uses_true_division</code> is defined in the same file to handle the different behavior of <code>/</code> in Python2 with or without <code>from __future__ import division</code> (see <a href="https://www.Python.org/dev/peps/pep-0238/" target="_blank" rel="noopener">PEP 238</a> for the difference). The <code>SourceContext</code> is also defined in the same file. It is a subclass of <code>SourceRangeFactory</code> with additional field to store if the division is true division. The <code>SourceRangeFactory</code> is imported by <code>from torch._C._jit_tree_views import *</code>. After reading its definition at <code>torch/csrc/jit/script/python_tree_views.cpp</code>, we can see that this is basically a class designed to store the range of source code, e.g. where in the source code a token is located.</p>
<p>The core is the <code>build_def</code> in the last line, so we move on:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_def</span><span class="params">(ctx, py_def, type_line, is_method)</span>:</span></div><div class="line">    returns = []</div><div class="line">    ret_body = []</div><div class="line">    body = py_def.body</div><div class="line">    r = ctx.make_range(py_def.lineno, py_def.col_offset,</div><div class="line">                       py_def.col_offset + len(<span class="string">"def"</span>))</div><div class="line">    param_list = build_param_list(ctx, py_def.args)</div><div class="line">    return_type = <span class="keyword">None</span></div><div class="line">    <span class="keyword">if</span> getattr(py_def, <span class="string">'returns'</span>, <span class="keyword">None</span>) <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">        return_type = build_expr(ctx, py_def.returns)</div><div class="line">    decl = Decl(r, param_list, return_type)</div><div class="line">    <span class="keyword">if</span> type_line <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</div><div class="line">        type_comment_decl = torch._C.parse_type_comment(type_line)</div><div class="line">        decl = torch._C.merge_type_from_type_comment(decl, type_comment_decl, is_method)</div><div class="line">    <span class="keyword">return</span> Def(Ident(r, py_def.name),</div><div class="line">               decl,</div><div class="line">               build_stmts(ctx, body))</div></pre></td></tr></table></figure>
<p>Reading through this, we can see that what basically this does is to convert the Python’s AST into the internal representation. Names like <code>Decl</code>, <code>Def</code>, <code>Ident</code> are all imported by <code>from torch._C._jit_tree_views import *</code>. In the last line, we can see that the function body is constructed by <code>build_stmts</code>, so let’s go further to read <code>build_stmts</code>:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">build_stmts</span><span class="params">(ctx, stmts)</span>:</span></div><div class="line">    stmts = [build_stmt(ctx, s) <span class="keyword">for</span> s <span class="keyword">in</span> stmts]</div><div class="line">    <span class="keyword">return</span> list(filter(<span class="keyword">None</span>, stmts))</div></pre></td></tr></table></figure>
<p>This is a very simple function: call <code>build_stmt</code> for each item and filter out those not needed. But what is <code>build_stmt</code>? It is defined as: <code>build_stmt = StmtBuilder()</code>. The definition of <code>StmtBuilder</code> looks like:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">class</span> <span class="title">StmtBuilder</span><span class="params">(Builder)</span>:</span></div><div class="line">    <span class="comment"># ...</span></div><div class="line"><span class="meta">    @staticmethod</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_Expr</span><span class="params">(ctx, stmt)</span>:</span></div><div class="line">        value = stmt.value</div><div class="line">        <span class="keyword">if</span> value.__class__.__name__ == <span class="string">'Str'</span>:</div><div class="line">            <span class="comment"># If a statement is a string literal expression,</span></div><div class="line">            <span class="comment"># then it is a docstring. Just ignore it.</span></div><div class="line">            <span class="keyword">return</span> <span class="keyword">None</span></div><div class="line">        <span class="keyword">else</span>:</div><div class="line">            <span class="keyword">return</span> ExprStmt([build_expr(ctx, value)])</div><div class="line">    <span class="comment"># ...</span></div><div class="line"><span class="meta">    @staticmethod</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">get_assign_lhs_expr</span><span class="params">(ctx, expr)</span>:</span></div><div class="line">        <span class="comment"># ...</span></div><div class="line">    <span class="comment"># ...</span></div><div class="line"><span class="meta">    @staticmethod</span></div><div class="line">    <span class="function"><span class="keyword">def</span> <span class="title">build_Assign</span><span class="params">(ctx, stmt)</span>:</span></div><div class="line">        <span class="comment">#...</span></div><div class="line">    <span class="comment"># ......</span></div></pre></td></tr></table></figure>
<p>We can see that, this is a class with many static methods that define what to do for different types of Python AST. I will not go deep into how each type is handled. Since at this point, the readers should be able to catch all the details on how each type of nodes in Python AST are dealt with by themselves. So We will stop our frontend reading right here.</p>
<h1 id="ScriptModule-and-ScriptMethod"><a href="#ScriptModule-and-ScriptMethod" class="headerlink" title="ScriptModule and ScriptMethod"></a>ScriptModule and ScriptMethod</h1><p>To find where <code>ScriptModule</code> in C++ is defined, run <code>grep &#39;ScriptModule&#39; -r torch/csrc/</code> and you will locate it at <code>torch/csrc/jit/script/init.cpp</code>:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// torch.jit.ScriptModule is a subclass of this C++ object.</span></div><div class="line"><span class="comment">// Methods here are prefixed with _ since they should not be</span></div><div class="line"><span class="comment">// public.</span></div><div class="line">py::class_&lt;Module, <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Module&gt;&gt;(m, <span class="string">"ScriptModule"</span>)</div><div class="line">    .def(py::init&lt;&gt;())</div><div class="line">    .def(<span class="string">"save"</span>, &amp;Module::save)</div><div class="line">    .def(<span class="string">"_set_optimized"</span>, &amp;Module::set_optimized)</div><div class="line">    .def(</div><div class="line">        <span class="string">"_define"</span>,</div><div class="line">        [](<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Module&gt; m,</div><div class="line">            <span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; script,</div><div class="line">            ResolutionCallback rcb, <span class="keyword">bool</span> has_self) &#123;</div><div class="line">          <span class="keyword">auto</span> self = has_self ? <span class="built_in">std</span>::make_shared&lt;ModuleValue&gt;(m) : <span class="literal">nullptr</span>;</div><div class="line">          <span class="keyword">return</span> defineMethodsInModule(*m, script, pythonResolver(rcb), self);</div><div class="line">        &#125;)</div><div class="line">    .def(<span class="string">"_create_methods"</span>, [](<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Module&gt; m, <span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Def&gt;&amp; defs, <span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;ResolutionCallback&gt;&amp; rcbs) &#123;</div><div class="line">      <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Resolver&gt; resolvers;</div><div class="line">      <span class="keyword">for</span>(<span class="keyword">auto</span> &amp; callback : rcbs) &#123;</div><div class="line">        resolvers.push_back(pythonResolver(callback));</div><div class="line">      &#125;</div><div class="line">      defineMethodsInModule(</div><div class="line">        *m,</div><div class="line">        defs,</div><div class="line">        resolvers,</div><div class="line">        <span class="built_in">std</span>::make_shared&lt;ModuleValue&gt;(m));</div><div class="line">    &#125;)</div><div class="line">    .def(<span class="string">"_get_method"</span>,</div><div class="line">    [](Module&amp; self, <span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span>&amp; name) -&gt; <span class="keyword">const</span> Method&amp; &#123;</div><div class="line">      <span class="keyword">return</span> self.get_method(name);</div><div class="line">    &#125;, py::return_value_policy::reference_internal)</div><div class="line">    <span class="comment">//.def more ...</span></div><div class="line"></div><div class="line">py::class_&lt;Method&gt;(m, <span class="string">"ScriptMethod"</span>, py::dynamic_attr())</div><div class="line">    .def(<span class="string">"graph"</span>, [&amp;](Method&amp; self) &#123;</div><div class="line">      <span class="keyword">return</span> self.graph();</div><div class="line">    &#125;)</div><div class="line">    .def(<span class="string">"__call__"</span>, invokeScriptMethodFromPython)</div><div class="line">    <span class="comment">//.def more ...</span></div></pre></td></tr></table></figure>
<p>We can see that <code>ScriptModule</code> is basically a binding for the C++ class <code>Module</code>. By skim through the list of methods defined here, we can see that it has methods for adding, getting, and checking existence of methods, parameters, submodules, buffers, etc. The class for methods is <code>Method</code>, which binds to Python as <code>ScriptMethod</code>. Methods in modules are created by <code>defineMethodsInModule</code> and invoked by <code>invokeScriptMethodFromPython</code>. <code>defineMethodsInModule</code> is a bit complicated, and we will postpone its reading to the backend compiler part of this article. But <code>invokeScriptMethodFromPython</code> is very simple. Searching with <code>grep</code>, we can easily find its definition in <code>torch/csrc/jit/pybind_utils.h</code>:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">inline</span> py::<span class="function">object <span class="title">invokeScriptMethodFromPython</span><span class="params">(</span></span></div><div class="line">    script::Method&amp; method,</div><div class="line">    py::args args, py::kwargs kwargs) &#123;</div><div class="line">  <span class="keyword">auto</span> <span class="built_in">stack</span> = createStackForSchema(method.getSchema(), <span class="built_in">std</span>::move(args), <span class="built_in">std</span>::move(kwargs));</div><div class="line">  &#123;</div><div class="line">    AutoNoGIL no_gil_guard;</div><div class="line">    method.run(<span class="built_in">stack</span>);</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">return</span> createPyObjectForStack(<span class="built_in">std</span>::move(<span class="built_in">stack</span>));</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>We can easily tell that it just create a stack from the input parameters, invoke <code>Method::run</code> to consume elements on the stack as input and leave the output of graph on the stack, and finally convert elements on the stack into Python objects.</p>
<p>Now let’s move on to <code>Module</code> and <code>Method</code>. It’s easy to guess from the name that these classes are defined at <code>torch/csrc/jit/script/module.{h,cpp}</code>. Read through these two files, we would see that <code>Module</code> is just a container of things: it just uses ordered dictionary to store methods, parameters and submodules, and provide methods to access or run them.</p>
<p>What <code>Method</code> does is more interesting. One important thing that the designer of <code>Method</code> must worry about is, since methods have access to not only its arguments, but also other class members of the same object, there must be a mechanism for such kind of access. We will see how this is handled very soon. From its constructor, we can see that a method can be created either from the graph and initial class members directly, or from a method creator. The method creator is invoked lazily, i.e. it is not invoked inside the constructor, but wait until someone call <code>ensure_defined</code>. The following member functions of <code>Method</code> defines how an object of <code>Method</code> is run:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">(Stack &amp; <span class="built_in">stack</span>)</span> </span>&#123;</div><div class="line">  <span class="keyword">for</span>(at::Tensor* tp : member_inputs) &#123;</div><div class="line">    <span class="built_in">stack</span>.push_back(*tp);</div><div class="line">  &#125;</div><div class="line">  get_executor().run(<span class="built_in">stack</span>);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function">IValue <span class="title">operator</span><span class="params">()</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;IValue&gt; <span class="built_in">stack</span>)</span> </span>&#123;</div><div class="line">  checkInputsAgainstSchema(<span class="built_in">stack</span>);</div><div class="line">  run(<span class="built_in">stack</span>);</div><div class="line">  <span class="keyword">if</span> (<span class="built_in">stack</span>.size() != <span class="number">1</span>) &#123;</div><div class="line">    <span class="keyword">return</span> Tuple::create(<span class="built_in">std</span>::move(<span class="built_in">stack</span>));</div><div class="line">  &#125;</div><div class="line">  <span class="keyword">return</span> <span class="built_in">stack</span>.front();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>By looking at the types of names appearing in the above code, we can see that: graph is an object of <code>Graph</code>, and the virtual machine that execute the graph is an object of <code>GraphExecutor</code>. <code>GraphExecutor</code> operate on data type <code>IValue</code>, and its stack is a <code>vector</code> of that data type. To run a method, one need to first push the arguments onto the stack, and invoke <code>Method::run</code>, which will further push other member inputs onto the stack, and invoke <code>GraphExecutor::run</code> to run the graph. The graph executor will leave its output on the stack.</p>
<p>At this point, we still don’t know how things like <code>Graph</code> and <code>GraphExecutor</code> works, but before looking deep into that, let’s pause a little bit to take a look at the backend compiler.</p>
<h1 id="From-Python-AST-to-PyTorch-IR-part-1"><a href="#From-Python-AST-to-PyTorch-IR-part-1" class="headerlink" title="From Python AST to PyTorch IR: part 1"></a>From Python AST to PyTorch IR: part 1</h1><p>Now let’s move on to read <code>_jit_script_compile</code>. To find where it is located, simply run the command <code>grep _jit_script_compile -r .</code>. We will find something like:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div></pre></td><td class="code"><pre><div class="line">./torch/csrc/jit/script/init.cpp:  m.def(<span class="string">"_jit_script_compile"</span>, [](<span class="keyword">const</span> Def &amp;def, ResolutionCallback rcb) &#123;</div></pre></td></tr></table></figure>
<p>So, <code>torch/csrc/jit/script/init.cpp</code> would be a good start point. The complete definition of <code>_jit_script_compile</code> is:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line">m.def(<span class="string">"_jit_script_compile"</span>, [](<span class="keyword">const</span> Def &amp;def, ResolutionCallback rcb) &#123;</div><div class="line">  <span class="keyword">return</span> compileFunction(def, PythonResolver(rcb));</div><div class="line">&#125;);</div></pre></td></tr></table></figure>
<p>So, let’s move on to <code>compileFunction</code>. Using grep to search, we would find its definition in <code>torch/csrc/jit/script/compiler.cpp</code>:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Graph&gt; compileFunction(Def def, <span class="keyword">const</span> Resolver&amp; resolver) &#123;</div><div class="line">  Module m;</div><div class="line">  defineMethodsInModule(m, &#123;def&#125;, &#123;resolver&#125;, <span class="literal">nullptr</span>);</div><div class="line">  <span class="keyword">return</span> m.get_method(def.name().name()).graph();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>We see the <code>defineMethodsInModule</code> that we saw before on the definition of Python bindings for <code>Module</code>. Move on to <code>defineMethodsInModule</code>, on the same file:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">defineMethodsInModule</span><span class="params">(Module &amp; m, <span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Def&gt;&amp; definitions, <span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Resolver&gt;&amp; resolvers, SugaredValuePtr self)</span> </span>&#123;</div><div class="line">  <span class="comment">// ......</span></div><div class="line">  <span class="keyword">for</span>(Def def : definitions) &#123;</div><div class="line">    <span class="comment">// ......</span></div><div class="line">    <span class="keyword">auto</span> creator = [def, &amp;table, resolver, self](Method&amp; method) &#123;</div><div class="line">      to_ir(def, table, resolver, self,  method);</div><div class="line">    &#125;;</div><div class="line">    Method&amp; method = m.create_method(name, creator);</div><div class="line">    <span class="comment">// ......</span></div><div class="line">  &#125;</div><div class="line">  <span class="comment">// ......</span></div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Less important parts of the code is omitted. From above, we can find that the core of compiling an AST into a compute graph is done at <code>to_ir</code>. Skimming through <code>to_ir</code> we find that it is a struct of ~1000 lines of code, with member functions that handles different cases of Python AST. Without knowing PyTorch’s IR, it’s not easy to understand what <code>to_ir</code> does. So let’s pause a little bit to take a look at PyTorch IR and come back later.</p>
<h1 id="The-PyTorch-IR"><a href="#The-PyTorch-IR" class="headerlink" title="The PyTorch IR"></a>The PyTorch IR</h1><p>A good starting point is the class <code>Graph</code>, located at <code>torch/csrc/jit/ir.h</code>. Skimming through this file, as well as <code>to_ir</code>, we keep seeing things like <code>aten::mul</code>, <code>prim::Constant</code>. What are they? They seems to be very relevant, actually they seems to be <strong>the node</strong> in the graph. By doing some <code>grep</code> search, we find a good document of them at <code>torch/csrc/jit/interned_strings.h</code>:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// 'prim' symbols are synthetic operators that occur only in the IR</span></div><div class="line"><span class="comment">// and don't have corresponding implementations in ATen.</span></div><div class="line"></div><div class="line"><span class="comment">// 'onnx' symbols correspond to ONNX operators.  Their semantics</span></div><div class="line"><span class="comment">// are defined in https://github.com/onnx/onnx/blob/master/docs/Operators.md</span></div><div class="line"><span class="comment">// The particular version we are targeting is specified by '_onnx_opset_version'</span></div><div class="line"><span class="comment">// in torch.onnx.symbolic</span></div><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment">// In general, most ONNX operators won't get an entry here, because they</span></div><div class="line"><span class="comment">// are handled from the Python end.  However, you may occasionally need</span></div><div class="line"><span class="comment">// to intern an ONNX symbol here so that you can conveniently write an</span></div><div class="line"><span class="comment">// optimization on ONNX operations.</span></div><div class="line"></div><div class="line"><span class="comment">// 'attr' symbols are attribute keys.  They are shared between both ONNX and ATen</span></div><div class="line"><span class="comment">// operators (you disambiguate their meaning by looking at the operator itself).</span></div><div class="line"><span class="comment">// In general, you only need to define attribute keys that are used by</span></div><div class="line"><span class="comment">// onnx or prim; ATen attributes are automatically generated in FORALL_ATTR_BASE_SYMBOLS.</span></div><div class="line"></div><div class="line"><span class="comment">// Note [Symbol allocation]</span></div><div class="line"><span class="comment">// ~~~~~~~~~~~~~~~~~~~~~~~~</span></div><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment">//  1. Symbol namespace is split up into namespaces.</span></div><div class="line"><span class="comment">//</span></div><div class="line"><span class="comment">//  2. The intended access pattern for built-in symbols is onnx::MatMul</span></div><div class="line"><span class="comment">//  in the torch::jit namespace (this is a Symbol).</span></div><div class="line"><span class="comment">//</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment">// Built-in constant definition strategy:</span></div><div class="line"><span class="comment">// - Enum is the most convenient way to generate a contiguous sequence</span></div><div class="line"><span class="comment">//   of numbers for an identifier.</span></div><div class="line"><span class="comment">// - However, an enum gives you a fresh type.  We want onnx::MatMul to</span></div><div class="line"><span class="comment">//   be type Symbol, not some random enum type!</span></div><div class="line"><span class="comment">// - Therefore, after using enums to generate the sequence of integers,</span></div><div class="line"><span class="comment">//   we then declare constexpr Symbols to get everything the actual Symbol</span></div><div class="line"><span class="comment">//   type we want.  Symbols must be constexpr to be valid to be "case"ed on.</span></div><div class="line"></div><div class="line"><span class="keyword">using</span> <span class="keyword">unique_t</span> = <span class="keyword">uint32_t</span>;</div><div class="line"></div><div class="line"><span class="keyword">static</span> <span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">string</span> domain_prefix = <span class="string">"org.PyTorch."</span>;</div><div class="line"></div><div class="line"><span class="comment">// A Symbol is like an interned string, but with a little extra</span></div><div class="line"><span class="comment">// structure; it is namespaced via SymbolNamespace and the resulting</span></div><div class="line"><span class="comment">// intern pointers support efficient namespace testing.</span></div><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">TORCH_API</span> <span class="title">Symbol</span> &#123;</span></div><div class="line"><span class="comment">// more code omitted ......</span></div></pre></td></tr></table></figure>
<p>This very well explains what those things are: they are instances of <code>Symbol</code> to represent operators. Knowing this level of detail about these things is enough for us, so let’s go back to IR.</p>
<p>The beginning of file <code>torch/csrc/jit/ir.h</code> very well explains what things are:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Graph represents one "function" of computation.</span></div><div class="line"><span class="comment">// It uses a simple ownership model where the graph owns all the nodes inside it.</span></div><div class="line"><span class="comment">// All references inside the graph are raw pointers.</span></div><div class="line"><span class="comment">// Destroying the Graph will invalidate any pointers to nodes in the graph.</span></div><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Graph</span>;</span></div><div class="line"></div><div class="line"><span class="comment">// Node is the base class of the IR graph. It represents one computation</span></div><div class="line"><span class="comment">// and dependencies on a list of Values. The "prim-ops", so to speak.</span></div><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Node</span>;</span></div><div class="line"></div><div class="line"><span class="comment">// A Value represents an input or output to node that is either a</span></div><div class="line"><span class="comment">// Tensor or an opaque Handle object, as determined by type().</span></div><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Value</span>;</span></div><div class="line"></div><div class="line"><span class="comment">// ......</span></div><div class="line"></div><div class="line"><span class="comment">// A list of nodes, with inputs and outputs</span></div><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Block</span>;</span></div><div class="line"></div><div class="line"><span class="comment">// Each use is represented by this type, see Node::uses()</span></div><div class="line"><span class="comment">// 'user' is the consumer of the value, offset is the index into</span></div><div class="line"><span class="comment">// 'user's input this where the produces will be found.</span></div><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Use</span> &#123;</span></div><div class="line">  Use(Node * user, <span class="keyword">size_t</span> offset)</div><div class="line">  : user(user), offset(offset) &#123;&#125;</div><div class="line">  Node * user;</div><div class="line">  <span class="keyword">size_t</span> offset;</div><div class="line">&#125;;</div><div class="line"></div><div class="line"><span class="comment">// ......</span></div><div class="line"></div><div class="line"><span class="comment">// Scope is a node of a trie that represents the tree of nested scopes.</span></div><div class="line"><span class="comment">// Individual scopes are pushed and popped from Graph, which holds a</span></div><div class="line"><span class="comment">// pointer to the current scope. Each Node in Graph holds a pointer</span></div><div class="line"><span class="comment">// to the scope that was current when the node was created.</span></div><div class="line"><span class="comment">// The trie never needs to shrink, it only grows until it is disposed</span></div><div class="line"><span class="comment">// of when Graph is deallocated. Hence, pointers to scopes held by nodes</span></div><div class="line"><span class="comment">// will always be valid as long as Graph is alive.</span></div><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Scope</span> &#123;</span></div></pre></td></tr></table></figure>
<p>Reading through the whole file, we can summarize how it works:</p>
<p>A <code>Graph</code> object owns all <code>Node</code>s, <code>Value</code>s, and <code>Block</code>s. The internal structure is not maintained by the <code>Graph</code> object, but inside <code>Node</code>s, <code>Value</code>s, and <code>Block</code>s.</p>
<p>Each <code>Node</code> keeps pointers to its input, and output <code>Value</code>s. It also maintains pointers to siblings in a doubly-linked list of <code>Node</code>s. This doubly-linked list is a topological sort of the <code>Node</code>s in the <code>Graph</code>. Each <code>Node</code> has a <code>NodeKind</code> as an object of <code>Symbol</code>. <code>Node</code>s also maintains a pointer to the <code>Block</code> owning this <code>Node</code>, as well as pointers to subblocks.</p>
<p>Each <code>Value</code> must be an output of some <code>Node</code>, and it has a <code>Node</code> pointer pointing to the <code>Node</code> that outputs this <code>Value</code>. It also has a <code>Use</code> list storing where this <code>Value</code> is used as input.</p>
<p>Each <code>Block</code> maintains pointers to its input and output <code>Node</code>s, as well as the <code>Node</code> owning this <code>Block</code>.</p>
<h1 id="From-Python-AST-to-PyTorch-IR-part-2"><a href="#From-Python-AST-to-PyTorch-IR-part-2" class="headerlink" title="From Python AST to PyTorch IR: part 2"></a>From Python AST to PyTorch IR: part 2</h1><p>With the knowledge of IR, let’s go back to read the backend compiler.</p>
<p>In the code in <code>torch/csrc/jit/script/compiler.cpp</code>, we have been seeing <code>SugaredValue</code> many times. What <code>SugaredValue</code> does is explained in <code>torch/csrc/jit/script/compiler.h</code>:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// The AST can contain nodes like `self`, `self.b` or `Python_fn` that</span></div><div class="line"><span class="comment">// are not first-class values in the graph representation, but instead</span></div><div class="line"><span class="comment">// will be desugared based on how they are used in the AST.</span></div><div class="line"></div><div class="line"><span class="comment">// SugaredValue is used to temporarily represent these values in a way</span></div><div class="line"><span class="comment">// that separates their behavior from the AST -&gt; IR converter itself.</span></div><div class="line"><span class="comment">// This allows us to keep dependencies on Python minimal.</span></div><div class="line"></div><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">SugaredValue</span> :</span> <span class="keyword">public</span> <span class="built_in">std</span>::enable_shared_from_this&lt;SugaredValue&gt; &#123;</div></pre></td></tr></table></figure>
<p>From the comments above, together with what we see when skimming through the code, we can see that, <code>SugaredValue</code> is a super class of different types of values. These values might be first-class values like tensors or integers, or <code>ScriptModule</code> such as <code>self</code>, or Python modules like <code>torch</code>, or some builtin functions like <code>print</code>. Different types of values are handled by different subclasses: <code>SimpleValue</code> for first class values, <code>BuiltinFunction</code> for operators like <code>aten::relu</code>, <code>BuiltinModule</code> for something like <code>torch</code>, <code>NoneValue</code> for <code>None</code>, <code>PrintValue</code> for <code>print</code>, <code>CastValue</code> for types like <code>int</code>, <code>float</code>, etc. These subclasses listed above are all defined in <code>torch/csrc/jit/script/compiler.{cpp, h}</code>.</p>
<p>Now let’s move on to read the constructor of the struct <code>to_ir</code>. It basically:</p>
<ol>
<li>Read the information of parameters from the Python AST, and set them up in graph.</li>
<li>Call <code>emitStatements</code> to emit IR for function body.</li>
<li>Set up output values for the graph based on the return statement in the end of function body (compiling functions that has a return statement on somewhere other than the end is not supported).</li>
</ol>
<p>In step 1, there is a little bit of trouble that for functions that is a method of some module, the first parameter is always the reference to the object owing this method (aka. the so called “self”). So it requires a little bit of special case when checking against schema. Also, we need to add the identifier for the first parameter to the symbol table (here the symbol table is <code>Environment::value_table</code>, an object of <code>ValueTable</code>). The input to the graph is not only those appears explicitly in the argument list, but also those members access inside the function body. Recall that when we read the code of <code>Method::run</code>, there is a step that push members onto the stack. This issue is not handled here, and we will see how it is handled later.</p>
<p>In step 2, things started to get complicated. In <code>emitStatements</code>, code emitting are dispatched to different specialized private methods of the struct by its type:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">emitStatements</span><span class="params">(List&lt;Stmt&gt;::const_iterator begin, List&lt;Stmt&gt;::const_iterator end)</span> </span>&#123;</div><div class="line">  <span class="keyword">for</span> (; begin != end; ++begin) &#123;</div><div class="line">    <span class="keyword">auto</span> stmt = *begin;</div><div class="line">    <span class="keyword">switch</span> (stmt.kind()) &#123;</div><div class="line">      <span class="keyword">case</span> TK_IF:</div><div class="line">        emitIf(If(stmt));</div><div class="line">        <span class="keyword">break</span>;</div><div class="line">      <span class="keyword">case</span> TK_WHILE:</div><div class="line">        emitWhile(While(stmt));</div><div class="line">        <span class="keyword">break</span>;</div><div class="line">      <span class="keyword">case</span> TK_FOR:</div><div class="line">        emitFor(For(stmt));</div><div class="line">        <span class="keyword">break</span>;</div><div class="line">      <span class="keyword">case</span> TK_ASSIGN:</div><div class="line">        emitAssignment(Assign(stmt));</div><div class="line">        <span class="keyword">break</span>;</div><div class="line">      <span class="keyword">case</span> TK_GLOBAL:</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">auto</span> ident : Global(stmt).names()) &#123;</div><div class="line">          <span class="keyword">const</span> <span class="keyword">auto</span>&amp; name = Ident(ident).name();</div><div class="line">          environment_stack-&gt;setVar(ident.range(), name, graph-&gt;addInput(name));</div><div class="line">        &#125;</div><div class="line">        <span class="keyword">break</span>;</div><div class="line">      <span class="keyword">case</span> TK_EXPR_STMT: &#123;</div><div class="line">        <span class="keyword">auto</span> exprs = ExprStmt(stmt).exprs();</div><div class="line">        <span class="keyword">for</span> (<span class="keyword">const</span> <span class="keyword">auto</span>&amp; expr : exprs) &#123;</div><div class="line">          emitSugaredExpr(expr, <span class="number">0</span>);</div><div class="line">        &#125;</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">break</span>;</div><div class="line">      <span class="keyword">case</span> TK_RETURN:</div><div class="line">        <span class="keyword">throw</span> ErrorReport(stmt) &lt;&lt; <span class="string">"return statements can appear only at the end "</span></div><div class="line">                                &lt;&lt; <span class="string">"of the function body"</span>;</div><div class="line">        <span class="keyword">break</span>;</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>There are so many specialized emits, I will not go over these in detail one by one. I will only go deep into <code>emitSugaredExpr</code> as an example here. <code>emitSugaredExpr</code> is defined as follows:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// any expression that can produce a SugaredValue is handled here</span></div><div class="line"><span class="comment">// expressions that only return a single Value* are handled in emitSimpleExpr</span></div><div class="line"><span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;SugaredValue&gt; emitSugaredExpr(Expr tree, <span class="keyword">size_t</span> n_binders) &#123;</div><div class="line">  <span class="keyword">switch</span>(tree.kind()) &#123;</div><div class="line">    <span class="keyword">case</span> TK_VAR:</div><div class="line">      <span class="keyword">return</span> environment_stack-&gt;getSugaredVar(Var(tree).name());</div><div class="line">    <span class="keyword">case</span> <span class="string">'.'</span>: &#123;</div><div class="line">      <span class="keyword">auto</span> select = Select(tree);</div><div class="line">      <span class="keyword">auto</span> sv = emitSugaredExpr(select.value(), <span class="number">1</span>);</div><div class="line">      <span class="keyword">return</span> sv-&gt;attr(select.range(), method, select.selector().name());</div><div class="line">    &#125;</div><div class="line">    <span class="keyword">case</span> TK_APPLY: &#123;</div><div class="line">      <span class="keyword">auto</span> apply = Apply(tree);</div><div class="line">      <span class="keyword">auto</span> inputs = getNamedValues(apply.inputs(), <span class="literal">true</span>);</div><div class="line">      <span class="keyword">auto</span> attributes = fmap(apply.attributes(), [&amp;](<span class="keyword">const</span> Attribute&amp; attr) &#123;</div><div class="line">        <span class="keyword">return</span> NamedValue(attr.range(), attr.name().name(), emitExpr(attr.value()));</div><div class="line">      &#125;);</div><div class="line">      <span class="comment">// the apply is directly an identifier 'foo'</span></div><div class="line">      <span class="keyword">if</span>(apply.callee().kind() == TK_VAR) &#123;</div><div class="line">        <span class="keyword">return</span> emitApplyIdent(Var(apply.callee()).name(), inputs, attributes, n_binders);</div><div class="line">      &#125;</div><div class="line">      <span class="keyword">return</span> emitApplyExpr(apply.callee(), inputs, attributes, n_binders);</div><div class="line">    &#125; <span class="keyword">break</span>;</div><div class="line">    <span class="keyword">default</span>:</div><div class="line">      <span class="keyword">return</span> <span class="built_in">std</span>::make_shared&lt;SimpleValue&gt;(emitSimpleExpr(tree));</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>What it does is basically: for cases that guaranteed to produce a <code>SimpleValue</code>, we just call <code>emitSimpleExpr</code> to emit the code, otherwise it must be one of the following three format: <code>foo</code>, <code>foo.bar</code>, <code>foo(bar)</code>. For the <code>foo</code> case, we just lookup <code>foo</code> in the symbol table, for the <code>foo.bar</code> case, we first emit <code>foo</code> and lookup its attribute <code>bar</code>. For the <code>foo(bar)</code> case, depending on whether <code>foo</code> is an identifier or an expression, invoke <code>emitApplyIdent</code> or <code>emitApplyExpr</code> correspondingly to do code emitting.</p>
<p>The <code>self</code> argument of the method is handled a bit differently: there is a subclass of <code>SugaredValue</code> called <code>ModuleValue</code> defined in <code>torch/csrc/jit/script/init.cpp</code>, in its override method <code>attr</code>, we see:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">if</span>(NamedParameter* v = <span class="keyword">module</span>-&gt;find_parameter(field)) &#123;</div><div class="line">  <span class="keyword">return</span> <span class="built_in">std</span>::make_shared&lt;SimpleValue&gt;(m.get_or_add_parameter(v-&gt;slot()));</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Where the <code>get_or_add_parameter</code> defined in <code>torch/csrc/jit/script/module.h</code> reads:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div></pre></td><td class="code"><pre><div class="line"><span class="function">Value * <span class="title">get_or_add_parameter</span><span class="params">(at::Tensor* slot)</span> </span>&#123;</div><div class="line">  <span class="keyword">auto</span> it = member_input_index.find(slot);</div><div class="line">  <span class="keyword">if</span>(it != member_input_index.end()) &#123;</div><div class="line">    <span class="keyword">return</span> graph()-&gt;inputs().at(it-&gt;second);</div><div class="line">  &#125;</div><div class="line">  <span class="comment">// add it as a new parameter</span></div><div class="line">  member_inputs.push_back(slot);</div><div class="line">  member_input_index[slot] = graph()-&gt;inputs().size();</div><div class="line">  <span class="keyword">return</span> graph()-&gt;addInput();</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>That tells us: adding members as parameters of the graph actually happens at code emitting of <code>self.bar</code>, where the <code>attr</code> of <code>ModuleValue</code> called.</p>
<h1 id="The-Graph-Executor"><a href="#The-Graph-Executor" class="headerlink" title="The Graph Executor"></a>The Graph Executor</h1><p>Now we have seen how the compilation is done and what does PyTorch JIT’s IR looks like, the thing left is how the IR are executed. From above we already know that the executor is obtained by invoking <code>Method::get_executor</code> and run by invoking <code>GraphExecutor::run</code>. Let’s first take a look at <code>Method::get_executor</code>:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line"><span class="function">GraphExecutor&amp; <span class="title">get_executor</span><span class="params">()</span> </span>&#123;</div><div class="line">  <span class="built_in">std</span>::call_once(executor_init, [&amp;]&#123;</div><div class="line">    executor = GraphExecutor(graph(), optimize);</div><div class="line">  &#125;);</div><div class="line">  <span class="keyword">return</span> executor;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>We know that a graph executor is created from a graph, and does optimization if asked. It’s not hard to guess from name that <code>GraphExecutor</code> is defined in <code>torch/csrc/jit/graph_executor.{h, cpp}</code>.</p>
<p>The constructor and <code>run</code> tells us that <code>GraphExecutor</code> is just a wrapper of <code>GraphExecutorImpl</code>:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">GraphExecutor::GraphExecutor(<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Graph&gt; graph, <span class="keyword">bool</span> optimize)</div><div class="line">: pImpl(<span class="keyword">new</span> GraphExecutorImpl(<span class="built_in">std</span>::move(graph), optimize)) &#123;&#125;</div><div class="line"></div><div class="line"><span class="keyword">void</span> GraphExecutor::run(Stack &amp; inputs) &#123;</div><div class="line">  <span class="keyword">return</span> pImpl-&gt;run(inputs);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>So let’s move on to <code>GraphExecutorImpl</code>:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">GraphExecutorImpl(<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Graph&gt; graph, <span class="keyword">bool</span> optimize)</div><div class="line">  : graph(prepareGraph(graph))</div><div class="line">  , optimize(optimize)</div><div class="line">  , num_inputs(<span class="keyword">this</span>-&gt;graph-&gt;inputs().size())</div><div class="line">  , num_flat_inputs(countFlatInputs(graph))</div><div class="line">  , num_outputs(<span class="keyword">this</span>-&gt;graph-&gt;outputs().size()) &#123;&#125;</div><div class="line"></div><div class="line"><span class="comment">// entry point where execution begins</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">(Stack &amp; <span class="built_in">stack</span>)</span> </span>&#123;</div><div class="line">  AT_CHECK(<span class="built_in">stack</span>.size() &gt;= num_inputs, <span class="string">"expected "</span>, num_inputs, <span class="string">" inputs, but got only "</span>, <span class="built_in">stack</span>.size());</div><div class="line"></div><div class="line">  <span class="keyword">if</span>(tracer::isTracing()) &#123;</div><div class="line">    <span class="keyword">return</span> runTraced(<span class="built_in">stack</span>);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="keyword">auto</span> &amp; execution_plan = optimize ? getOrCompile(<span class="built_in">stack</span>) : getOrCompileFallback();</div><div class="line">  <span class="keyword">return</span> execution_plan.run(<span class="built_in">stack</span>);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>We see that the graph is compiled at the first time it runs to get an execution plan. The <code>run</code> method of execution plan is called to run the graph. Compilation of graph to execution plan is done by <code>getOrCompile</code> or <code>getOrCompileFallback</code> depending on if optimization is enabled. These two methods are copied below:</p>
<figure class="highlight"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line">const ExecutionPlan &amp; getOrCompileFallback() &#123;</div><div class="line">  std::lock_guard&lt;std::mutex&gt; lock(compile_mutex);</div><div class="line">  if(!fallback) &#123;</div><div class="line">    auto graph_ = graph-&gt;copy();</div><div class="line">    runRequiredPasses(graph_);</div><div class="line">    fallback = ExecutionPlan(graph_);</div><div class="line">  &#125;</div><div class="line">  return fallback;</div><div class="line">&#125;</div><div class="line"></div><div class="line">const ExecutionPlan &amp; getOrCompile(const Stack&amp; stack) &#123;</div><div class="line">  // outside lock guard, to minimize the time holding the lock on the fast path</div><div class="line">  // ArgumentSpec even computes its hashCode here.</div><div class="line">  ArgumentSpec spec(autograd::GradMode::is_enabled(), last(stack, num_inputs), num_flat_inputs);</div><div class="line">  &#123;</div><div class="line">    std::lock_guard&lt;std::mutex&gt; lock(compile_mutex);</div><div class="line">    auto it = plan_cache.find(spec);</div><div class="line">    if (it != plan_cache.end())</div><div class="line">      return it-&gt;second;</div><div class="line">    auto plan = compileSpec(spec);</div><div class="line">    auto r = plan_cache.emplace(std::move(spec), std::move(plan));</div><div class="line">    return r.first-&gt;second;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>These code explain itself well: if optimization is turned off, then we only run required passes and cache the result. Otherwise, depending on the characteristic of inputs (<code>ArgumentSpec</code>), we run full optimization and cache the generated plan for each different <code>ArgumentSpec</code>. The plan is created by the constructor of <code>ExecutionPlan</code>.</p>
<p>It worth a look at what passes are called:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div></pre></td><td class="code"><pre><div class="line"><span class="function">ExecutionPlan <span class="title">compileSpec</span><span class="params">(<span class="keyword">const</span> ArgumentSpec &amp; spec)</span> </span>&#123;</div><div class="line">  <span class="keyword">auto</span> opt_graph = graph-&gt;copy();</div><div class="line">  setInputTypes(*opt_graph, spec);</div><div class="line"></div><div class="line">  <span class="comment">// Phase 1. Specialize to input definedness (this is very important for</span></div><div class="line">  <span class="comment">//          gradient graphs), and run required passes to bring the graph</span></div><div class="line">  <span class="comment">//          to an executable form.</span></div><div class="line">  runRequiredPasses(opt_graph);</div><div class="line"></div><div class="line">  <span class="comment">// Phase 2. Propagate detailed information about the spec through the</span></div><div class="line">  <span class="comment">//          graph (enabled more specializations in later passes).</span></div><div class="line">  <span class="comment">//          Shape propagation sometimes depends on certain arguments being</span></div><div class="line">  <span class="comment">//          constants, and constant propagation doesn't need shape information</span></div><div class="line">  <span class="comment">//          anyway, so it's better to run it first.</span></div><div class="line">  ConstantPropagation(opt_graph);</div><div class="line">  PropagateInputShapes(*opt_graph);</div><div class="line">  PropagateRequiresGrad(opt_graph);</div><div class="line"></div><div class="line">  <span class="comment">// Phase 3. Run differentiable optimizations (i.e. simple graph rewrites that</span></div><div class="line">  <span class="comment">//          we can still execute using autograd).</span></div><div class="line">  runOptimization(opt_graph, spec);</div><div class="line"></div><div class="line">  <span class="comment">// Phase 4. If this graph will be differentiated, we need to slice out the</span></div><div class="line">  <span class="comment">//          symbolically differentiable subgraphs for further optimizations.</span></div><div class="line">  <span class="comment">// Phase 5. Apply non-differentiable optimizations to the graphs we've found</span></div><div class="line">  <span class="comment">//          (or the whole grpah if we know we won't need its derivative).</span></div><div class="line">  <span class="keyword">if</span> (needsGradient(opt_graph)) &#123;</div><div class="line">    <span class="keyword">auto</span> diff_nodes = CreateAutodiffSubgraphs(*opt_graph);</div><div class="line">    <span class="keyword">for</span> (Node * dnode : diff_nodes) &#123;</div><div class="line">      <span class="keyword">auto</span> diff_graph = <span class="built_in">std</span>::move(dnode-&gt;g(attr::Subgraph));</div><div class="line">      Gradient gradient = differentiate(diff_graph);</div><div class="line">      runNondiffOptimization(gradient.f);</div><div class="line">      packGradient(gradient, dnode);</div><div class="line">    &#125;</div><div class="line">    InlineAutodiffSubgraphs(opt_graph);</div><div class="line">  &#125; <span class="keyword">else</span> &#123;</div><div class="line">    runNondiffOptimization(opt_graph);</div><div class="line">  &#125;</div><div class="line">  <span class="comment">// Make sure there are no leftovers from any passes.</span></div><div class="line">  EliminateDeadCode(opt_graph);</div><div class="line">  <span class="keyword">return</span> ExecutionPlan(opt_graph);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">runOptimization</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Graph&gt;&amp; graph, <span class="keyword">const</span> ArgumentSpec&amp; spec)</span> </span>&#123;</div><div class="line">  EliminateDeadCode(graph);</div><div class="line">  EliminateCommonSubexpression(graph);</div><div class="line">  UnrollLoops(graph);</div><div class="line">  PeepholeOptimize(graph);</div><div class="line">  CheckInplace(graph);</div><div class="line">  BatchMM(graph);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">runNondiffOptimization</span><span class="params">(<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Graph&gt;&amp; graph)</span> </span>&#123;</div><div class="line">  FuseGraph(graph);</div><div class="line">&#125;</div><div class="line"></div><div class="line"><span class="comment">// ......</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">runRequiredPasses</span><span class="params">(<span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Graph&gt;&amp; g)</span>  </span>&#123;</div><div class="line">  specializeUndef(*g);</div><div class="line">  LowerGradOf(*g);</div><div class="line">  <span class="comment">// implicit inserted expand nodes are not necessarily always valid</span></div><div class="line">  <span class="comment">// when used inside script methods that might have unstable shapes</span></div><div class="line">  <span class="comment">// we remove the implicitly created ones, and have shape analysis</span></div><div class="line">  <span class="comment">// add valid expand nodes when the shapes are stable</span></div><div class="line">  RemoveExpands(g);</div><div class="line">  CanonicalizeOps(g);</div><div class="line">  EliminateDeadCode(g);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>I will not go deep into these passes here, interested readers can read them at <code>torch/csrc/jit/passes/</code>.</p>
<p>Now it’s time to look at <code>ExecutionPlan</code>:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">ExecutionPlan</span> &#123;</span></div><div class="line">  ExecutionPlan() = <span class="keyword">default</span>;</div><div class="line">  ExecutionPlan(<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Graph&gt; graph)</div><div class="line">    : code(graph)</div><div class="line">    , graph(<span class="built_in">std</span>::move(graph)) &#123;&#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">void</span> <span class="title">run</span><span class="params">(Stack&amp; <span class="built_in">stack</span>)</span> <span class="keyword">const</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> InterpreterState(code).runOneStage(<span class="built_in">stack</span>);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function"><span class="keyword">operator</span> <span class="title">bool</span><span class="params">()</span> <span class="keyword">const</span> </span>&#123;</div><div class="line">    <span class="keyword">return</span> <span class="keyword">static_cast</span>&lt;<span class="keyword">bool</span>&gt;(graph);</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  <span class="function">ExecutionPlanState <span class="title">getDebugState</span><span class="params">()</span> </span>&#123;</div><div class="line">    ExecutionPlanState state;</div><div class="line">    state.code = &amp;code;</div><div class="line">    state.graph = graph.get();</div><div class="line">    <span class="keyword">return</span> state;</div><div class="line">  &#125;</div><div class="line"></div><div class="line">  Code code;</div><div class="line">  <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Graph&gt; graph;</div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>It just convert the graph into an object of <code>Code</code>, and the running is done by <code>InterpreterState</code>.</p>
<h1 id="Compiling-to-Interpreter-Instructions"><a href="#Compiling-to-Interpreter-Instructions" class="headerlink" title="Compiling to Interpreter Instructions"></a>Compiling to Interpreter Instructions</h1><p><code>Code</code> and <code>InterpreterState</code> are defined in <code>torch/csrc/jit/interpreter.{h,cpp}</code>. These two classes are just a wrapper of its implementations:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div></pre></td><td class="code"><pre><div class="line">Code::Code(<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Graph&gt;&amp; graph)</div><div class="line">    : pImpl(<span class="keyword">new</span> CodeImpl(graph)) &#123;&#125;</div><div class="line">Code::~Code() = <span class="keyword">default</span>;</div><div class="line"></div><div class="line"><span class="keyword">const</span> <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;GraphExecutor*&gt;&amp; Code::grad_executors() &#123;</div><div class="line">  <span class="keyword">return</span> pImpl-&gt;grad_executors();</div><div class="line">&#125;</div><div class="line"></div><div class="line">InterpreterState::InterpreterState(<span class="keyword">const</span> Code &amp; code)</div><div class="line">  : pImpl(<span class="keyword">new</span> InterpreterStateImpl(code)) &#123;&#125;</div><div class="line">InterpreterState::~InterpreterState() = <span class="keyword">default</span>;</div><div class="line"></div><div class="line"><span class="keyword">void</span> InterpreterState::runOneStage(Stack &amp; <span class="built_in">stack</span>) &#123;</div><div class="line">  <span class="keyword">return</span> pImpl-&gt;runOneStage(<span class="built_in">stack</span>);</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p><code>CodeImpl</code> is a long struct, but quite logical. A selected list of fields it has is listed below:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div></pre></td><td class="code"><pre><div class="line">PreprocessGraph preprocess;</div><div class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Instruction&gt; instructions;</div></pre></td></tr></table></figure>
<p>Its constructor is:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div></pre></td><td class="code"><pre><div class="line">CodeImpl(<span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Graph&gt;&amp; graph_)</div><div class="line">    : preprocess(*graph_) &#123;</div><div class="line">  graph = preprocess.graph;</div><div class="line">  <span class="comment">// std::cout &lt;&lt; "into code graph:\n" &lt;&lt; *graph &lt;&lt; "\n";</span></div><div class="line">  insertNodesFromBlock(graph-&gt;block());</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Clearly we can see what it does is: 1. preprocess the graph, and then 2. emit instructions for interpreter.</p>
<p>The preprocessing of graph is very well explained in the beginning of file:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// Before we translate to intepreter instructions, we do</span></div><div class="line"><span class="comment">// some preprocessing of the graph to turn it into a form that is closer</span></div><div class="line"><span class="comment">// to what the instructions will look like.</span></div><div class="line"><span class="comment">// In particular we:</span></div><div class="line"><span class="comment">// * (TODO) desugar Loop trip counts into c = 0, c += 1 instructions in the loop</span></div><div class="line"><span class="comment">// * flatten stages so that each stage starts with a load from the stack</span></div><div class="line"><span class="comment">//   and ends with a store to the stack</span></div><div class="line"><span class="comment">// *. computes move_flags (see Outputs), and inserts</span></div><div class="line"><span class="comment">// *  Drop nodes are inserted for any node that is unused to create a dummy use</span></div><div class="line"><span class="comment">//    that will cause the interpreter to free the node.</span></div><div class="line"><span class="comment">//    A drop node is just a node with no outputs that just pops its inputs off the stack,</span></div><div class="line"><span class="comment">//    to ensure the interpreter release references to nodes that are never used.</span></div><div class="line"><span class="comment">//    Drop nodes are also inserted when the last use of a node is in some conditionally</span></div><div class="line"><span class="comment">//    run control flow (e.g. one side of an If) and the interpreter must free</span></div><div class="line"><span class="comment">//    the node only after the control flow has reconverged</span></div><div class="line"><span class="comment">// Outputs are:</span></div><div class="line"><span class="comment">// * graph - the post processed copy of g</span></div><div class="line"><span class="comment">// * move_flags[n] - a list of booleans, one for each input,</span></div><div class="line"><span class="comment">//   indicating whether this is the last use of the value. The interpreter</span></div><div class="line"><span class="comment">//   should generate a move rather than a copy in this case.</span></div><div class="line"><span class="comment">// * stage_input_types: the type annotations on the inputs to each stage</span></div><div class="line"><span class="comment">//   these can be removed once the the backward tracer is no longer used</span></div></pre></td></tr></table></figure>
<p>as well as in its definition</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div></pre></td><td class="code"><pre><div class="line"><span class="class"><span class="keyword">struct</span> <span class="title">PreprocessGraph</span> &#123;</span></div><div class="line">  PreprocessGraph(Graph &amp; g)</div><div class="line">  : graph(g.copy()) &#123;</div><div class="line">    desugarTripCounts(graph-&gt;block());</div><div class="line">    stage_input_types = flattenStages(*graph);</div><div class="line">    dropUnused(graph-&gt;block());</div><div class="line">    <span class="comment">// fill in move_flags by scanning blocks;</span></div><div class="line">    move_flags = findLastUses(*graph);</div><div class="line">    <span class="comment">//<span class="doctag">TODO:</span> desugar Loop trip counts, for now we drop trip counts</span></div><div class="line">  &#125;</div><div class="line">  <span class="comment">// Outputs of the preprocessing:</span></div><div class="line">  <span class="built_in">std</span>::<span class="built_in">shared_ptr</span>&lt;Graph&gt; graph;</div><div class="line">  <span class="comment">// for each input, should we move rather than copy the inputs</span></div><div class="line">  <span class="built_in">std</span>::<span class="built_in">unordered_map</span>&lt;Node*, <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="keyword">uint8_t</span>&gt;&gt; move_flags;</div><div class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;TypePtr&gt;&gt; stage_input_types;</div><div class="line"></div><div class="line">&#125;;</div></pre></td></tr></table></figure>
<p>The <code>insertNodesFromBlock</code> emits instructions. It is also very self-explained:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div></pre></td><td class="code"><pre><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">insertNodesFromBlock</span><span class="params">(Block* block)</span> </span>&#123;</div><div class="line">  <span class="keyword">for</span>(<span class="keyword">auto</span> node : block-&gt;nodes()) &#123;</div><div class="line">    <span class="keyword">const</span> <span class="keyword">auto</span> &amp; source_location = node-&gt;getSourceLocation();</div><div class="line">    <span class="keyword">switch</span>(node-&gt;kind()) &#123;</div><div class="line">      <span class="keyword">case</span> prim::If: &#123;</div><div class="line">        <span class="comment">// x = if c:</span></div><div class="line">        <span class="comment">//   &lt;then_block&gt;</span></div><div class="line">        <span class="comment">//   -&gt; (vt)</span></div><div class="line">        <span class="comment">// else:</span></div><div class="line">        <span class="comment">//    &lt;else_block&gt;</span></div><div class="line">        <span class="comment">//   -&gt; (vf)</span></div><div class="line"></div><div class="line">        <span class="comment">// turns into:</span></div><div class="line">        <span class="comment">//   JumpNZ c, then</span></div><div class="line">        <span class="comment">//   &lt;else_block&gt;</span></div><div class="line">        <span class="comment">//   x = vf</span></div><div class="line">        <span class="comment">//   Jump end</span></div><div class="line">        <span class="comment">// then:</span></div><div class="line">        <span class="comment">//   &lt;then_block&gt;</span></div><div class="line">        <span class="comment">//   x = vt</span></div><div class="line">        <span class="comment">// end:</span></div><div class="line"></div><div class="line">        <span class="comment">// prim::Placeholder instructions are replaced with branch instructions</span></div><div class="line">        <span class="comment">// when the branch target locations are known</span></div><div class="line">        <span class="keyword">auto</span> cond_branch = insertInstruction(prim::Placeholder, source_location, node-&gt;inputs(), moveFlags(node), &#123;&#125;);</div><div class="line">        <span class="keyword">auto</span> then_block = node-&gt;blocks()[<span class="number">0</span>];</div><div class="line">        <span class="keyword">auto</span> else_block = node-&gt;blocks()[<span class="number">1</span>];</div><div class="line">        insertNodesFromBlock(else_block);</div><div class="line">        insertAssign(source_location,else_block-&gt;outputs(), moveFlags(else_block), node-&gt;outputs());</div><div class="line">        <span class="keyword">auto</span> jump = insertInstruction(prim::Placeholder, source_location, &#123;&#125;, &#123;&#125;, &#123;&#125;);</div><div class="line">        <span class="keyword">auto</span> then_block_start = instructions.size();</div><div class="line">        insertNodesFromBlock(then_block);</div><div class="line">        insertAssign(source_location, then_block-&gt;outputs(), moveFlags(then_block), node-&gt;outputs());</div><div class="line">        createJump(jump, instructions.size());</div><div class="line">        createJumpNZ(cond_branch, then_block_start);</div><div class="line">      &#125; <span class="keyword">break</span>;</div><div class="line">      <span class="keyword">case</span> prim::Loop: &#123;</div><div class="line">        <span class="comment">// omitted ......</span></div><div class="line">      &#125; <span class="keyword">break</span>;</div><div class="line">      <span class="keyword">default</span>: &#123;</div><div class="line">        insertInstruction(node);</div><div class="line">      &#125; <span class="keyword">break</span>;</div><div class="line">    &#125;</div><div class="line">    <span class="comment">// each stage ends with a load instruction</span></div><div class="line">    <span class="comment">// we record where these instructions occur, and use them to</span></div><div class="line">    <span class="comment">// exit the interpreter</span></div><div class="line">    <span class="keyword">if</span>(node-&gt;kind() == prim::Load) &#123;</div><div class="line">      stage_end.push_back(instructions.size());</div><div class="line">    &#125;</div><div class="line">  &#125;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>Since the nodes are topologically sorted, we just need to iterate the linked list and generate code for each node.</p>
<h1 id="The-Virtual-Machine"><a href="#The-Virtual-Machine" class="headerlink" title="The Virtual Machine"></a>The Virtual Machine</h1><p><code>InterpreterStateImpl</code> is the virtual machine that executes instructions.</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div></pre></td><td class="code"><pre><div class="line">InterpreterStateImpl(<span class="keyword">const</span> Code &amp; code)</div><div class="line">: function(code.pImpl),</div><div class="line">  int_data(function-&gt;int_data.data()),</div><div class="line">  bool_data(function-&gt;bool_data),</div><div class="line">  registers(function-&gt;register_size) &#123;</div><div class="line">&#125;</div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">runOneStage</span><span class="params">(Stack &amp; <span class="built_in">stack</span>)</span> </span>&#123;</div><div class="line">  <span class="comment">// std::cout &lt;&lt; "running stage: " &lt;&lt; current_stage &lt;&lt; " of " &lt;&lt; function-&gt;stage_end.size() &lt;&lt; "\n";</span></div><div class="line">  <span class="comment">// std::cout &lt;&lt; *function-&gt;graph &lt;&lt; "\n";</span></div><div class="line">  <span class="comment">// function-&gt;dump(std::cout);</span></div><div class="line">  <span class="keyword">size_t</span> pc = current_pc;</div><div class="line">  <span class="keyword">size_t</span> last = function-&gt;stage_end[current_stage];</div><div class="line">  <span class="keyword">auto</span> &amp; instructions = function-&gt;instructions;</div><div class="line">  <span class="keyword">while</span>(pc &lt; last) &#123;</div><div class="line">      <span class="comment">// std::cout &lt;&lt; "executing " &lt;&lt; pc &lt;&lt; ": ";</span></div><div class="line">      <span class="comment">// function-&gt;dumpInstruction(std::cout, pc);</span></div><div class="line">      <span class="comment">// std::cout &lt;&lt; "\n";</span></div><div class="line">      <span class="keyword">try</span> &#123;</div><div class="line">        <span class="keyword">auto</span> &amp; inst = instructions[pc];</div><div class="line">        loadTensorsFromRegisters(inst.inputs, <span class="built_in">stack</span>);</div><div class="line">        <span class="keyword">size_t</span> new_pc = pc + <span class="number">1</span> + inst.callback(<span class="built_in">stack</span>);</div><div class="line">        <span class="keyword">for</span>(<span class="keyword">int</span> i = inst.outputs.size - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i--) &#123;</div><div class="line">          <span class="keyword">int</span> reg = get(inst.outputs,i);</div><div class="line">          registers[reg] = pop(<span class="built_in">stack</span>);</div><div class="line">          <span class="comment">// std::cout &lt;&lt; "pop reg[" &lt;&lt; reg &lt;&lt; "];\n" &lt;&lt; registers[reg].pImpl &lt;&lt; "\n";</span></div><div class="line">        &#125;</div><div class="line">        pc = new_pc;</div><div class="line">      &#125; <span class="keyword">catch</span>(<span class="built_in">std</span>::exception &amp; e) &#123;</div><div class="line">        <span class="keyword">if</span>(!instructions[pc].debug_location)</div><div class="line">          <span class="keyword">throw</span>; <span class="comment">// rethrow original exception</span></div><div class="line">        <span class="comment">// throw a new exception with enhanced debugging information</span></div><div class="line">        instructions[pc].debug_location-&gt;wrapAndRethrowException(e, <span class="string">"operation failed in interpreter"</span>);</div><div class="line">      &#125;</div><div class="line">  &#125;</div><div class="line">  current_pc = pc;</div><div class="line">  current_stage++;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>There is nothing special, just mimicking the behavior of processors. We can easily tell from the above code that the actions is defined at <code>Instruction::callback</code> and branching is implemented as returning a non-zero value from that callback function. Some of the callbacks are defined inside <code>CodeImpl</code>, such as:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div></pre></td><td class="code"><pre><div class="line"><span class="comment">// jump when input is not 0</span></div><div class="line"><span class="function"><span class="keyword">void</span> <span class="title">createJumpNZ</span><span class="params">(<span class="keyword">int</span> from_inst, <span class="keyword">int</span> to_inst)</span> </span>&#123;</div><div class="line">  <span class="keyword">auto</span> &amp; inst = instructions[from_inst];</div><div class="line">  JIT_ASSERT(inst.debug_name == prim::Placeholder);</div><div class="line">  <span class="keyword">auto</span> offset = relativeJump(from_inst, to_inst);</div><div class="line">  inst.callback = [offset](Stack &amp; <span class="built_in">stack</span>) &#123;</div><div class="line">    <span class="keyword">auto</span> t = pop(<span class="built_in">stack</span>).toInt();</div><div class="line">    <span class="keyword">return</span> (t != <span class="number">0</span>) ? offset : <span class="number">0</span>;</div><div class="line">  &#125;;</div><div class="line">  inst.debug_name = prim::JumpNZ;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>while others are defined by its node kind:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div></pre></td><td class="code"><pre><div class="line"><span class="keyword">size_t</span> insertInstruction(Node * n) &#123;</div><div class="line">  <span class="keyword">auto</span> inst = insertInstruction(n-&gt;kind(), n-&gt;getSourceLocation(), n-&gt;inputs(), moveFlags(n) , n-&gt;outputs());</div><div class="line">  instructions[inst].callback = getOperation(n);</div><div class="line">  <span class="keyword">return</span> inst;</div><div class="line">&#125;</div></pre></td></tr></table></figure>
<p>where <code>getOperation</code> is defined in <code>torch/csrc/jit/operator.{h, cpp}</code>. Further reading through these two files, we can see that operations are registered by calling <code>registerOperator</code>, which is done through calling <code>RegisterOperators</code>. Using <code>grep RegisterOperators -r torch/csrc/</code>, we can locate the definition of all operations:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div></pre></td><td class="code"><pre><div class="line">torch/csrc/jit/generated/register_aten_ops.cpp:RegisterOperators reg(&#123;</div><div class="line">torch/csrc/jit/fusers/common/fusion_handle_impl.cpp:RegisterOperators reg_fused_operators(&#123;</div><div class="line">torch/csrc/jit/custom_operator.h:/// so in the global scope when a `RegisterOperators` object is assigned to a</div><div class="line">torch/csrc/jit/custom_operator.h:struct TORCH_API RegisterOperators &#123;</div><div class="line">torch/csrc/jit/custom_operator.h:  RegisterOperators() = default;</div><div class="line">torch/csrc/jit/custom_operator.h:  RegisterOperators(std::vector&lt;Operator&gt; operators) &#123;</div><div class="line">torch/csrc/jit/custom_operator.h:  RegisterOperators(const std::string&amp; name, Implementation&amp;&amp; implementation) &#123;</div><div class="line">torch/csrc/jit/custom_operator.h:  RegisterOperators&amp; op(</div><div class="line">torch/csrc/jit/Python_interpreter.cpp:RegisterOperators reg(&#123;</div><div class="line">torch/csrc/jit/register_special_ops.cpp:RegisterOperators reg(&#123;</div><div class="line">torch/csrc/jit/graph_executor.cpp:RegisterOperators reg_graph_executor_ops(&#123;</div><div class="line">torch/csrc/jit/constants.cpp:RegisterOperators reg(&#123;</div><div class="line">torch/csrc/jit/register_prim_ops.cpp:RegisterOperators reg(&#123;</div><div class="line">torch/csrc/jit/register_prim_ops.cpp:RegisterOperators reg2(&#123;</div><div class="line">torch/csrc/jit/test_jit.cpp:    RegisterOperators reg(&#123;createOperator(</div><div class="line">torch/csrc/jit/test_jit.cpp:    RegisterOperators reg(&#123;createOperator(</div><div class="line">torch/csrc/jit/test_jit.cpp:    RegisterOperators reg(&#123;createOperator(</div><div class="line">torch/csrc/jit/test_jit.cpp:    RegisterOperators reg(</div></pre></td></tr></table></figure>
<p>At this point, we are done with getting the whole big picture of PyTorch’s JIT. It’s time to stop here, and interested readers can read the code by themselves for more details.</p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/PyTorch/" rel="tag"># PyTorch</a>
          
            <a href="/tags/深度学习/" rel="tag"># 深度学习</a>
          
            <a href="/tags/机器学习/" rel="tag"># 机器学习</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2018/06/11/从头开始阅读PyTorch代码 -- Operators篇/" rel="next" title="从头开始阅读PyTorch代码 -- Operators篇">
                <i class="fa fa-chevron-left"></i> 从头开始阅读PyTorch代码 -- Operators篇
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </article>





    <div class="post-spread">
      
    </div>

  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="zasdfgbnm" />
          <p class="site-author-name" itemprop="name">zasdfgbnm</p>
           
              <p class="site-description motion-element" itemprop="description"></p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives/">
                <span class="site-state-item-count">8</span>
                <span class="site-state-item-name">日志</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">3</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">35</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/zasdfgbnm" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Starting-point-script-and-script-method"><span class="nav-number">1.</span> <span class="nav-text">Starting point: script and script_method</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Scripting-a-function"><span class="nav-number">1.1.</span> <span class="nav-text">Scripting a function</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Scripting-a-module"><span class="nav-number">1.2.</span> <span class="nav-text">Scripting a module</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#The-frontend"><span class="nav-number">2.</span> <span class="nav-text">The frontend</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#ScriptModule-and-ScriptMethod"><span class="nav-number">3.</span> <span class="nav-text">ScriptModule and ScriptMethod</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#From-Python-AST-to-PyTorch-IR-part-1"><span class="nav-number">4.</span> <span class="nav-text">From Python AST to PyTorch IR: part 1</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#The-PyTorch-IR"><span class="nav-number">5.</span> <span class="nav-text">The PyTorch IR</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#From-Python-AST-to-PyTorch-IR-part-2"><span class="nav-number">6.</span> <span class="nav-text">From Python AST to PyTorch IR: part 2</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#The-Graph-Executor"><span class="nav-number">7.</span> <span class="nav-text">The Graph Executor</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Compiling-to-Interpreter-Instructions"><span class="nav-number">8.</span> <span class="nav-text">Compiling to Interpreter Instructions</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#The-Virtual-Machine"><span class="nav-number">9.</span> <span class="nav-text">The Virtual Machine</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">zasdfgbnm</span>
</div>


<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        

        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  

    
      <script id="dsq-count-scr" src="https://zasdfgbnm-github-io.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'https://zasdfgbnm.github.io/2018/09/20/PyTorch-JIT-Source-Code-Read-Note/';
          this.page.identifier = '2018/09/20/PyTorch-JIT-Source-Code-Read-Note/';
          this.page.title = 'PyTorch JIT Source Code Read Note';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://zasdfgbnm-github-io.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  





  








  





  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
